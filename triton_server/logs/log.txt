I0804 08:09:44.897777 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f6b6e000000' with size 268435456
I0804 08:09:44.898112 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:09:44.902155 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:09:44.902202 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:09:44.902254 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:09:44.902285 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:09:44.902323 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:09:44.902349 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:09:44.902374 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:09:44.902397 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:09:44.902421 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:09:44.902765 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:09:44.902804 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:09:44.902827 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:09:44.902849 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:09:44.902870 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:09:44.903249 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:09:45.284699 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:09:45.284748 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:09:45.284756 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:09:45.287557 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:09:45.287587 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:09:45.287597 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:09:45.287601 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:09:56.751978 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:09:56.752661 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:09:56.753183 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:09:56.753202 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:09:56.753210 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:09:56.753218 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:09:56.753266 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:09:56.753653 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:09:56.754032 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:09:56.754050 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:09:56.754055 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:09:56.754059 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:09:56.754413 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:09:59.122399 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:10:02.764532 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:10:02.765033 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:10:02.765589 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:10:02.765610 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:10:02.765617 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:10:02.765631 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:10:02.765668 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0804 08:10:02.765927 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 08:10:02.766261 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 08:10:02.766276 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 08:10:02.766280 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 08:10:02.766284 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 08:10:02.766322 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0804 08:10:03.556136 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 08:10:03.556542 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 08:10:03.557014 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0804 08:10:03.559078 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0804 08:10:04.619733 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0804 08:10:04.620020 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0804 08:10:09.857854 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0804 08:10:09.857903 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 08:10:12.662554 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0804 08:10:12.662668 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 08:10:14.791961 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 08:10:14.792243 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0804 08:10:15.621573 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0804 08:10:15.621752 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 08:10:16.425899 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:10:16.426125 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0804 08:10:17.991043 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 08:10:17.992129 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:10:17.992258 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 08:10:17.992422 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0804 08:10:19.220704 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 08:10:20.509757 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 08:10:20.787406 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:10:20.787609 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 08:10:22.499930 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:10:39.195494 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0804 08:10:39.511177 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0804 08:10:39.511343 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0804 08:10:40.766827 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0804 08:10:42.061523 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 08:10:57.336702 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0804 08:10:57.336859 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0804 08:10:58.560881 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0804 08:10:59.889269 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0804 08:11:01.106612 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0804 08:11:02.537541 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0804 08:11:03.837361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0804 08:11:05.237311 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0804 08:11:06.523818 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0804 08:11:07.869263 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0804 08:11:09.145481 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0804 08:11:10.455869 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0804 08:11:11.725472 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0804 08:11:11.727806 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0804 08:11:13.087878 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0804 08:11:13.089484 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0804 08:11:13.089551 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0804 08:11:13.089589 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0804 08:11:13.089620 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0804 08:11:13.089651 1 model_lifecycle.cc:459] loading: intent_ensemble:1
E0804 08:11:13.089678 1 model_repository_manager.cc:507] failed to load model 'pipeline_greedy_ensemble_EN': at least one version must be available under the version policy of model 'pipeline_greedy_ensemble_EN'
E0804 08:11:13.089694 1 model_repository_manager.cc:507] failed to load model 'pipeline_greedy_ensemble_HI': at least one version must be available under the version policy of model 'pipeline_greedy_ensemble_HI'
E0804 08:11:13.089711 1 model_repository_manager.cc:507] failed to load model 'pipeline_pyctc_ensemble_EN': at least one version must be available under the version policy of model 'pipeline_pyctc_ensemble_EN'
E0804 08:11:13.089726 1 model_repository_manager.cc:507] failed to load model 'pipeline_pyctc_ensemble_HI': at least one version must be available under the version policy of model 'pipeline_pyctc_ensemble_HI'
I0804 08:11:13.089784 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0804 08:11:13.089813 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0804 08:11:13.089858 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0804 08:11:13.089889 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0804 08:11:13.090374 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0804 08:11:13.090495 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0804 08:11:13.090538 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:11:13.090636 1 server.cc:633] 
+-----------------------------+---------+----------------------------------------+
| Model                       | Version | Status                                 |
+-----------------------------+---------+----------------------------------------+
| asr_am_EN                   | 1       | READY                                  |
| asr_am_HI                   | 1       | READY                                  |
| asr_greedy_decoder_EN       | 1       | READY                                  |
| asr_greedy_decoder_HI       | 1       | READY                                  |
| asr_greedy_ensemble_EN      | 1       | READY                                  |
| asr_greedy_ensemble_HI      | 1       | READY                                  |
| asr_greedy_top1             | 1       | READY                                  |
| asr_preprocessor            | 1       | READY                                  |
| asr_pyctc_decoder_EN        | 1       | READY                                  |
| asr_pyctc_decoder_HI        | 1       | READY                                  |
| asr_pyctc_ensemble_EN       | 1       | READY                                  |
| asr_pyctc_ensemble_HI       | 1       | READY                                  |
| entity_EN                   | 1       | READY                                  |
| entity_HI                   | 1       | READY                                  |
| intent_ensemble             | 1       | READY                                  |
| intent_model_onnx           | 1       | READY                                  |
| intent_postprocessor        | 1       | READY                                  |
| intent_preprocessor         | 1       | READY                                  |
| itn_EN                      | 1       | READY                                  |
| itn_HI                      | 1       | READY                                  |
| pipeline_greedy_ensemble_EN | -       | Not loaded: No model version was found |
| pipeline_greedy_ensemble_HI | -       | Not loaded: No model version was found |
| pipeline_pyctc_ensemble_EN  | -       | Not loaded: No model version was found |
| pipeline_pyctc_ensemble_HI  | -       | Not loaded: No model version was found |
+-----------------------------+---------+----------------------------------------+

I0804 08:11:13.106262 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0804 08:11:13.106486 1 metrics.cc:757] Collecting CPU metrics
I0804 08:11:13.106610 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:11:13.106633 1 server.cc:264] Waiting for in-flight requests to complete.
I0804 08:11:13.106656 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0804 08:11:13.106980 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0804 08:11:13.107138 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:11:13.107261 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:11:13.111480 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:11:13.111776 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_EN' version 1
I0804 08:11:13.111813 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_HI' version 1
I0804 08:11:13.112001 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0804 08:11:13.112295 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:11:13.112429 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:11:13.112778 1 server.cc:295] All models are stopped, unloading models
I0804 08:11:13.112804 1 server.cc:302] Timeout 30: Found 16 live models and 0 in-flight non-inference requests
I0804 08:11:13.113225 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0804 08:11:13.113441 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:11:13.113859 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:11:13.114000 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_top1' version 1
I0804 08:11:13.114128 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0804 08:11:13.126271 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:11:13.126404 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:11:13.126545 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0804 08:11:13.131262 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0804 08:11:13.137636 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:11:13.137782 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0804 08:11:14.116263 1 server.cc:302] Timeout 29: Found 10 live models and 0 in-flight non-inference requests
I0804 08:11:14.295989 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_HI' version 1
I0804 08:11:14.316566 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0804 08:11:14.342538 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0804 08:11:14.387406 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_EN' version 1
I0804 08:11:14.393190 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0804 08:11:14.425757 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0804 08:11:14.442524 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0804 08:11:14.566947 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0804 08:11:15.116413 1 server.cc:302] Timeout 28: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:16.116534 1 server.cc:302] Timeout 27: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:17.116670 1 server.cc:302] Timeout 26: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:18.116799 1 server.cc:302] Timeout 25: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:19.116940 1 server.cc:302] Timeout 24: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:20.117096 1 server.cc:302] Timeout 23: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:21.117242 1 server.cc:302] Timeout 22: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:22.117389 1 server.cc:302] Timeout 21: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:23.117547 1 server.cc:302] Timeout 20: Found 2 live models and 0 in-flight non-inference requests
I0804 08:11:23.959659 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0804 08:11:24.049474 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0804 08:11:24.117684 1 server.cc:302] Timeout 19: Found 0 live models and 0 in-flight non-inference requests
I0804 08:11:30.062103 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7ff01a000000' with size 268435456
I0804 08:11:30.062463 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:11:30.066345 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:11:30.066388 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:11:30.066467 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:11:30.066502 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:11:30.066542 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:11:30.066577 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:11:30.066603 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:11:30.066687 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:11:30.066720 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:11:30.066748 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:11:30.066775 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:11:30.066799 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:11:30.066822 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:11:30.066843 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:11:30.067025 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:11:30.407684 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:11:30.407730 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:11:30.407737 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:11:30.409679 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:11:30.410637 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:11:30.411070 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:11:30.411086 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:11:30.411091 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:11:30.411096 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:11:30.411125 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:11:30.411496 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:11:30.411914 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:11:30.411929 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:11:30.411933 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:11:30.411937 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:11:30.413295 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:11:30.413332 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:11:30.413341 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:11:30.413344 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:11:30.422306 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:11:32.737024 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:11:34.635267 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0804 08:11:34.635671 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 08:11:34.636108 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 08:11:34.636139 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 08:11:34.636156 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 08:11:34.636160 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 08:11:34.636221 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:11:34.636589 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:11:34.636980 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:11:34.636995 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:11:34.637000 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:11:34.637004 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:11:34.637043 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 08:11:34.638374 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0804 08:11:34.638496 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:11:40.217848 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:12:01.192212 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 08:12:01.192707 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 08:12:07.522037 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0804 08:12:08.281035 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0804 08:12:08.281179 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0804 08:12:08.284221 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:12:08.284336 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0804 08:12:09.905793 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 08:12:09.906907 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:12:11.166837 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 08:12:11.938310 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0804 08:12:11.938523 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 08:12:12.249423 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 08:12:12.249548 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0804 08:12:13.545094 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 08:12:17.232550 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 08:12:17.232679 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 08:12:32.161050 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0804 08:12:32.161232 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0804 08:12:33.189264 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 08:12:33.189565 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0804 08:12:33.457241 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0804 08:12:33.457392 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 08:12:36.702474 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0804 08:12:36.702601 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0804 08:12:38.702107 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0804 08:12:38.702259 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0804 08:12:39.940356 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0804 08:12:41.247163 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0804 08:12:42.442007 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0804 08:12:43.711439 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0804 08:12:44.908875 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0804 08:12:46.190125 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0804 08:12:47.414173 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0804 08:12:48.697031 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0804 08:12:49.911628 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0804 08:12:51.185844 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0804 08:12:52.396373 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0804 08:12:53.668716 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0804 08:12:54.876891 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0804 08:12:54.877119 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0804 08:12:56.155245 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0804 08:12:56.156618 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0804 08:12:56.156687 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0804 08:12:56.156724 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0804 08:12:56.156758 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0804 08:12:56.156790 1 model_lifecycle.cc:459] loading: intent_ensemble:1
E0804 08:12:56.156818 1 model_repository_manager.cc:507] failed to load model 'pipeline_greedy_ensemble_EN': at least one version must be available under the version policy of model 'pipeline_greedy_ensemble_EN'
E0804 08:12:56.156837 1 model_repository_manager.cc:507] failed to load model 'pipeline_greedy_ensemble_HI': at least one version must be available under the version policy of model 'pipeline_greedy_ensemble_HI'
E0804 08:12:56.156851 1 model_repository_manager.cc:507] failed to load model 'pipeline_pyctc_ensemble_EN': at least one version must be available under the version policy of model 'pipeline_pyctc_ensemble_EN'
E0804 08:12:56.156865 1 model_repository_manager.cc:507] failed to load model 'pipeline_pyctc_ensemble_HI': at least one version must be available under the version policy of model 'pipeline_pyctc_ensemble_HI'
I0804 08:12:56.156887 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0804 08:12:56.156950 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0804 08:12:56.157050 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0804 08:12:56.157095 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0804 08:12:56.157376 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0804 08:12:56.157466 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0804 08:12:56.157515 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:12:56.157619 1 server.cc:633] 
+-----------------------------+---------+----------------------------------------+
| Model                       | Version | Status                                 |
+-----------------------------+---------+----------------------------------------+
| asr_am_EN                   | 1       | READY                                  |
| asr_am_HI                   | 1       | READY                                  |
| asr_greedy_decoder_EN       | 1       | READY                                  |
| asr_greedy_decoder_HI       | 1       | READY                                  |
| asr_greedy_ensemble_EN      | 1       | READY                                  |
| asr_greedy_ensemble_HI      | 1       | READY                                  |
| asr_greedy_top1             | 1       | READY                                  |
| asr_preprocessor            | 1       | READY                                  |
| asr_pyctc_decoder_EN        | 1       | READY                                  |
| asr_pyctc_decoder_HI        | 1       | READY                                  |
| asr_pyctc_ensemble_EN       | 1       | READY                                  |
| asr_pyctc_ensemble_HI       | 1       | READY                                  |
| entity_EN                   | 1       | READY                                  |
| entity_HI                   | 1       | READY                                  |
| intent_ensemble             | 1       | READY                                  |
| intent_model_onnx           | 1       | READY                                  |
| intent_postprocessor        | 1       | READY                                  |
| intent_preprocessor         | 1       | READY                                  |
| itn_EN                      | 1       | READY                                  |
| itn_HI                      | 1       | READY                                  |
| pipeline_greedy_ensemble_EN | -       | Not loaded: No model version was found |
| pipeline_greedy_ensemble_HI | -       | Not loaded: No model version was found |
| pipeline_pyctc_ensemble_EN  | -       | Not loaded: No model version was found |
| pipeline_pyctc_ensemble_HI  | -       | Not loaded: No model version was found |
+-----------------------------+---------+----------------------------------------+

I0804 08:12:56.172533 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0804 08:12:56.172742 1 metrics.cc:757] Collecting CPU metrics
I0804 08:12:56.172878 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:12:56.172902 1 server.cc:264] Waiting for in-flight requests to complete.
I0804 08:12:56.172931 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0804 08:12:56.173206 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0804 08:12:56.173485 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:12:56.173757 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:12:56.173833 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:12:56.174198 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_EN' version 1
I0804 08:12:56.174379 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_HI' version 1
I0804 08:12:56.174749 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0804 08:12:56.174957 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:12:56.175038 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:12:56.175316 1 server.cc:295] All models are stopped, unloading models
I0804 08:12:56.175339 1 server.cc:302] Timeout 30: Found 16 live models and 0 in-flight non-inference requests
I0804 08:12:56.175465 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0804 08:12:56.175531 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:12:56.175765 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:12:56.175982 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_top1' version 1
I0804 08:12:56.176012 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0804 08:12:56.185288 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:12:56.186135 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0804 08:12:56.193868 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:12:56.193888 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:12:56.194034 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0804 08:12:56.195522 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0804 08:12:57.175559 1 server.cc:302] Timeout 29: Found 10 live models and 0 in-flight non-inference requests
I0804 08:12:57.228854 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0804 08:12:57.307612 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0804 08:12:57.308635 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0804 08:12:57.365654 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0804 08:12:57.448732 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_HI' version 1
I0804 08:12:57.470408 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0804 08:12:57.505311 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_EN' version 1
I0804 08:12:57.656536 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0804 08:12:58.175812 1 server.cc:302] Timeout 28: Found 2 live models and 0 in-flight non-inference requests
I0804 08:12:59.175966 1 server.cc:302] Timeout 27: Found 2 live models and 0 in-flight non-inference requests
I0804 08:13:00.176118 1 server.cc:302] Timeout 26: Found 2 live models and 0 in-flight non-inference requests
I0804 08:13:01.176253 1 server.cc:302] Timeout 25: Found 2 live models and 0 in-flight non-inference requests
I0804 08:13:02.176404 1 server.cc:302] Timeout 24: Found 2 live models and 0 in-flight non-inference requests
I0804 08:13:03.176562 1 server.cc:302] Timeout 23: Found 2 live models and 0 in-flight non-inference requests
I0804 08:13:04.176726 1 server.cc:302] Timeout 22: Found 2 live models and 0 in-flight non-inference requests
I0804 08:13:05.176873 1 server.cc:302] Timeout 21: Found 2 live models and 0 in-flight non-inference requests
I0804 08:13:06.177023 1 server.cc:302] Timeout 20: Found 2 live models and 0 in-flight non-inference requests
I0804 08:13:06.590034 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0804 08:13:06.856129 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0804 08:13:07.177219 1 server.cc:302] Timeout 19: Found 0 live models and 0 in-flight non-inference requests
I0804 08:13:13.240273 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fb8ba000000' with size 268435456
I0804 08:13:13.240614 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:13:13.244389 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:13:13.244432 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:13:13.244462 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:13:13.244507 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:13:13.244537 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:13:13.244562 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:13:13.244607 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:13:13.244640 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:13:13.244706 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:13:13.244749 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:13:13.244778 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:13:13.244809 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:13:13.244833 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:13:13.244947 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:13:13.244978 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:13:13.589818 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:13:13.589863 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:13:13.589869 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:13:13.591524 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:13:13.592062 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:13:13.592488 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:13:13.592505 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:13:13.592510 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:13:13.592514 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:13:13.592541 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:13:13.592881 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:13:13.593369 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:13:13.593387 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:13:13.593393 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:13:13.593400 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:13:13.594924 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:13:13.594976 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:13:13.594985 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:13:13.594992 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:13:13.609253 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:13:15.891115 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:13:15.892343 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:13:17.485036 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:13:21.298707 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:13:21.299251 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:13:21.299761 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:13:21.299781 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:13:21.299789 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:13:21.299796 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:13:21.299867 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0804 08:13:21.300350 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 08:13:21.300857 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 08:13:21.300875 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 08:13:21.300883 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 08:13:21.300891 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 08:13:21.301228 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:13:24.984612 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:13:29.006329 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 08:13:29.006818 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 08:13:52.327213 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 08:13:53.144161 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0804 08:13:53.144347 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 08:13:53.913049 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 08:13:53.913222 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0804 08:13:53.914333 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0804 08:13:53.914621 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0804 08:13:53.917297 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 08:13:53.917553 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0804 08:13:55.213911 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0804 08:13:55.529983 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 08:13:55.530184 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0804 08:13:56.764004 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0804 08:13:59.630026 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0804 08:13:59.630212 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0804 08:14:00.671838 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 08:14:00.672289 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0804 08:14:00.959323 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0804 08:14:00.959482 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 08:14:02.944616 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 08:14:02.944753 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0804 08:14:05.793062 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 08:14:05.793241 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 08:14:20.973915 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0804 08:14:20.974555 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0804 08:14:22.365957 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0804 08:14:23.600494 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0804 08:14:24.959773 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0804 08:14:26.231598 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0804 08:14:27.555764 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0804 08:14:28.821649 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0804 08:14:30.157090 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0804 08:14:31.386103 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0804 08:14:32.713827 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0804 08:14:33.939622 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0804 08:14:35.249049 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0804 08:14:36.476324 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0804 08:14:37.775065 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0804 08:14:37.775391 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0804 08:14:39.000811 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0804 08:14:39.002201 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0804 08:14:39.002399 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0804 08:14:39.002474 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0804 08:14:39.002523 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0804 08:14:39.002567 1 model_lifecycle.cc:459] loading: intent_ensemble:1
E0804 08:14:39.002611 1 model_repository_manager.cc:507] failed to load model 'pipeline_greedy_ensemble_EN': at least one version must be available under the version policy of model 'pipeline_greedy_ensemble_EN'
I0804 08:14:39.002612 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0804 08:14:39.002662 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
E0804 08:14:39.002742 1 model_repository_manager.cc:507] failed to load model 'pipeline_greedy_ensemble_HI': at least one version must be available under the version policy of model 'pipeline_greedy_ensemble_HI'
E0804 08:14:39.002776 1 model_repository_manager.cc:507] failed to load model 'pipeline_pyctc_ensemble_EN': at least one version must be available under the version policy of model 'pipeline_pyctc_ensemble_EN'
I0804 08:14:39.002782 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0804 08:14:39.002851 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
E0804 08:14:39.002929 1 model_repository_manager.cc:507] failed to load model 'pipeline_pyctc_ensemble_HI': at least one version must be available under the version policy of model 'pipeline_pyctc_ensemble_HI'
I0804 08:14:39.003131 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0804 08:14:39.003221 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0804 08:14:39.003275 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:14:39.003370 1 server.cc:633] 
+-----------------------------+---------+----------------------------------------+
| Model                       | Version | Status                                 |
+-----------------------------+---------+----------------------------------------+
| asr_am_EN                   | 1       | READY                                  |
| asr_am_HI                   | 1       | READY                                  |
| asr_greedy_decoder_EN       | 1       | READY                                  |
| asr_greedy_decoder_HI       | 1       | READY                                  |
| asr_greedy_ensemble_EN      | 1       | READY                                  |
| asr_greedy_ensemble_HI      | 1       | READY                                  |
| asr_greedy_top1             | 1       | READY                                  |
| asr_preprocessor            | 1       | READY                                  |
| asr_pyctc_decoder_EN        | 1       | READY                                  |
| asr_pyctc_decoder_HI        | 1       | READY                                  |
| asr_pyctc_ensemble_EN       | 1       | READY                                  |
| asr_pyctc_ensemble_HI       | 1       | READY                                  |
| entity_EN                   | 1       | READY                                  |
| entity_HI                   | 1       | READY                                  |
| intent_ensemble             | 1       | READY                                  |
| intent_model_onnx           | 1       | READY                                  |
| intent_postprocessor        | 1       | READY                                  |
| intent_preprocessor         | 1       | READY                                  |
| itn_EN                      | 1       | READY                                  |
| itn_HI                      | 1       | READY                                  |
| pipeline_greedy_ensemble_EN | -       | Not loaded: No model version was found |
| pipeline_greedy_ensemble_HI | -       | Not loaded: No model version was found |
| pipeline_pyctc_ensemble_EN  | -       | Not loaded: No model version was found |
| pipeline_pyctc_ensemble_HI  | -       | Not loaded: No model version was found |
+-----------------------------+---------+----------------------------------------+

I0804 08:14:39.018583 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0804 08:14:39.018775 1 metrics.cc:757] Collecting CPU metrics
I0804 08:14:39.018889 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:14:39.018910 1 server.cc:264] Waiting for in-flight requests to complete.
I0804 08:14:39.018935 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0804 08:14:39.019239 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0804 08:14:39.019428 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:14:39.019645 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:14:39.019740 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_EN' version 1
I0804 08:14:39.019965 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:14:39.020057 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_HI' version 1
I0804 08:14:39.020312 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0804 08:14:39.020550 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:14:39.020767 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0804 08:14:39.020953 1 server.cc:295] All models are stopped, unloading models
I0804 08:14:39.020986 1 server.cc:302] Timeout 30: Found 16 live models and 0 in-flight non-inference requests
I0804 08:14:39.021190 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0804 08:14:39.021276 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:14:39.021696 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_top1' version 1
I0804 08:14:39.021947 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:14:39.022082 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0804 08:14:39.029290 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:14:39.029428 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0804 08:14:39.039098 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:14:39.040157 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0804 08:14:39.040203 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0804 08:14:39.040439 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0804 08:14:40.038671 1 server.cc:302] Timeout 29: Found 10 live models and 0 in-flight non-inference requests
I0804 08:22:14.333955 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fb8b2000000' with size 268435456
I0804 08:22:14.334335 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:22:14.339076 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:22:14.339121 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:22:14.339149 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:22:14.339213 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:22:14.339287 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:22:14.339465 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:22:14.339573 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:22:14.346460 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:22:14.346593 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:22:14.346701 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:22:14.346800 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:22:14.346896 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:22:14.346995 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:22:14.347107 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:22:14.354480 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:22:15.053076 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:22:15.053113 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:22:15.053133 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:22:19.538205 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:22:19.538635 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:22:19.539001 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:22:19.539017 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:22:19.539022 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:22:19.539026 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:22:19.539066 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:22:22.544224 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:22:22.545167 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:22:24.951581 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:22:24.952020 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:22:24.952426 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:22:24.952442 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:22:24.952447 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:22:24.952452 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:22:24.952499 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 08:22:24.953626 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
I0804 08:22:24.953872 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
W0804 08:22:24.954225 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 08:22:24.954824 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 08:22:24.954845 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 08:22:24.954852 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 08:22:24.954859 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 08:22:24.955487 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:22:29.967752 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0804 08:22:30.761499 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 08:22:30.761717 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0804 08:22:31.547516 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:22:31.548078 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:22:31.548268 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 08:22:31.548561 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:22:31.548579 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:22:31.548584 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:22:31.548588 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:22:31.548638 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 08:22:32.768244 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:22:32.768308 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:22:32.768327 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:22:32.768347 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:22:32.782366 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 08:22:34.072265 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0804 08:22:34.384200 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 08:22:34.384503 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0804 08:22:34.656174 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:22:34.656325 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 08:22:36.593181 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0804 08:22:36.594404 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:22:37.860504 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0804 08:22:37.863741 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 08:22:37.863881 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0804 08:22:37.880429 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 08:23:02.238579 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0804 08:23:03.591253 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0804 08:23:04.888453 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0804 08:23:06.314106 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 08:23:06.314380 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0804 08:23:12.815170 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0804 08:23:12.815477 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 08:23:15.060201 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 08:23:15.060369 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0804 08:23:31.516984 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0804 08:23:31.517119 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0804 08:23:35.117172 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0804 08:23:35.117481 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0804 08:23:36.631377 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0804 08:23:38.088295 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0804 08:23:39.633867 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0804 08:23:41.016135 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0804 08:23:42.480140 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0804 08:23:43.824256 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0804 08:23:45.267592 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0804 08:23:46.583280 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0804 08:23:48.048653 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0804 08:23:49.496340 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0804 08:23:49.496588 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0804 08:23:51.033308 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0804 08:23:51.034662 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0804 08:23:51.034729 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0804 08:23:51.034767 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0804 08:23:51.034802 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0804 08:23:51.034836 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0804 08:23:51.034875 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0804 08:23:51.034907 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0804 08:23:51.034941 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0804 08:23:51.034973 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0804 08:23:51.035001 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0804 08:23:51.035050 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0804 08:23:51.035112 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0804 08:23:51.035214 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0804 08:23:51.035525 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0804 08:23:51.035639 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0804 08:23:51.035738 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0804 08:23:51.035795 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0804 08:23:51.035832 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0804 08:23:51.035962 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0804 08:23:51.036024 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:23:51.036113 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
+-----------------------------+---------+--------+

I0804 08:23:51.056327 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0804 08:23:51.056556 1 metrics.cc:757] Collecting CPU metrics
I0804 08:23:51.056698 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:23:51.057994 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0804 08:23:51.058182 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0804 08:23:51.099462 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0804 08:50:13.550980 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f88fa000000' with size 268435456
I0804 08:50:13.551373 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:50:13.556609 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:50:13.556807 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:50:13.556954 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:50:13.557129 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:50:13.557258 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:50:13.557373 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:50:13.557496 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:50:13.557627 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:50:13.557791 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:50:13.557986 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:50:13.558130 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:50:13.558242 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:50:13.558352 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:50:13.558479 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:50:13.562566 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:50:14.169769 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:50:14.169829 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:50:14.169841 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:50:14.172556 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:50:14.173169 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:50:14.173640 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:50:14.173663 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:50:14.173673 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:50:14.173681 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:50:14.173711 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:50:14.174158 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:50:14.174640 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:50:14.174660 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:50:14.174665 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:50:14.174670 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:50:14.174711 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:50:17.599448 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:50:17.600217 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:50:20.341993 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 08:50:20.344635 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0804 08:50:20.345869 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:50:20.345922 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:50:20.345930 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:50:20.345934 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:50:20.356652 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:50:23.107369 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:50:23.108097 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:50:23.108599 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:50:23.108618 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:50:23.108624 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:50:23.108628 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:50:23.108706 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 08:50:24.466515 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0804 08:50:24.466978 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 08:50:24.467484 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 08:50:24.467501 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 08:50:24.467510 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 08:50:24.467519 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 08:50:36.153353 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 08:50:36.153758 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 08:50:56.641973 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 08:50:58.057619 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:51:00.013200 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0804 08:51:00.015325 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:51:01.390209 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0804 08:51:01.393533 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0804 08:51:01.393730 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0804 08:51:02.245995 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0804 08:51:02.246209 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0804 08:51:05.616964 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 08:51:05.617115 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0804 08:51:05.909374 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0804 08:51:05.909543 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 08:51:06.221180 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 08:51:06.221340 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0804 08:51:09.115334 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0804 08:51:09.115618 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 08:51:11.354395 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0804 08:51:11.354540 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0804 08:51:12.810087 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 08:51:12.810374 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0804 08:51:13.655075 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 08:51:13.655290 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 08:51:30.029806 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0804 08:51:30.029996 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0804 08:51:31.515090 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0804 08:51:32.898229 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0804 08:51:34.360195 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0804 08:51:35.742741 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0804 08:51:37.200474 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0804 08:51:38.670092 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0804 08:51:40.218285 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0804 08:51:41.650348 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0804 08:51:43.060785 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0804 08:51:44.370824 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0804 08:51:45.709508 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0804 08:51:46.980300 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0804 08:51:46.980555 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0804 08:51:48.312404 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0804 08:51:48.313790 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0804 08:51:48.313859 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0804 08:51:48.313898 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0804 08:51:48.313933 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0804 08:51:48.313967 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0804 08:51:48.314004 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0804 08:51:48.314033 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0804 08:51:48.314076 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0804 08:51:48.314127 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0804 08:51:48.314158 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0804 08:51:48.314206 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0804 08:51:48.314478 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0804 08:51:48.314539 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0804 08:51:48.314755 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0804 08:51:48.314820 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0804 08:51:48.314837 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0804 08:51:48.314884 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0804 08:51:48.314911 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0804 08:51:48.315005 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0804 08:51:48.315056 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:51:48.315143 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
+-----------------------------+---------+--------+

I0804 08:51:48.330127 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0804 08:51:48.330323 1 metrics.cc:757] Collecting CPU metrics
I0804 08:51:48.330487 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 08:51:48.331562 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0804 08:51:48.331752 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0804 08:51:48.372991 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0804 08:55:55.482934 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fe4b6000000' with size 268435456
I0804 08:55:55.483399 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:55:55.490417 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:55:55.490681 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:55:55.490852 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:55:55.491032 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:55:55.491194 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:55:55.491354 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:55:55.491535 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:55:55.491718 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:55:55.491895 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:55:55.492109 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:55:55.492275 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:55:55.492434 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:55:55.492596 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:55:55.492762 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:55:55.493098 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:55:56.092230 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:55:56.092276 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:55:56.092283 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:55:56.095849 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:55:56.095911 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:55:56.095926 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:55:56.095934 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:55:58.354380 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:55:58.355058 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:55:58.355526 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:55:58.355617 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:55:58.355689 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:55:58.355760 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:55:58.355875 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:55:58.356345 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:55:58.356780 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:55:58.356800 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:55:58.356807 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:55:58.356815 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:56:01.234634 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:56:03.587538 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:56:03.588057 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:56:03.588569 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:56:03.588589 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:56:03.588597 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:56:03.588604 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:56:03.589164 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:56:24.799451 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 08:56:24.800070 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 08:56:24.800845 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0804 08:56:24.801284 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 08:56:24.801832 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 08:56:24.801851 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 08:56:24.801859 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 08:56:24.801866 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 08:56:31.713066 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 08:56:32.490735 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:56:32.490887 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 08:56:35.088852 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:56:35.090084 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:56:36.954274 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 08:56:36.955428 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:56:37.240637 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 08:56:37.242145 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 08:56:40.856023 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 08:56:40.856191 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 08:56:42.062528 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0804 08:56:43.294724 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 08:56:44.604670 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 08:57:02.538881 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f550a000000' with size 268435456
I0804 08:57:02.539327 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:57:02.545325 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:57:02.545565 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:57:02.545715 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:57:02.545860 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:57:02.546001 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:57:02.546162 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:57:02.546377 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:57:02.546542 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:57:02.546709 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:57:02.546869 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:57:02.547014 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:57:02.547150 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:57:02.547282 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:57:02.547428 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:57:02.547571 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:57:03.096573 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:57:03.096621 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:57:03.096627 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:57:03.098355 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:57:03.098973 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:57:03.099480 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:57:03.099495 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:57:03.099499 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:57:03.099504 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:57:03.101213 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:57:03.101259 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:57:03.101274 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:57:03.101281 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:57:03.116934 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:57:06.003618 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:57:07.937129 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0804 08:57:07.937585 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 08:57:07.938012 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 08:57:07.938027 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 08:57:07.938032 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 08:57:07.938036 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 08:57:09.896005 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:57:12.296766 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:57:12.297297 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:57:12.297811 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:57:12.297829 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:57:12.297836 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:57:12.297842 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:57:13.617437 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:57:16.039966 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 08:57:16.040537 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 08:57:34.255868 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:57:34.256428 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:57:34.256903 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:57:34.256920 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:57:34.256925 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:57:34.256930 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:57:42.303066 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 08:57:43.107243 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0804 08:57:43.107411 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 08:57:43.111028 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0804 08:57:43.111262 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0804 08:57:43.925680 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 08:57:43.925886 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0804 08:57:45.165827 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 08:57:45.167268 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0804 08:57:45.167520 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0804 08:57:45.497977 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 08:57:45.498087 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0804 08:57:46.816256 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0804 08:57:47.960580 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 08:57:47.960882 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0804 08:58:03.434659 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:58:03.434827 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0804 08:58:05.177977 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 08:58:05.179722 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:58:05.487520 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 08:58:05.487684 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 08:58:08.067487 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0804 08:58:08.067647 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 08:58:10.250157 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0804 08:58:10.250326 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0804 08:58:12.844797 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0804 08:58:12.844950 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0804 08:58:14.114699 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0804 08:58:15.512436 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0804 08:58:23.939886 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7efd4a000000' with size 268435456
I0804 08:58:23.940233 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:58:23.944182 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:58:23.944227 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:58:23.944257 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:58:23.944315 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:58:23.944358 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:58:23.944406 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:58:23.944433 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:58:23.944462 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:58:23.944501 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:58:23.944538 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:58:23.944560 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:58:23.944581 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:58:23.944605 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:58:23.944627 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:58:23.944708 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:58:24.419630 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:58:24.419680 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:58:24.419687 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:58:24.419864 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:58:24.420343 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:58:24.420715 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:58:24.420730 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:58:24.420735 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:58:24.420739 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:58:24.420774 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:58:27.159209 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:58:27.159661 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:58:27.160087 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:58:27.160104 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:58:27.160108 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:58:27.160113 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:58:27.160148 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:58:27.190141 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:58:28.861746 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:58:28.861798 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:58:28.861803 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:58:28.861816 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:58:28.862443 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:58:30.795196 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:58:30.795638 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:58:30.796012 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:58:30.796027 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:58:30.796033 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:58:30.796037 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:58:30.796399 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:58:33.196704 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0804 08:58:33.197140 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 08:58:33.197605 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 08:58:33.197622 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 08:58:33.197627 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 08:58:33.197632 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 08:58:33.198095 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:58:40.209452 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 08:58:40.210054 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 08:59:04.883136 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0804 08:59:05.745414 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 08:59:05.745624 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0804 08:59:05.746869 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 08:59:05.747161 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0804 08:59:07.099423 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0804 08:59:07.102909 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 08:59:07.103138 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0804 08:59:08.461734 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 08:59:08.785178 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0804 08:59:08.785332 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 08:59:09.115026 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 08:59:09.115152 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0804 08:59:09.978463 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0804 08:59:09.978672 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 08:59:11.172531 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 08:59:11.172798 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0804 08:59:14.211649 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0804 08:59:14.211796 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 08:59:17.647926 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 08:59:17.648089 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0804 08:59:39.991611 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fd1dc000000' with size 268435456
I0804 08:59:39.991954 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 08:59:39.996036 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 08:59:39.996243 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 08:59:39.996357 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 08:59:39.996491 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 08:59:39.996605 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 08:59:39.996716 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 08:59:39.996831 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 08:59:39.996943 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 08:59:39.997056 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 08:59:39.997195 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 08:59:39.997307 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 08:59:39.997410 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 08:59:39.997513 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 08:59:39.997619 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 08:59:39.997738 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 08:59:40.637940 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 08:59:40.638005 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 08:59:40.638014 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 08:59:40.640463 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 08:59:40.641066 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 08:59:40.641517 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 08:59:40.641532 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 08:59:40.641537 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 08:59:40.641541 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 08:59:40.641567 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 08:59:40.642028 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 08:59:40.642545 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 08:59:40.642568 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 08:59:40.642576 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 08:59:40.642584 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 08:59:40.644483 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 08:59:40.644541 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 08:59:40.644555 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 08:59:40.644562 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 08:59:40.659716 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 08:59:43.671218 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 08:59:43.672542 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 08:59:45.553114 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 08:59:49.440430 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 08:59:49.440786 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 08:59:49.441140 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 08:59:49.441156 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 08:59:49.441161 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 08:59:49.441165 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 08:59:49.441211 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 08:59:49.442494 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0804 08:59:49.442657 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 08:59:52.180817 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 09:16:20.669689 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f0b46000000' with size 268435456
I0804 09:16:20.670046 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0804 09:16:20.674034 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0804 09:16:20.674080 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0804 09:16:20.674131 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0804 09:16:20.674178 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0804 09:16:20.674208 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0804 09:16:20.674246 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0804 09:16:20.674275 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0804 09:16:20.674301 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0804 09:16:20.674325 1 model_lifecycle.cc:459] loading: entity_EN:1
I0804 09:16:20.674353 1 model_lifecycle.cc:459] loading: entity_HI:1
I0804 09:16:20.674382 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0804 09:16:20.674406 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0804 09:16:20.674442 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0804 09:16:20.674498 1 model_lifecycle.cc:459] loading: itn_EN:1
I0804 09:16:20.674560 1 model_lifecycle.cc:459] loading: itn_HI:1
I0804 09:16:21.138706 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0804 09:16:21.138754 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0804 09:16:21.138762 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0804 09:16:21.138929 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0804 09:16:21.139408 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0804 09:16:21.139874 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0804 09:16:21.139889 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0804 09:16:21.139894 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0804 09:16:21.139898 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0804 09:16:21.139935 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0804 09:16:24.006941 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0804 09:16:24.007350 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0804 09:16:24.007795 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0804 09:16:24.007812 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0804 09:16:24.007816 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0804 09:16:24.007821 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0804 09:16:24.009448 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0804 09:16:24.009500 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0804 09:16:24.009508 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0804 09:16:24.009514 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0804 09:16:24.038345 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0804 09:16:27.902626 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0804 09:16:27.903147 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0804 09:16:27.903705 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0804 09:16:27.903726 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0804 09:16:27.903733 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0804 09:16:27.903741 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0804 09:16:27.903815 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0804 09:16:27.904200 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0804 09:16:27.904604 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0804 09:16:27.904620 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0804 09:16:27.904625 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0804 09:16:27.904629 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0804 09:16:27.905099 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 09:16:30.326180 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0804 09:16:32.042445 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0804 09:16:32.042908 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0804 09:16:32.044512 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0804 09:16:39.796899 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0804 09:17:01.808053 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0804 09:17:02.644142 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0804 09:17:02.644303 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0804 09:17:03.494906 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0804 09:17:03.495083 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0804 09:17:03.499323 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0804 09:17:03.499570 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0804 09:17:03.500578 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0804 09:17:03.500815 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0804 09:17:04.789745 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0804 09:17:05.878491 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0804 09:17:05.878786 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0804 09:17:08.812158 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0804 09:17:08.812279 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0804 09:17:09.133440 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0804 09:17:09.133615 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0804 09:17:09.465890 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0804 09:17:09.466092 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0804 09:17:11.643951 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0804 09:17:11.644114 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0804 09:17:12.973435 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0804 09:17:28.103207 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0804 09:17:28.103364 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0804 09:17:31.450207 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0804 09:17:31.450342 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0804 09:17:32.828695 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0804 09:17:34.273108 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0804 09:17:35.631426 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0804 09:17:37.070502 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0804 09:17:38.432878 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0804 09:17:39.863592 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0804 09:17:41.274276 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0804 09:17:42.739559 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0804 09:17:44.188188 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0804 09:17:45.638322 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0804 09:17:46.972698 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0804 09:17:48.391927 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0804 09:17:49.732732 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0804 09:17:49.732922 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0804 09:17:51.199021 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0804 09:17:51.201192 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0804 09:17:51.201270 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0804 09:17:51.201314 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0804 09:17:51.201363 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0804 09:17:51.201406 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0804 09:17:51.201457 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0804 09:17:51.201509 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0804 09:17:51.201560 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0804 09:17:51.201615 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0804 09:17:51.202194 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0804 09:17:51.202274 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0804 09:17:51.202311 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0804 09:17:51.202345 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0804 09:17:51.202374 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0804 09:17:51.202393 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0804 09:17:51.202408 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0804 09:17:51.202452 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0804 09:17:51.202550 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0804 09:17:51.202702 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0804 09:17:51.202766 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 09:17:51.202925 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
+-----------------------------+---------+--------+

I0804 09:17:51.220988 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0804 09:17:51.221264 1 metrics.cc:757] Collecting CPU metrics
I0804 09:17:51.221427 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0804 09:17:51.222703 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0804 09:17:51.222943 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0804 09:17:51.264251 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0805 08:28:42.417567 1 server.cc:264] Waiting for in-flight requests to complete.
I0805 08:28:42.417777 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0805 08:28:42.418131 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_HI' version 1
I0805 08:28:42.418164 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_EN' version 1
I0805 08:28:42.418201 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0805 08:28:42.418659 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0805 08:28:42.418810 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0805 08:28:42.418872 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0805 08:28:42.419253 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0805 08:28:42.419300 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0805 08:28:42.419437 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_EN' version 1
I0805 08:28:42.419715 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_HI' version 1
I0805 08:28:42.419801 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0805 08:28:42.420076 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0805 08:28:42.420116 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0805 08:28:42.420523 1 server.cc:295] All models are stopped, unloading models
I0805 08:28:42.420560 1 server.cc:302] Timeout 30: Found 16 live models and 0 in-flight non-inference requests
I0805 08:28:42.422939 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0805 08:28:42.423895 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0805 08:28:42.424040 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_top1' version 1
I0805 08:28:42.424357 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0805 08:28:42.424504 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0805 08:28:42.431291 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0805 08:28:42.431466 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0805 08:28:42.432792 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0805 08:28:42.432945 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0805 08:28:42.445900 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0805 08:28:42.446022 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0805 08:28:43.431315 1 server.cc:302] Timeout 29: Found 10 live models and 0 in-flight non-inference requests
I0805 08:28:43.529685 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0805 08:28:43.531179 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_HI' version 1
I0805 08:28:43.676684 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0805 08:28:43.683155 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0805 08:28:43.697713 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_EN' version 1
I0805 08:28:43.732771 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0805 08:28:43.744860 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0805 08:28:43.755786 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0805 08:28:44.432163 1 server.cc:302] Timeout 28: Found 2 live models and 0 in-flight non-inference requests
I0805 08:28:45.432433 1 server.cc:302] Timeout 27: Found 2 live models and 0 in-flight non-inference requests
I0805 08:28:46.432562 1 server.cc:302] Timeout 26: Found 2 live models and 0 in-flight non-inference requests
I0806 20:10:07.095581 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fd3d6000000' with size 268435456
I0806 20:10:07.096359 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0806 20:10:07.105058 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0806 20:10:07.105123 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0806 20:10:07.105158 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0806 20:10:07.105211 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0806 20:10:07.105256 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0806 20:10:07.105297 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0806 20:10:07.105335 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0806 20:10:07.105373 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0806 20:10:07.105424 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0806 20:10:07.105502 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0806 20:10:07.105547 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0806 20:10:07.105584 1 model_lifecycle.cc:459] loading: entity_EN:1
I0806 20:10:07.105616 1 model_lifecycle.cc:459] loading: entity_HI:1
W0806 20:10:07.106663 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0806 20:10:07.106706 1 model_lifecycle.cc:459] loading: entity_TA:1
I0806 20:10:07.106767 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0806 20:10:07.106811 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0806 20:10:07.106859 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0806 20:10:07.106911 1 model_lifecycle.cc:459] loading: itn_EN:1
I0806 20:10:07.106977 1 model_lifecycle.cc:459] loading: itn_HI:1
W0806 20:10:07.107376 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0806 20:10:07.107397 1 model_lifecycle.cc:459] loading: itn_TA:1
I0806 20:10:07.557033 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0806 20:10:07.557081 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0806 20:10:07.557089 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0806 20:10:07.557280 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0806 20:10:07.557914 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0806 20:10:07.558520 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0806 20:10:07.558541 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0806 20:10:07.558549 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0806 20:10:07.558557 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0806 20:10:07.558604 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0_0 (GPU device 0)
I0806 20:10:10.578245 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0_1 (GPU device 0)
I0806 20:10:12.412048 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0806 20:10:12.412746 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0806 20:10:12.413292 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0806 20:10:12.413313 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0806 20:10:12.413321 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0806 20:10:12.413328 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0806 20:10:12.413384 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0_0 (GPU device 0)
I0806 20:10:12.413986 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0806 20:10:20.246957 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0806 20:10:22.956433 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0806 20:10:25.368708 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0806 20:10:30.455739 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0806 20:10:30.456172 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0806 20:10:30.456579 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0806 20:10:30.456596 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0806 20:10:30.456601 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0806 20:10:30.456605 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0806 20:10:31.790578 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0806 20:10:31.791029 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0806 20:10:31.791456 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0806 20:10:31.791484 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0806 20:10:31.791489 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0806 20:10:31.791493 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0806 20:10:31.791533 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0806 20:10:31.791875 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0806 20:10:31.792242 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0806 20:10:31.792258 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0806 20:10:31.792262 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0806 20:10:31.792266 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0806 20:10:31.795663 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0806 20:10:31.795719 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0806 20:10:31.795729 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0806 20:10:31.795734 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0806 20:10:31.804849 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0_0 (CPU device 0)
I0806 20:10:32.630066 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0_0 (CPU device 0)
I0806 20:10:33.454536 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0_0 (CPU device 0)
I0806 20:10:34.286328 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0806 20:10:35.556972 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0806 20:10:36.864879 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0806 20:10:38.100418 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0_0 (CPU device 0)
I0806 20:10:38.397909 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0_0 (CPU device 0)
I0806 20:10:38.719701 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0_0 (GPU device 0)
I0806 20:10:38.723259 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0_0 (CPU device 0)
I0806 20:10:39.006053 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0_0 (GPU device 0)
I0806 20:10:39.007293 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0_0 (GPU device 0)
I0806 20:10:40.988758 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0_1 (GPU device 0)
I0806 20:10:42.842808 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0806 20:10:42.843496 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0806 20:10:42.844111 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0_0 (GPU device 0)
I0806 20:10:42.844272 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0806 20:11:18.917844 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0_1 (CPU device 0)
I0806 20:11:19.765077 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0_1 (CPU device 0)
I0806 20:11:19.765295 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0806 20:11:20.620484 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0_1 (CPU device 0)
I0806 20:11:20.620653 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0806 20:11:21.481731 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0806 20:11:21.481880 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0806 20:11:22.755995 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0806 20:11:24.095415 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0806 20:11:25.475102 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0_1 (CPU device 0)
I0806 20:11:25.795232 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0_1 (CPU device 0)
I0806 20:11:25.795447 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0806 20:11:26.161126 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0_1 (GPU device 0)
I0806 20:11:26.161244 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0806 20:11:26.165575 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0_1 (CPU device 0)
I0806 20:11:26.165873 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0806 20:11:26.491560 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0_1 (GPU device 0)
I0806 20:11:26.491887 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0806 20:11:26.493283 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0_1 (GPU device 0)
I0806 20:11:26.493551 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0806 20:11:28.359788 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0806 20:11:30.056801 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0_1 (GPU device 0)
I0806 20:11:30.321762 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0_0 (CPU device 0)
I0806 20:11:30.322090 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0806 20:11:36.844593 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0_0 (CPU device 0)
I0806 20:11:39.058677 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0_0 (CPU device 0)
I0806 20:11:54.633108 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0_0 (CPU device 0)
I0806 20:12:05.763070 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0806 20:12:07.085225 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0806 20:12:08.481711 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0806 20:12:09.791630 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0_0 (CPU device 0)
I0806 20:12:13.685382 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0_1 (CPU device 0)
I0806 20:12:16.299117 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0_1 (CPU device 0)
I0806 20:12:16.299245 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0806 20:12:18.473732 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0_1 (CPU device 0)
I0806 20:12:18.473910 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0806 20:12:33.605599 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0_1 (CPU device 0)
I0806 20:12:33.605809 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0806 20:12:44.469274 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0806 20:12:44.469438 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0806 20:12:45.821382 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0806 20:12:47.217629 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0806 20:12:48.541959 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0_1 (CPU device 0)
I0806 20:12:52.029717 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0806 20:12:52.029865 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0806 20:12:53.334775 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0806 20:12:54.715017 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0806 20:12:56.014540 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0806 20:12:57.309150 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0806 20:12:58.705583 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0806 20:13:00.025352 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0806 20:13:01.308606 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0806 20:13:02.699622 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0806 20:13:03.986391 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0806 20:13:05.384463 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0806 20:13:05.384771 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0806 20:13:06.780877 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0806 20:13:06.781064 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0806 20:13:08.058878 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0806 20:13:08.060794 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0806 20:13:08.060867 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0806 20:13:08.060904 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0806 20:13:08.060935 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0806 20:13:08.060966 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0806 20:13:08.060994 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0806 20:13:08.061023 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0806 20:13:08.061056 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0806 20:13:08.061089 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0806 20:13:08.061124 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0806 20:13:08.061160 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0806 20:13:08.061191 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0806 20:13:08.061568 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0806 20:13:08.061645 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0806 20:13:08.061727 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0806 20:13:08.061751 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0806 20:13:08.061797 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0806 20:13:08.061943 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0806 20:13:08.062032 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0806 20:13:08.062133 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0806 20:13:08.062229 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0806 20:13:08.062310 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0806 20:13:08.062334 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0806 20:13:08.062464 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0806 20:13:08.062618 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0806 20:13:08.062666 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0806 20:13:08.062792 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0806 20:13:08.062836 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0806 20:13:08.062938 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0806 20:13:08.078504 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0806 20:13:08.078728 1 metrics.cc:757] Collecting CPU metrics
I0806 20:13:08.078871 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0806 20:13:08.079888 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0806 20:13:08.080087 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0806 20:13:08.121770 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0810 11:54:18.866939 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fe0fc000000' with size 268435456
I0810 11:54:18.867274 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0810 11:54:18.872834 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0810 11:54:18.872870 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0810 11:54:18.872893 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0810 11:54:18.872918 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0810 11:54:18.872966 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0810 11:54:18.872996 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0810 11:54:18.873018 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0810 11:54:18.873044 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0810 11:54:18.873183 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0810 11:54:18.873231 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0810 11:54:18.873261 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0810 11:54:18.873283 1 model_lifecycle.cc:459] loading: entity_EN:1
I0810 11:54:18.873304 1 model_lifecycle.cc:459] loading: entity_HI:1
W0810 11:54:18.873540 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0810 11:54:18.873559 1 model_lifecycle.cc:459] loading: entity_TA:1
I0810 11:54:18.873613 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0810 11:54:18.873651 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0810 11:54:18.873690 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0810 11:54:18.874583 1 model_lifecycle.cc:459] loading: itn_EN:1
I0810 11:54:18.874616 1 model_lifecycle.cc:459] loading: itn_HI:1
W0810 11:54:18.874654 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0810 11:54:18.874661 1 model_lifecycle.cc:459] loading: itn_TA:1
I0810 11:54:19.289715 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0810 11:54:19.289748 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0810 11:54:19.289754 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0810 11:54:19.292318 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0810 11:54:19.292955 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0810 11:54:19.293366 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0810 11:54:19.293374 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0810 11:54:19.293377 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0810 11:54:19.293380 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0810 11:54:19.296061 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0810 11:54:19.296087 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0810 11:54:19.296100 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0810 11:54:19.296104 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0810 11:54:19.307514 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0810 11:54:22.925611 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0810 11:54:25.160548 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0810 11:54:25.160945 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0810 11:54:25.161361 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0810 11:54:25.161379 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0810 11:54:25.161383 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0810 11:54:25.161386 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0810 11:54:25.161411 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0810 11:54:25.164685 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
I0810 11:54:25.164883 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
W0810 11:54:25.165095 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0810 11:54:25.165501 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0810 11:54:25.165508 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0810 11:54:25.165512 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0810 11:54:25.165516 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0810 11:54:27.096673 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0810 11:54:27.097228 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0810 11:54:27.097774 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0810 11:54:27.097785 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0810 11:54:27.097790 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0810 11:54:27.097796 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0810 11:54:27.098215 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 11:54:29.850422 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 11:54:35.563534 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 11:54:40.664128 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0810 11:54:40.664715 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0810 11:55:19.119311 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0810 11:55:19.983176 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
I0810 11:55:19.983339 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
W0810 11:55:19.983672 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0810 11:55:19.984168 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0810 11:55:19.984178 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0810 11:55:19.984184 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0810 11:55:19.984191 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0810 11:55:19.984254 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0810 11:55:22.237713 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0810 11:55:22.238993 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0810 11:55:23.086981 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0810 11:55:23.087184 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0810 11:55:25.447093 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0810 11:55:25.448266 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0810 11:55:26.849382 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0810 11:55:28.129004 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0810 11:55:28.970278 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0810 11:55:28.970504 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0810 11:55:29.306526 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0810 11:55:29.306754 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0810 11:55:30.587559 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0810 11:55:30.889990 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0810 11:55:30.890187 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0810 11:55:31.175337 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0810 11:55:31.175492 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0810 11:55:32.936248 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0810 11:55:32.936482 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0810 11:55:36.594894 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0810 11:55:36.595075 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0810 11:55:40.597327 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0810 11:55:40.597491 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0810 11:55:42.906045 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0810 11:55:42.906195 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0810 11:55:59.197715 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0810 11:55:59.197879 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0810 11:56:10.654474 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0810 11:56:10.654669 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0810 11:56:10.655619 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0810 11:56:10.655866 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0810 11:56:12.162821 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0810 11:56:13.641179 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0810 11:56:15.137963 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0810 11:56:16.690637 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0810 11:56:18.168488 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0810 11:56:19.636026 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0810 11:56:21.060211 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0810 11:56:22.460783 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0810 11:56:23.871901 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0810 11:56:25.406310 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0810 11:56:26.820700 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0810 11:56:28.123860 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0810 11:56:29.527978 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0810 11:56:30.934281 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0810 11:56:32.433098 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0810 11:56:33.911078 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0810 11:56:35.361134 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0810 11:56:36.794149 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0810 11:56:38.235690 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0810 11:56:38.235930 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0810 11:56:39.562024 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0810 11:56:39.562236 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0810 11:56:40.926796 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0810 11:56:40.929581 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0810 11:56:40.929665 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0810 11:56:40.929708 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0810 11:56:40.929747 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0810 11:56:40.929786 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0810 11:56:40.929832 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0810 11:56:40.929877 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0810 11:56:40.929924 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0810 11:56:40.929948 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0810 11:56:40.930007 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0810 11:56:40.930064 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0810 11:56:40.930119 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0810 11:56:40.930168 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0810 11:56:40.930214 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0810 11:56:40.930398 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0810 11:56:40.930462 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0810 11:56:40.930516 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0810 11:56:40.930569 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0810 11:56:40.930650 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0810 11:56:40.930693 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0810 11:56:40.930738 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0810 11:56:40.930836 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0810 11:56:40.930867 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0810 11:56:40.930941 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0810 11:56:40.931032 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0810 11:56:40.931107 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0810 11:56:40.931238 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0810 11:56:40.931297 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0810 11:56:40.931476 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0810 11:56:40.949294 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0810 11:56:40.949540 1 metrics.cc:757] Collecting CPU metrics
I0810 11:56:40.949719 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0810 11:56:40.951013 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0810 11:56:40.951253 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0810 11:56:40.992722 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0810 12:01:35.464874 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f06dc000000' with size 268435456
I0810 12:01:35.465234 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0810 12:01:35.470703 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0810 12:01:35.470742 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0810 12:01:35.470775 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0810 12:01:35.470802 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0810 12:01:35.470849 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0810 12:01:35.470879 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0810 12:01:35.470901 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0810 12:01:35.470927 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0810 12:01:35.470952 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0810 12:01:35.471028 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0810 12:01:35.471057 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0810 12:01:35.471080 1 model_lifecycle.cc:459] loading: entity_EN:1
I0810 12:01:35.471104 1 model_lifecycle.cc:459] loading: entity_HI:1
W0810 12:01:35.471462 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0810 12:01:35.471494 1 model_lifecycle.cc:459] loading: entity_TA:1
I0810 12:01:35.471561 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0810 12:01:35.471590 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0810 12:01:35.471640 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0810 12:01:35.472404 1 model_lifecycle.cc:459] loading: itn_EN:1
I0810 12:01:35.472440 1 model_lifecycle.cc:459] loading: itn_HI:1
W0810 12:01:35.472493 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0810 12:01:35.472502 1 model_lifecycle.cc:459] loading: itn_TA:1
I0810 12:01:35.826109 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0810 12:01:35.826139 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0810 12:01:35.826145 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0810 12:01:35.827927 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0810 12:01:35.828469 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0810 12:01:35.828922 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0810 12:01:35.828934 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0810 12:01:35.828940 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0810 12:01:35.828947 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0810 12:01:35.828971 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0810 12:01:35.829299 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0810 12:01:35.829651 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0810 12:01:35.829659 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0810 12:01:35.829662 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0810 12:01:35.829665 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0810 12:01:35.831186 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0810 12:01:35.831206 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0810 12:01:35.831215 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0810 12:01:35.831218 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0810 12:01:35.840902 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0810 12:01:38.351160 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0810 12:01:38.352356 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0810 12:01:40.183141 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0810 12:01:42.142148 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0810 12:01:42.142710 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0810 12:01:42.143122 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0810 12:01:42.143130 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0810 12:01:42.143134 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0810 12:01:42.143137 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0810 12:01:48.729165 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 12:01:51.160283 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0810 12:01:51.160867 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0810 12:01:51.161374 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0810 12:01:51.161385 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0810 12:01:51.161391 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0810 12:01:51.161397 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0810 12:01:51.161952 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 12:01:53.586105 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 12:01:56.019502 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0810 12:01:56.019949 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0810 12:01:56.020435 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0810 12:01:56.020445 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0810 12:01:56.020449 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0810 12:01:56.020453 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0810 12:02:04.143298 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0810 12:02:04.143762 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0810 12:02:34.597966 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0810 12:02:35.449421 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0810 12:02:35.449580 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0810 12:02:37.258691 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0810 12:02:37.259931 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0810 12:02:38.107471 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0810 12:02:38.107671 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0810 12:02:38.976327 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0810 12:02:38.976640 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0810 12:02:39.287081 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0810 12:02:39.287212 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0810 12:02:39.640329 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0810 12:02:39.640544 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0810 12:02:40.944517 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0810 12:02:40.945980 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0810 12:02:40.946268 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0810 12:02:42.235722 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0810 12:02:43.594041 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0810 12:02:43.597709 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0810 12:02:43.597901 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0810 12:02:43.894559 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0810 12:02:43.894725 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0810 12:02:47.254220 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0810 12:02:47.254353 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0810 12:02:50.359724 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0810 12:02:50.359869 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0810 12:02:52.575859 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0810 12:02:52.575958 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0810 12:02:53.687511 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0810 12:02:53.687802 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0810 12:03:09.347505 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0810 12:03:09.347724 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0810 12:03:20.594689 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0810 12:03:20.594841 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0810 12:03:21.911284 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0810 12:03:23.218860 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0810 12:03:24.608161 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0810 12:03:25.959189 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0810 12:03:27.263220 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0810 12:03:28.640745 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0810 12:03:29.933139 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0810 12:03:31.232897 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0810 12:03:32.610708 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0810 12:03:33.909318 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0810 12:03:35.216382 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0810 12:03:36.643874 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0810 12:03:37.991904 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0810 12:03:39.289483 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0810 12:03:40.664406 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0810 12:03:41.976390 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0810 12:03:43.282233 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0810 12:03:44.645057 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0810 12:03:45.903252 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0810 12:03:45.903473 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0810 12:03:47.179209 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0810 12:03:47.179576 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0810 12:03:48.535659 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0810 12:03:48.537525 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0810 12:03:48.537581 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0810 12:03:48.537694 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0810 12:03:48.537740 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0810 12:03:48.537770 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0810 12:03:48.537798 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0810 12:03:48.537842 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0810 12:03:48.537946 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0810 12:03:48.538020 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0810 12:03:48.538079 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0810 12:03:48.538116 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0810 12:03:48.538166 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0810 12:03:48.538204 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0810 12:03:48.538251 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0810 12:03:48.538318 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0810 12:03:48.538403 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0810 12:03:48.538448 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0810 12:03:48.538497 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0810 12:03:48.538553 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0810 12:03:48.538605 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0810 12:03:48.538656 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0810 12:03:48.538697 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0810 12:03:48.538884 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0810 12:03:48.538935 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0810 12:03:48.538961 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0810 12:03:48.539014 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0810 12:03:48.539124 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0810 12:03:48.539165 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0810 12:03:48.539283 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0810 12:03:48.554636 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0810 12:03:48.554832 1 metrics.cc:757] Collecting CPU metrics
I0810 12:03:48.554951 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0810 12:03:48.556002 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0810 12:03:48.556177 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0810 12:03:48.597474 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0810 12:05:30.714649 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f479a000000' with size 268435456
I0810 12:05:30.714967 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0810 12:05:30.719816 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0810 12:05:30.719857 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0810 12:05:30.719879 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0810 12:05:30.719907 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0810 12:05:30.719952 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0810 12:05:30.719986 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0810 12:05:30.720012 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0810 12:05:30.720051 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0810 12:05:30.720081 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0810 12:05:30.720115 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0810 12:05:30.720138 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0810 12:05:30.720159 1 model_lifecycle.cc:459] loading: entity_EN:1
I0810 12:05:30.720177 1 model_lifecycle.cc:459] loading: entity_HI:1
W0810 12:05:30.720477 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0810 12:05:30.720496 1 model_lifecycle.cc:459] loading: entity_TA:1
I0810 12:05:30.720544 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0810 12:05:30.720576 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0810 12:05:30.720604 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0810 12:05:30.720673 1 model_lifecycle.cc:459] loading: itn_EN:1
I0810 12:05:30.720697 1 model_lifecycle.cc:459] loading: itn_HI:1
W0810 12:05:30.720736 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0810 12:05:30.720742 1 model_lifecycle.cc:459] loading: itn_TA:1
I0810 12:05:31.075875 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0810 12:05:31.075907 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0810 12:05:31.075913 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0810 12:05:31.078471 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0810 12:05:31.078963 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0810 12:05:31.079325 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0810 12:05:31.079333 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0810 12:05:31.079336 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0810 12:05:31.079339 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0810 12:05:31.079369 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0810 12:05:31.079754 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0810 12:05:31.080245 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0810 12:05:31.080255 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0810 12:05:31.080261 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0810 12:05:31.080267 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0810 12:05:31.080299 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0810 12:05:31.080549 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0810 12:05:31.080867 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0810 12:05:31.080876 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0810 12:05:31.080879 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0810 12:05:31.080882 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0810 12:05:31.082202 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0810 12:05:31.082237 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0810 12:05:31.082241 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0810 12:05:31.082245 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0810 12:05:31.091741 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0810 12:05:33.596842 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0810 12:05:33.597978 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0810 12:05:35.422235 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0810 12:05:35.423669 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0810 12:05:37.150236 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0810 12:05:43.034869 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 12:05:45.791428 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0810 12:05:45.791930 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0810 12:05:45.792355 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0810 12:05:45.792364 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0810 12:05:45.792377 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0810 12:05:45.792382 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0810 12:05:47.142742 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 12:05:49.604265 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0810 12:05:53.382549 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0810 12:05:53.382955 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0810 12:05:53.383385 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0810 12:05:53.383393 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0810 12:05:53.383397 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0810 12:05:53.383401 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0810 12:05:56.425460 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0810 12:05:56.425866 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0810 12:06:32.059746 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0810 12:06:32.919203 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0810 12:06:32.919341 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0810 12:06:33.779178 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0810 12:06:33.779384 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0810 12:06:34.621367 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0810 12:06:34.621536 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0810 12:06:35.902448 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0810 12:06:35.906854 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0810 12:06:35.907100 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0810 12:06:36.262266 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0810 12:06:36.262457 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0810 12:06:37.592542 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0810 12:06:38.877889 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0810 12:06:39.182489 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0810 12:06:39.182646 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0810 12:06:39.183800 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0810 12:06:39.184044 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0810 12:06:39.482588 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0810 12:06:39.482736 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0810 12:06:42.121290 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0810 12:06:42.121442 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0810 12:06:43.244773 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0810 12:06:43.245077 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0810 12:06:45.502555 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0810 12:06:45.502713 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0810 12:06:49.348686 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0810 12:06:49.348867 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0810 12:07:01.180108 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0810 12:07:01.185910 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0810 12:07:16.817689 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0810 12:07:16.817853 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0810 12:07:18.109416 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0810 12:07:19.509677 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0810 12:07:20.835782 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0810 12:07:22.161957 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0810 12:07:23.540226 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0810 12:07:24.834861 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0810 12:07:26.104124 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0810 12:07:27.483215 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0810 12:07:28.798459 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0810 12:07:30.072517 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0810 12:07:31.456933 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0810 12:07:32.758858 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0810 12:07:34.024314 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0810 12:07:35.366468 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0810 12:07:36.659461 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0810 12:07:37.950332 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0810 12:07:39.296766 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0810 12:07:40.589784 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0810 12:07:41.873144 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0810 12:07:41.873395 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0810 12:07:43.216764 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0810 12:07:43.217038 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0810 12:07:44.503392 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0810 12:07:44.505421 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0810 12:07:44.505477 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0810 12:07:44.505546 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0810 12:07:44.505602 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0810 12:07:44.505637 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0810 12:07:44.505692 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0810 12:07:44.505757 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0810 12:07:44.505794 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0810 12:07:44.505829 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0810 12:07:44.505866 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0810 12:07:44.505902 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0810 12:07:44.505935 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0810 12:07:44.505967 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0810 12:07:44.506044 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0810 12:07:44.506100 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0810 12:07:44.506131 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0810 12:07:44.506239 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0810 12:07:44.506513 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0810 12:07:44.506566 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0810 12:07:44.506654 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0810 12:07:44.506722 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0810 12:07:44.506754 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0810 12:07:44.506894 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0810 12:07:44.506944 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0810 12:07:44.507011 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0810 12:07:44.507129 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0810 12:07:44.507255 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0810 12:07:44.507293 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0810 12:07:44.507401 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0810 12:07:44.522342 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0810 12:07:44.522550 1 metrics.cc:757] Collecting CPU metrics
I0810 12:07:44.522668 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0810 12:07:44.523648 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0810 12:07:44.523820 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0810 12:07:44.565175 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0816 10:55:16.812321 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f1986000000' with size 268435456
I0816 10:55:16.812669 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0816 10:55:16.819303 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0816 10:55:16.819347 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0816 10:55:16.819372 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0816 10:55:16.819425 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0816 10:55:16.819578 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0816 10:55:16.819616 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0816 10:55:16.819642 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0816 10:55:16.819750 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0816 10:55:16.819845 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0816 10:55:16.819885 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0816 10:55:16.819918 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0816 10:55:16.819941 1 model_lifecycle.cc:459] loading: entity_EN:1
I0816 10:55:16.819972 1 model_lifecycle.cc:459] loading: entity_HI:1
W0816 10:55:16.820329 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0816 10:55:16.820359 1 model_lifecycle.cc:459] loading: entity_TA:1
I0816 10:55:16.820426 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0816 10:55:16.820488 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0816 10:55:16.820530 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0816 10:55:16.820614 1 model_lifecycle.cc:459] loading: itn_EN:1
I0816 10:55:16.820644 1 model_lifecycle.cc:459] loading: itn_HI:1
W0816 10:55:16.820692 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0816 10:55:16.820699 1 model_lifecycle.cc:459] loading: itn_TA:1
I0816 10:55:17.239472 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0816 10:55:17.239509 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0816 10:55:17.239514 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0816 10:55:17.241919 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0816 10:55:17.242829 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0816 10:55:17.243247 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0816 10:55:17.243255 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0816 10:55:17.243258 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0816 10:55:17.243262 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0816 10:55:17.245021 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0816 10:55:17.245061 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0816 10:55:17.245066 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0816 10:55:17.245074 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0816 10:55:17.261459 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0816 10:55:20.741647 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0816 10:55:22.999481 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0816 10:55:23.000080 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0816 10:55:23.000643 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0816 10:55:23.000655 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0816 10:55:23.000661 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0816 10:55:23.000667 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0816 10:55:25.263752 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0816 10:55:25.264280 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0816 10:55:25.264808 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0816 10:55:25.264819 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0816 10:55:25.264824 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0816 10:55:25.264831 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0816 10:55:27.215552 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0816 10:55:27.216303 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0816 10:55:27.216963 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0816 10:55:27.216974 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0816 10:55:27.216978 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0816 10:55:27.216982 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0816 10:55:28.558869 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0816 10:55:28.559405 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0816 10:55:28.559832 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0816 10:55:28.559841 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0816 10:55:28.559844 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0816 10:55:28.559848 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0816 10:55:28.560269 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0816 10:55:31.313905 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0816 10:55:36.739945 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0816 10:55:39.496184 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0816 10:55:39.496714 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0816 10:56:19.223361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0816 10:56:20.146951 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0816 10:56:20.147106 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0816 10:56:22.414016 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0816 10:56:22.415266 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0816 10:56:23.330597 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0816 10:56:23.330785 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0816 10:56:25.586602 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0816 10:56:25.587925 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0816 10:56:26.518905 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0816 10:56:26.519042 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0816 10:56:26.520187 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0816 10:56:26.520403 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0816 10:56:26.846704 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0816 10:56:26.846805 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0816 10:56:26.851959 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0816 10:56:26.852214 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0816 10:56:28.324559 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0816 10:56:29.766046 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0816 10:56:30.073286 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0816 10:56:30.073484 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0816 10:56:30.431751 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0816 10:56:30.431939 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0816 10:56:31.863966 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0816 10:56:33.245512 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0816 10:56:33.245849 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0816 10:56:36.635429 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0816 10:56:36.635624 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0816 10:56:39.899772 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0816 10:56:39.900014 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0816 10:56:52.286451 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0816 10:56:52.286584 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0816 10:56:54.725353 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0816 10:56:54.725552 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0816 10:57:11.732818 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0816 10:57:11.732973 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0816 10:57:13.151853 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0816 10:57:14.542176 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0816 10:57:16.091265 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0816 10:57:17.590444 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0816 10:57:19.028766 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0816 10:57:20.406941 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0816 10:57:21.719917 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0816 10:57:23.014202 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0816 10:57:24.395822 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0816 10:57:25.695247 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0816 10:57:27.021588 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0816 10:57:28.379389 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0816 10:57:29.699171 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0816 10:57:31.019053 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0816 10:57:32.383560 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0816 10:57:33.724361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0816 10:57:35.071550 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0816 10:57:36.605115 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0816 10:57:38.166582 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0816 10:57:38.166854 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0816 10:57:39.646602 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0816 10:57:39.646858 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0816 10:57:41.064352 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0816 10:57:41.066268 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0816 10:57:41.066321 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0816 10:57:41.066358 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0816 10:57:41.066386 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0816 10:57:41.066416 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0816 10:57:41.066468 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0816 10:57:41.066516 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0816 10:57:41.066553 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0816 10:57:41.066588 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0816 10:57:41.066624 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0816 10:57:41.066659 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0816 10:57:41.066689 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0816 10:57:41.066725 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0816 10:57:41.067000 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0816 10:57:41.067052 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0816 10:57:41.067101 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0816 10:57:41.067161 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0816 10:57:41.067229 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0816 10:57:41.067269 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0816 10:57:41.067339 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0816 10:57:41.067380 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0816 10:57:41.067408 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0816 10:57:41.067528 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0816 10:57:41.067571 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0816 10:57:41.067614 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0816 10:57:41.067731 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0816 10:57:41.067827 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0816 10:57:41.067865 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0816 10:57:41.067963 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0816 10:57:41.092238 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0816 10:57:41.092476 1 metrics.cc:757] Collecting CPU metrics
I0816 10:57:41.092643 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0816 10:57:41.093837 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0816 10:57:41.094014 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0816 10:57:41.135480 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0817 07:17:43.690322 1 server.cc:264] Waiting for in-flight requests to complete.
I0817 07:17:43.690425 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0817 07:17:43.690759 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0817 07:17:43.690798 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0817 07:17:43.690914 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_TA' version 1
I0817 07:17:43.691000 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_EN' version 1
I0817 07:17:43.691035 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0817 07:17:43.691100 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_TA' version 1
I0817 07:17:43.691107 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0817 07:17:43.691337 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0817 07:17:43.691552 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0817 07:17:43.692766 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0817 07:17:43.693006 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0817 07:17:43.693142 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0817 07:17:43.693439 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0817 07:17:43.693941 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0817 07:17:43.694949 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_HI' version 1
I0817 07:17:43.695035 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0817 07:17:43.695351 1 server.cc:295] All models are stopped, unloading models
I0817 07:17:43.695401 1 server.cc:302] Timeout 30: Found 23 live models and 0 in-flight non-inference requests
I0817 07:17:43.698579 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0817 07:17:43.698601 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0817 07:17:43.698715 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_EN' version 1
I0817 07:17:43.698720 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_HI' version 1
I0817 07:17:43.699080 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_top1' version 1
I0817 07:17:43.704949 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0817 07:17:43.705049 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0817 07:17:43.705100 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0817 07:17:43.705151 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0817 07:17:43.718534 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0817 07:17:43.718751 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0817 07:17:43.745362 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0817 07:17:43.745449 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0817 07:17:43.745539 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0817 07:17:43.745631 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0817 07:17:44.695834 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0817 07:17:44.782168 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0817 07:17:44.809429 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0817 07:17:44.851845 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0817 07:17:44.881908 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0817 07:17:44.910061 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0817 07:17:44.917369 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0817 07:17:44.931790 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_EN' version 1
I0817 07:17:44.934148 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_HI' version 1
I0817 07:17:44.982331 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_TA' version 1
I0817 07:17:45.101207 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0817 07:17:45.153580 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0817 07:17:45.695998 1 server.cc:302] Timeout 28: Found 3 live models and 0 in-flight non-inference requests
I0817 07:17:46.696145 1 server.cc:302] Timeout 27: Found 3 live models and 0 in-flight non-inference requests
I0817 07:17:47.696304 1 server.cc:302] Timeout 26: Found 3 live models and 0 in-flight non-inference requests
I0817 07:17:48.696449 1 server.cc:302] Timeout 25: Found 3 live models and 0 in-flight non-inference requests
I0817 07:17:49.696587 1 server.cc:302] Timeout 24: Found 3 live models and 0 in-flight non-inference requests
I0817 07:17:50.696738 1 server.cc:302] Timeout 23: Found 3 live models and 0 in-flight non-inference requests
I0817 07:17:51.696888 1 server.cc:302] Timeout 22: Found 3 live models and 0 in-flight non-inference requests
I0817 07:17:52.697049 1 server.cc:302] Timeout 21: Found 3 live models and 0 in-flight non-inference requests
I0817 07:17:53.697287 1 server.cc:302] Timeout 20: Found 3 live models and 0 in-flight non-inference requests
I0817 07:19:05.492144 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fefea000000' with size 268435456
I0817 07:19:05.492597 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0817 07:19:05.502885 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0817 07:19:05.502949 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0817 07:19:05.502993 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0817 07:19:05.503041 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0817 07:19:05.503104 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0817 07:19:05.503327 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0817 07:19:05.503396 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_OR:1
I0817 07:19:05.503444 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0817 07:19:05.503492 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0817 07:19:05.503728 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0817 07:19:05.503870 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0817 07:19:05.503916 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0817 07:19:05.503955 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0817 07:19:05.518468 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0817 07:19:05.518551 1 model_lifecycle.cc:459] loading: entity_EN:1
I0817 07:19:05.522614 1 model_lifecycle.cc:459] loading: entity_HI:1
I0817 07:19:05.526570 1 model_lifecycle.cc:459] loading: entity_OR:1
W0817 07:19:05.530748 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0817 07:19:05.530798 1 model_lifecycle.cc:459] loading: entity_TA:1
I0817 07:19:05.530841 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0817 07:19:05.530883 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0817 07:19:05.530923 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0817 07:19:05.530961 1 model_lifecycle.cc:459] loading: itn_EN:1
I0817 07:19:05.531000 1 model_lifecycle.cc:459] loading: itn_HI:1
I0817 07:19:05.531036 1 model_lifecycle.cc:459] loading: itn_OR:1
W0817 07:19:05.531082 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0817 07:19:05.531094 1 model_lifecycle.cc:459] loading: itn_TA:1
I0817 07:19:06.035864 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0817 07:19:06.035918 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0817 07:19:06.035926 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0817 07:19:06.036141 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0817 07:19:06.036648 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0817 07:19:06.037066 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0817 07:19:06.037083 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0817 07:19:06.037088 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0817 07:19:06.037093 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0817 07:19:06.037127 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0817 07:19:09.230720 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0817 07:19:09.231249 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0817 07:19:09.231820 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0817 07:19:09.231840 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0817 07:19:09.231847 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0817 07:19:09.231854 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0817 07:19:09.231907 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0817 07:19:09.231933 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0817 07:19:11.034257 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0817 07:19:11.034673 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0817 07:19:11.035028 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0817 07:19:11.035181 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0817 07:19:11.035245 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0817 07:19:11.035322 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0817 07:19:11.035428 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0817 07:19:11.036379 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0817 07:19:12.970202 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0817 07:19:12.971961 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0817 07:19:12.972444 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0817 07:19:12.972852 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0817 07:19:12.972864 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0817 07:19:12.972869 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0817 07:19:12.972873 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0817 07:19:12.974071 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0817 07:19:12.974092 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0817 07:19:12.974102 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0817 07:19:12.974106 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0817 07:19:12.982521 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0817 07:19:15.103858 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0817 07:19:19.022214 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 07:19:21.762822 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 07:19:24.187686 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0817 07:19:24.188186 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0817 07:19:24.188711 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0817 07:19:24.188731 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0817 07:19:24.188739 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0817 07:19:24.188747 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0817 07:19:24.188800 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0817 07:19:24.190618 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0817 07:19:28.083360 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 07:19:31.839375 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0817 07:19:31.839775 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0817 07:19:31.840174 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0817 07:19:31.840190 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0817 07:19:31.840195 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0817 07:19:31.840199 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0817 07:19:31.840339 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0817 07:19:31.845510 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0817 07:19:36.173774 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0817 07:19:36.174237 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
E0817 07:19:58.760569 1 model_lifecycle.cc:597] failed to load 'itn_OR' version 1: Internal: SyntaxError: invalid syntax (model.py, line 1)
I0817 07:20:11.601045 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0817 07:20:12.459481 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0817 07:20:12.459688 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0817 07:20:13.296185 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0817 07:20:13.296425 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0817 07:20:14.683305 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0817 07:20:15.969844 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 07:20:18.392306 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_OR_0 (CPU device 0)
I0817 07:20:19.230482 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0817 07:20:19.230741 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_OR' version 1
I0817 07:20:20.058144 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0817 07:20:20.058281 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0817 07:20:21.489835 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0817 07:20:21.811596 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0817 07:20:23.154474 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0817 07:20:23.604413 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0817 07:20:23.604582 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0817 07:20:23.920279 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0817 07:20:23.920467 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0817 07:20:43.194403 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f5e8a000000' with size 268435456
I0817 07:20:43.194898 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0817 07:20:43.203955 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0817 07:20:43.204192 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0817 07:20:43.204366 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0817 07:20:43.204531 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0817 07:20:43.204694 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0817 07:20:43.204866 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0817 07:20:43.205015 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_OR:1
I0817 07:20:43.218508 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0817 07:20:43.218751 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0817 07:20:43.218923 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0817 07:20:43.219095 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0817 07:20:43.219260 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0817 07:20:43.219424 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0817 07:20:43.219608 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0817 07:20:43.219810 1 model_lifecycle.cc:459] loading: entity_EN:1
I0817 07:20:43.219976 1 model_lifecycle.cc:459] loading: entity_HI:1
I0817 07:20:43.220144 1 model_lifecycle.cc:459] loading: entity_OR:1
W0817 07:20:43.220417 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0817 07:20:43.220579 1 model_lifecycle.cc:459] loading: entity_TA:1
I0817 07:20:43.220741 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0817 07:20:43.220911 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0817 07:20:43.221094 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0817 07:20:43.221257 1 model_lifecycle.cc:459] loading: itn_EN:1
I0817 07:20:43.221424 1 model_lifecycle.cc:459] loading: itn_HI:1
I0817 07:20:43.221599 1 model_lifecycle.cc:459] loading: itn_OR:1
W0817 07:20:43.221768 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0817 07:20:43.221891 1 model_lifecycle.cc:459] loading: itn_TA:1
I0817 07:20:43.745145 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0817 07:20:43.745198 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0817 07:20:43.745209 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0817 07:20:43.749305 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0817 07:20:43.749358 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0817 07:20:43.749372 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0817 07:20:43.749381 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0817 07:20:43.766745 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0817 07:20:43.767814 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0817 07:20:43.768645 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0817 07:20:43.768661 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0817 07:20:43.768666 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0817 07:20:43.768670 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0817 07:20:43.768694 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0817 07:20:43.769026 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0817 07:20:43.769420 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0817 07:20:43.769434 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0817 07:20:43.769439 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0817 07:20:43.769443 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0817 07:20:43.769485 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0817 07:20:46.625670 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0817 07:20:46.626050 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0817 07:20:46.626400 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0817 07:20:46.626415 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0817 07:20:46.626420 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0817 07:20:46.626424 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0817 07:20:46.628101 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0817 07:20:54.355637 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0817 07:20:54.355997 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0817 07:20:54.356345 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0817 07:20:54.356360 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0817 07:20:54.356365 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0817 07:20:54.356369 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0817 07:20:54.356418 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0817 07:20:54.357766 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 07:20:54.358776 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0817 07:20:56.759886 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 07:20:59.177266 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 07:21:01.626395 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 07:21:09.650723 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0817 07:21:09.651321 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0817 07:22:06.231974 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0817 07:22:07.932431 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0817 07:22:07.932861 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0817 07:22:07.933306 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0817 07:22:07.933324 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0817 07:22:07.933329 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0817 07:22:07.933335 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0817 07:22:07.933376 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0817 07:22:07.933970 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0817 07:22:09.637847 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_OR_0 (CPU device 0)
I0817 07:22:09.639080 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0817 07:22:10.465979 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0817 07:22:10.466142 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_OR' version 1
I0817 07:22:11.269105 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0817 07:22:11.269345 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0817 07:22:12.096721 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0817 07:22:12.096887 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0817 07:22:12.975877 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
I0817 07:22:12.976053 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
W0817 07:22:12.976476 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0817 07:22:12.977055 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0817 07:22:12.977075 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0817 07:22:12.977082 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0817 07:22:12.977088 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0817 07:22:12.977131 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0817 07:22:14.311614 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0817 07:22:15.586133 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0817 07:22:16.834361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0817 07:22:18.308034 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0817 07:22:18.618938 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0817 07:22:18.619215 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0817 07:22:18.941271 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0817 07:22:18.941408 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0817 07:22:19.380043 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0817 07:22:19.380277 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0817 07:22:19.678453 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0817 07:22:19.678593 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0817 07:22:21.031546 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0817 07:22:21.031829 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0817 07:22:24.713218 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0817 07:22:24.713985 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0817 07:22:27.354545 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0817 07:22:27.354723 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0817 07:22:29.612558 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0817 07:22:29.612685 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0817 07:22:45.506787 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0817 07:22:45.507846 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0817 07:23:04.441960 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0817 07:23:04.442140 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0817 07:23:16.078221 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0817 07:23:16.078396 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0817 07:23:17.900563 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0817 07:23:17.901985 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0817 07:23:17.903821 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0817 07:23:17.904044 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0817 07:23:19.278459 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0817 07:23:20.564575 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0817 07:23:21.845046 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0817 07:23:23.269824 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0817 07:23:24.648306 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0817 07:23:25.953887 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0817 07:23:27.272920 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0817 07:23:28.732256 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0817 07:23:30.102889 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0817 07:23:31.416380 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0817 07:23:32.753202 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0817 07:23:34.278241 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0817 07:23:35.672122 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0817 07:23:37.011712 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0817 07:23:38.303101 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0817 07:23:39.751004 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0817 07:23:41.119832 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0817 07:23:42.437010 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0817 07:23:43.731756 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0817 07:23:45.154457 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0817 07:23:46.485803 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0817 07:23:47.816695 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0817 07:23:49.123221 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0817 07:23:50.520596 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0817 07:23:51.854118 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0817 07:23:51.854422 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0817 07:23:53.156416 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0817 07:23:53.157044 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0817 07:23:54.454474 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0817 07:23:54.454745 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0817 07:23:55.898324 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0817 07:23:55.902160 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0817 07:23:55.902260 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0817 07:23:55.902311 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_OR:1
I0817 07:23:55.902357 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0817 07:23:55.902404 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0817 07:23:55.902473 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0817 07:23:55.902523 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0817 07:23:55.902583 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0817 07:23:55.902796 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0817 07:23:55.902869 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0817 07:23:55.902919 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0817 07:23:55.902969 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_OR:1
I0817 07:23:55.903018 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0817 07:23:55.903064 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0817 07:23:55.903115 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0817 07:23:55.903164 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0817 07:23:55.903209 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0817 07:23:55.903275 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0817 07:23:55.903510 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0817 07:23:55.903621 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0817 07:23:55.903641 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0817 07:23:55.903692 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0817 07:23:55.903737 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_OR' version 1
I0817 07:23:55.903767 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0817 07:23:55.903799 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0817 07:23:55.903828 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0817 07:23:55.903852 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0817 07:23:55.903908 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0817 07:23:55.904004 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0817 07:23:55.904078 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0817 07:23:55.904370 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0817 07:23:55.904494 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0817 07:23:55.904588 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_OR' version 1
I0817 07:23:55.904625 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0817 07:23:55.905745 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0817 07:23:55.905826 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0817 07:23:55.906057 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_OR                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_OR       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_OR      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_OR        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_OR       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_OR                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_OR                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_OR | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_OR  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0817 07:23:55.933995 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0817 07:23:55.934214 1 metrics.cc:757] Collecting CPU metrics
I0817 07:23:55.934353 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0817 07:23:55.935547 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0817 07:23:55.935739 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0817 07:23:55.977586 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0817 10:09:27.340223 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f7dfa000000' with size 268435456
I0817 10:09:27.340541 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0817 10:09:27.347606 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0817 10:09:27.347655 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0817 10:09:27.347687 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0817 10:09:27.347711 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0817 10:09:27.347761 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0817 10:09:27.347844 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0817 10:09:27.347879 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_OR:1
I0817 10:09:27.347912 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0817 10:09:27.347946 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0817 10:09:27.347977 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0817 10:09:27.348008 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0817 10:09:27.348031 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0817 10:09:27.348053 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0817 10:09:27.348210 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0817 10:09:27.348250 1 model_lifecycle.cc:459] loading: entity_EN:1
I0817 10:09:27.348274 1 model_lifecycle.cc:459] loading: entity_HI:1
I0817 10:09:27.348302 1 model_lifecycle.cc:459] loading: entity_OR:1
W0817 10:09:27.348413 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0817 10:09:27.348566 1 model_lifecycle.cc:459] loading: entity_TA:1
I0817 10:09:27.348670 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0817 10:09:27.348798 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0817 10:09:27.348907 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0817 10:09:27.349012 1 model_lifecycle.cc:459] loading: itn_EN:1
I0817 10:09:27.349129 1 model_lifecycle.cc:459] loading: itn_HI:1
I0817 10:09:27.349227 1 model_lifecycle.cc:459] loading: itn_OR:1
W0817 10:09:27.349350 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0817 10:09:27.349443 1 model_lifecycle.cc:459] loading: itn_TA:1
I0817 10:09:27.772632 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0817 10:09:27.772686 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0817 10:09:27.772694 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0817 10:09:27.776319 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0817 10:09:27.776911 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0817 10:09:27.777318 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0817 10:09:27.777336 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0817 10:09:27.777341 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0817 10:09:27.777345 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0817 10:09:27.777392 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0817 10:09:27.777923 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0817 10:09:27.778501 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0817 10:09:27.778524 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0817 10:09:27.778531 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0817 10:09:27.778539 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0817 10:09:27.778581 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0817 10:09:27.779053 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0817 10:09:27.779550 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0817 10:09:27.779567 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0817 10:09:27.779573 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0817 10:09:27.779578 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0817 10:09:27.779624 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0817 10:09:27.780331 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0817 10:09:27.780875 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0817 10:09:27.780892 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0817 10:09:27.780897 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0817 10:09:27.780902 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0817 10:09:27.785711 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0817 10:09:27.785763 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0817 10:09:27.785776 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0817 10:09:27.785782 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0817 10:09:27.803433 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0817 10:09:30.950766 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0817 10:09:30.952027 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0817 10:09:32.917988 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0817 10:09:32.919383 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0817 10:09:34.889174 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0817 10:09:40.750397 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 10:09:45.463865 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0817 10:09:45.464439 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0817 10:09:45.464993 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0817 10:09:45.465012 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0817 10:09:45.465019 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0817 10:09:45.465026 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0817 10:09:45.465616 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 10:09:47.934780 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0817 10:09:47.935326 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0817 10:09:47.935839 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0817 10:09:47.935860 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0817 10:09:47.935868 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0817 10:09:47.935875 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0817 10:09:47.936461 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 10:09:50.674276 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 10:09:58.487366 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0817 10:10:00.444788 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0817 10:10:00.445298 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0817 10:10:00.446017 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0817 10:10:58.423646 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0817 10:10:59.280673 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0817 10:10:59.280921 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0817 10:11:00.160891 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_OR_0 (CPU device 0)
I0817 10:11:00.161095 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0817 10:11:01.019884 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0817 10:11:01.020103 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_OR' version 1
I0817 10:11:02.312949 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0817 10:11:03.179005 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0817 10:11:03.179257 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0817 10:11:03.182364 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0817 10:11:03.182593 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0817 10:11:04.619805 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0817 10:11:04.621184 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0817 10:11:04.621485 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0817 10:11:05.967771 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0817 10:11:07.254873 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0817 10:11:07.617559 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0817 10:11:07.617795 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0817 10:11:07.980480 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0817 10:11:07.980748 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0817 10:11:08.439773 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0817 10:11:08.439986 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0817 10:11:08.766517 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0817 10:11:08.766670 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0817 10:11:10.352824 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0817 10:11:10.353151 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0817 10:11:13.538660 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0817 10:11:13.538806 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0817 10:11:17.527025 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0817 10:11:17.527203 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0817 10:11:19.806233 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0817 10:11:19.807241 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0817 10:11:35.295043 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0817 10:11:35.295330 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0817 10:11:53.777861 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0817 10:11:53.777959 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0817 10:12:05.627711 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0817 10:12:05.627927 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0817 10:12:06.970320 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0817 10:12:08.405871 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0817 10:12:09.782539 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0817 10:12:11.084982 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0817 10:12:12.379840 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0817 10:12:13.844718 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0817 10:12:15.358590 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0817 10:12:16.815578 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0817 10:12:18.284502 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0817 10:12:19.782149 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0817 10:12:21.142181 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0817 10:12:22.434140 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0817 10:12:23.763363 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0817 10:12:25.231319 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0817 10:12:26.599052 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0817 10:12:27.957093 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0817 10:12:29.264233 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0817 10:12:30.863700 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0817 10:12:32.321198 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0817 10:12:33.643689 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0817 10:12:35.023211 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0817 10:12:36.499827 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0817 10:12:37.905717 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0817 10:12:39.299948 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0817 10:12:40.601040 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0817 10:12:40.601391 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0817 10:12:42.128674 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0817 10:12:42.128918 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0817 10:12:43.549686 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0817 10:12:43.562392 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0817 10:12:44.973839 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0817 10:12:44.976366 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0817 10:12:44.976439 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0817 10:12:44.976476 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_OR:1
I0817 10:12:44.976511 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0817 10:12:44.976545 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0817 10:12:44.976580 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0817 10:12:44.976613 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0817 10:12:44.976646 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0817 10:12:44.976733 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0817 10:12:44.976778 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0817 10:12:44.976820 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0817 10:12:44.976857 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_OR:1
I0817 10:12:44.976896 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0817 10:12:44.976933 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0817 10:12:44.976969 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0817 10:12:44.977005 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0817 10:12:44.977042 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0817 10:12:44.977069 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_OR' version 1
I0817 10:12:44.977169 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0817 10:12:44.977231 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0817 10:12:44.977319 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0817 10:12:44.977520 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0817 10:12:44.977560 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0817 10:12:44.977613 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0817 10:12:44.977706 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0817 10:12:44.977755 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0817 10:12:44.977863 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0817 10:12:44.977962 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0817 10:12:44.978050 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0817 10:12:44.978086 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0817 10:12:44.978139 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0817 10:12:44.978198 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0817 10:12:44.978227 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0817 10:12:44.978412 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_OR' version 1
I0817 10:12:44.978651 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0817 10:12:44.978702 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0817 10:12:44.978823 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_OR                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_OR       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_OR      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_OR        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_OR       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_OR                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_OR                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_OR | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_OR  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0817 10:12:44.994011 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0817 10:12:44.994224 1 metrics.cc:757] Collecting CPU metrics
I0817 10:12:44.994348 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0817 10:12:44.995412 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0817 10:12:44.995590 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0817 10:12:45.037044 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0817 14:21:42.554326 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f828c000000' with size 268435456
I0817 14:21:42.554673 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0817 14:21:42.560985 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0817 14:21:42.561035 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0817 14:21:42.561098 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0817 14:21:42.561138 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0817 14:21:42.561234 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0817 14:21:42.561267 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0817 14:21:42.561298 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_OR:1
I0817 14:21:42.561330 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0817 14:21:42.561357 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0817 14:21:42.561386 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0817 14:21:42.561417 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0817 14:21:42.561443 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0817 14:21:42.561466 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0817 14:21:42.561626 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0817 14:21:42.561771 1 model_lifecycle.cc:459] loading: entity_EN:1
I0817 14:21:42.561809 1 model_lifecycle.cc:459] loading: entity_HI:1
I0817 14:21:42.561838 1 model_lifecycle.cc:459] loading: entity_OR:1
W0817 14:21:42.561974 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0817 14:21:42.562011 1 model_lifecycle.cc:459] loading: entity_TA:1
I0817 14:21:42.562044 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0817 14:21:42.562077 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0817 14:21:42.562108 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0817 14:21:42.562134 1 model_lifecycle.cc:459] loading: itn_EN:1
I0817 14:21:42.562161 1 model_lifecycle.cc:459] loading: itn_HI:1
I0817 14:21:42.562185 1 model_lifecycle.cc:459] loading: itn_OR:1
W0817 14:21:42.562213 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0817 14:21:42.562221 1 model_lifecycle.cc:459] loading: itn_TA:1
I0817 14:21:42.987176 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0817 14:21:42.987231 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0817 14:21:42.987240 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0817 14:21:42.990130 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0817 14:21:42.990755 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0817 14:21:42.991212 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0817 14:21:42.991229 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0817 14:21:42.991234 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0817 14:21:42.991238 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0817 14:21:42.991268 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0817 14:21:42.991688 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0817 14:21:42.992216 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0817 14:21:42.992236 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0817 14:21:42.992242 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0817 14:21:42.992249 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0817 14:21:42.992290 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0817 14:21:42.992657 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0817 14:21:42.993080 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0817 14:21:42.993096 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0817 14:21:42.993101 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0817 14:21:42.993106 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0817 14:21:42.993149 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0817 14:21:42.993547 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0817 14:21:42.993949 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0817 14:21:42.993966 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0817 14:21:42.993971 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0817 14:21:42.993975 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0817 14:21:42.996400 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0817 14:21:42.996432 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0817 14:21:42.996447 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0817 14:21:42.996454 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0817 14:21:43.011526 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0817 14:21:46.040697 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0817 14:21:46.041806 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0817 14:21:47.972062 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0817 14:21:47.973156 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0817 14:21:49.975697 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0817 14:21:51.933895 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0817 14:21:53.780746 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0817 14:21:57.689456 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 14:22:02.095875 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 14:22:04.537957 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 14:22:06.990414 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0817 14:22:06.990858 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0817 14:22:06.991252 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0817 14:22:06.991268 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0817 14:22:06.991272 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0817 14:22:06.991277 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0817 14:22:06.991737 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0817 14:22:09.431326 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0817 14:22:09.431750 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0817 14:22:09.432127 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0817 14:22:09.432144 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0817 14:22:09.432149 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0817 14:22:09.432154 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0817 14:22:18.182530 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0817 14:22:18.182938 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0817 14:23:13.164420 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0817 14:23:14.029795 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0817 14:23:14.030007 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0817 14:23:14.881597 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_OR_0 (CPU device 0)
I0817 14:23:14.881852 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0817 14:23:15.762460 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_OR' version 1
I0817 14:23:15.764039 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0817 14:23:17.064167 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0817 14:23:17.907823 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0817 14:23:17.908032 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0817 14:23:19.281872 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0817 14:23:20.527178 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0817 14:23:20.528554 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0817 14:23:20.528826 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0817 14:23:21.939622 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0817 14:23:21.942902 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0817 14:23:21.943194 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0817 14:23:22.252362 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0817 14:23:22.252437 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0817 14:23:22.592277 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0817 14:23:22.592448 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0817 14:23:23.042258 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0817 14:23:23.042455 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0817 14:23:23.348840 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0817 14:23:23.349003 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0817 14:23:27.223703 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0817 14:23:27.224666 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0817 14:23:30.633121 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0817 14:23:30.633312 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0817 14:23:32.321232 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0817 14:23:32.321529 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0817 14:23:47.864498 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0817 14:23:47.864630 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0817 14:23:50.084911 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0817 14:23:50.085080 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0817 14:24:08.547361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0817 14:24:08.547639 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0817 14:24:19.825468 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0817 14:24:19.825669 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0817 14:24:21.116464 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0817 14:24:22.548636 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0817 14:24:23.834243 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0817 14:24:25.260056 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0817 14:24:26.565256 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0817 14:24:27.930094 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0817 14:24:29.229546 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0817 14:24:30.777543 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0817 14:24:32.298917 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0817 14:24:33.857596 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0817 14:24:35.309848 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0817 14:24:36.754062 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0817 14:24:38.034568 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0817 14:24:39.416692 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0817 14:24:40.719787 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0817 14:24:42.154750 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0817 14:24:43.456220 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0817 14:24:44.849577 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0817 14:24:46.298990 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0817 14:24:47.867946 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0817 14:24:49.155054 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0817 14:24:50.502342 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0817 14:24:51.842340 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0817 14:24:53.319012 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0817 14:24:54.602541 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0817 14:24:54.602985 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0817 14:24:56.090090 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0817 14:24:56.090362 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0817 14:24:57.408296 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0817 14:24:57.408704 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0817 14:24:58.945160 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0817 14:24:58.947612 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0817 14:24:58.947749 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0817 14:24:58.947856 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_OR:1
I0817 14:24:58.947960 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0817 14:24:58.948059 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0817 14:24:58.948161 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0817 14:24:58.948262 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0817 14:24:58.948371 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0817 14:24:58.948473 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0817 14:24:58.948726 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0817 14:24:58.948829 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0817 14:24:58.948974 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_OR:1
I0817 14:24:58.949077 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0817 14:24:58.949186 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0817 14:24:58.949264 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0817 14:24:58.949336 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0817 14:24:58.949378 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0817 14:24:58.949447 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0817 14:24:58.949478 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_OR' version 1
I0817 14:24:58.949528 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0817 14:24:58.949591 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0817 14:24:58.949899 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0817 14:24:58.949950 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0817 14:24:58.949989 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0817 14:24:58.950025 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0817 14:24:58.950054 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0817 14:24:58.950084 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0817 14:24:58.950219 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0817 14:24:58.950262 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0817 14:24:58.950339 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_OR' version 1
I0817 14:24:58.950383 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0817 14:24:58.950437 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0817 14:24:58.950501 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0817 14:24:58.950537 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0817 14:24:58.951721 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0817 14:24:58.951774 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0817 14:24:58.951894 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_OR                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_OR       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_OR      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_OR        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_OR       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_OR                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_OR                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_OR | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_OR  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0817 14:24:58.977860 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0817 14:24:58.978170 1 metrics.cc:757] Collecting CPU metrics
I0817 14:24:58.978313 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0817 14:24:58.979534 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0817 14:24:58.979718 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0817 14:24:59.021175 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0821 08:27:58.929358 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fc40e000000' with size 268435456
I0821 08:27:58.929662 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0821 08:27:58.936090 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 08:27:58.936134 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 08:27:58.936174 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 08:27:58.936207 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 08:27:58.936256 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0821 08:27:58.936288 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0821 08:27:58.936332 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_OR:1
I0821 08:27:58.936360 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0821 08:27:58.936384 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0821 08:27:58.936499 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 08:27:58.936549 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 08:27:58.936575 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 08:27:58.936596 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 08:27:58.936692 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 08:27:58.936720 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 08:27:58.936745 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 08:27:58.936793 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 08:27:58.936996 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 08:27:58.937021 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 08:27:58.937049 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 08:27:58.937077 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 08:27:58.937109 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 08:27:58.937132 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 08:27:58.937158 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 08:27:58.937178 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 08:27:58.937206 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 08:27:58.937212 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 08:27:59.395249 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 08:27:59.395281 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 08:27:59.395287 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 08:27:59.401178 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 08:27:59.402133 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 08:27:59.402731 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 08:27:59.402743 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 08:27:59.402749 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 08:27:59.402755 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 08:27:59.402798 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 08:27:59.403058 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 08:27:59.403398 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 08:27:59.403407 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 08:27:59.403411 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 08:27:59.403414 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 08:27:59.403441 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 08:27:59.403815 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 08:27:59.404215 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 08:27:59.404224 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 08:27:59.404228 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 08:27:59.404232 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 08:27:59.404267 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 08:28:02.837138 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 08:28:02.838512 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 08:28:02.838559 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 08:28:02.838566 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 08:28:02.838572 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 08:28:02.852825 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 08:28:04.855679 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 08:28:04.856213 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 08:28:04.856679 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 08:28:04.856691 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 08:28:04.856694 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 08:28:04.856699 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 08:28:04.857429 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 08:28:09.093808 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0821 08:28:09.094269 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0821 08:28:09.094703 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0821 08:28:09.094713 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0821 08:28:09.094716 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0821 08:28:09.094720 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0821 08:28:13.021120 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 08:28:15.766826 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 08:28:18.227479 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 08:28:20.674553 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 08:28:20.675073 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 08:28:20.675527 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 08:28:20.675535 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 08:28:20.675539 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 08:28:20.675543 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 08:28:22.011481 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 08:28:30.137995 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 08:28:32.338684 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 08:28:32.339167 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 08:28:32.339987 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 08:29:29.895289 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 08:29:32.261626 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_EN_0 (CPU device 0)
I0821 08:29:32.263102 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 08:29:33.134608 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_OR_0 (CPU device 0)
I0821 08:29:33.134799 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_EN' version 1
I0821 08:29:34.021761 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0821 08:29:34.021955 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_OR' version 1
I0821 08:29:34.022936 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_TA_0 (CPU device 0)
I0821 08:29:34.023125 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0821 08:29:34.890592 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_decoder_HI_0 (CPU device 0)
I0821 08:29:34.890759 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_TA' version 1
I0821 08:29:35.779904 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 08:29:35.780082 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_decoder_HI' version 1
I0821 08:29:37.256580 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 08:29:38.574911 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 08:29:39.953085 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 08:29:39.956683 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 08:29:39.956913 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 08:29:40.292092 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 08:29:40.292256 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 08:29:41.678055 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 08:29:42.023634 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 08:29:42.023837 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 08:29:42.560242 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 08:29:42.560405 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 08:29:45.609271 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 08:29:45.609398 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 08:29:45.922007 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 08:29:45.922169 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 08:29:47.237578 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 08:29:47.237900 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 08:29:50.239603 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 08:29:50.239757 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 08:29:52.541463 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 08:29:52.541697 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 08:30:08.990324 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 08:30:08.990502 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 08:30:28.535341 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 08:30:28.535490 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 08:30:40.663043 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 08:30:40.663243 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 08:30:42.156206 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 08:30:43.610634 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 08:30:45.132205 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 08:30:46.621852 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 08:30:48.103001 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 08:30:49.456722 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 08:30:50.890162 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 08:30:52.266593 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 08:30:53.769528 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 08:30:55.101347 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 08:30:56.482054 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 08:30:57.820234 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 08:30:59.269594 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 08:31:00.591291 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 08:31:01.988586 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 08:31:03.349905 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 08:31:04.815907 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 08:31:06.144793 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 08:31:07.595134 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 08:31:09.010226 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 08:31:10.626337 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 08:31:12.169154 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 08:31:13.730917 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 08:31:15.162103 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 08:31:16.640087 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 08:31:16.646692 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 08:31:17.996983 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 08:31:17.997268 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 08:31:19.429672 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 08:31:19.429970 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 08:31:20.743303 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 08:31:20.746081 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_EN:1
I0821 08:31:20.746142 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_HI:1
I0821 08:31:20.746178 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_OR:1
I0821 08:31:20.746210 1 model_lifecycle.cc:459] loading: asr_greedy_ensemble_TA:1
I0821 08:31:20.746243 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 08:31:20.746273 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 08:31:20.746305 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 08:31:20.746336 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 08:31:20.746411 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 08:31:20.746465 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_EN:1
I0821 08:31:20.746504 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_HI:1
I0821 08:31:20.746539 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_OR:1
I0821 08:31:20.746577 1 model_lifecycle.cc:459] loading: pipeline_greedy_ensemble_TA:1
I0821 08:31:20.746615 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 08:31:20.746652 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 08:31:20.746686 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 08:31:20.746725 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 08:31:20.746765 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_EN' version 1
I0821 08:31:20.746833 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_HI' version 1
I0821 08:31:20.746902 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 08:31:20.746964 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 08:31:20.747127 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_TA' version 1
I0821 08:31:20.747173 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_ensemble_OR' version 1
I0821 08:31:20.747231 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 08:31:20.747290 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_TA' version 1
I0821 08:31:20.747417 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_EN' version 1
I0821 08:31:20.747471 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_HI' version 1
I0821 08:31:20.747496 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 08:31:20.747519 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 08:31:20.747614 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 08:31:20.747689 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 08:31:20.747713 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 08:31:20.747764 1 model_lifecycle.cc:694] successfully loaded 'pipeline_greedy_ensemble_OR' version 1
I0821 08:31:20.747822 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 08:31:20.747957 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 08:31:20.748012 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 08:31:20.748138 1 server.cc:633] 
+-----------------------------+---------+--------+
| Model                       | Version | Status |
+-----------------------------+---------+--------+
| asr_am_EN                   | 1       | READY  |
| asr_am_HI                   | 1       | READY  |
| asr_am_OR                   | 1       | READY  |
| asr_am_TA                   | 1       | READY  |
| asr_greedy_decoder_EN       | 1       | READY  |
| asr_greedy_decoder_HI       | 1       | READY  |
| asr_greedy_decoder_OR       | 1       | READY  |
| asr_greedy_decoder_TA       | 1       | READY  |
| asr_greedy_ensemble_EN      | 1       | READY  |
| asr_greedy_ensemble_HI      | 1       | READY  |
| asr_greedy_ensemble_OR      | 1       | READY  |
| asr_greedy_ensemble_TA      | 1       | READY  |
| asr_greedy_top1             | 1       | READY  |
| asr_preprocessor            | 1       | READY  |
| asr_pyctc_decoder_EN        | 1       | READY  |
| asr_pyctc_decoder_HI        | 1       | READY  |
| asr_pyctc_decoder_OR        | 1       | READY  |
| asr_pyctc_decoder_TA        | 1       | READY  |
| asr_pyctc_ensemble_EN       | 1       | READY  |
| asr_pyctc_ensemble_HI       | 1       | READY  |
| asr_pyctc_ensemble_OR       | 1       | READY  |
| asr_pyctc_ensemble_TA       | 1       | READY  |
| entity_EN                   | 1       | READY  |
| entity_HI                   | 1       | READY  |
| entity_OR                   | 1       | READY  |
| entity_TA                   | 1       | READY  |
| intent_ensemble             | 1       | READY  |
| intent_model_onnx           | 1       | READY  |
| intent_postprocessor        | 1       | READY  |
| intent_preprocessor         | 1       | READY  |
| itn_EN                      | 1       | READY  |
| itn_HI                      | 1       | READY  |
| itn_OR                      | 1       | READY  |
| itn_TA                      | 1       | READY  |
| pipeline_greedy_ensemble_EN | 1       | READY  |
| pipeline_greedy_ensemble_HI | 1       | READY  |
| pipeline_greedy_ensemble_OR | 1       | READY  |
| pipeline_greedy_ensemble_TA | 1       | READY  |
| pipeline_pyctc_ensemble_EN  | 1       | READY  |
| pipeline_pyctc_ensemble_HI  | 1       | READY  |
| pipeline_pyctc_ensemble_OR  | 1       | READY  |
| pipeline_pyctc_ensemble_TA  | 1       | READY  |
+-----------------------------+---------+--------+

I0821 08:31:20.763549 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 08:31:20.763727 1 metrics.cc:757] Collecting CPU metrics
I0821 08:31:20.763835 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 08:31:20.765154 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0821 08:31:20.765320 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0821 08:31:20.806687 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0821 11:49:02.326726 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 11:49:02.326835 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 11:49:02.327122 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 11:49:02.327189 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 11:49:02.327289 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_TA' version 1
I0821 11:49:02.327312 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 11:49:02.327563 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_EN' version 1
I0821 11:49:02.327970 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:49:02.328055 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:49:02.328678 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 11:49:02.328894 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_HI' version 1
I0821 11:49:02.328898 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_EN' version 1
I0821 11:49:02.328935 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:49:02.329630 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:49:02.329329 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:49:02.329549 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:49:02.330345 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:49:02.330524 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_top1' version 1
I0821 11:49:02.330720 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 11:49:02.334112 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_TA' version 1
I0821 11:49:02.334111 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_greedy_ensemble_OR' version 1
I0821 11:49:02.334152 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 11:49:02.334159 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_OR' version 1
I0821 11:49:02.334161 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 11:49:02.334169 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 11:49:02.334309 1 server.cc:295] All models are stopped, unloading models
I0821 11:49:02.335342 1 server.cc:302] Timeout 30: Found 26 live models and 0 in-flight non-inference requests
I0821 11:49:02.335193 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 11:49:02.335192 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_ensemble_HI' version 1
I0821 11:49:02.341052 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:49:02.345665 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:49:02.350686 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 11:49:02.351224 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:49:02.351436 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 11:49:02.367303 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:49:02.371362 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:49:02.371480 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 11:49:02.377071 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 11:49:02.391744 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:49:02.396996 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:49:02.397075 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 11:49:02.397176 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 11:49:03.341964 1 server.cc:302] Timeout 29: Found 18 live models and 0 in-flight non-inference requests
I0821 11:49:03.399494 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 11:49:03.401605 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 11:49:03.417737 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 11:49:03.432202 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 11:49:03.505807 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_HI' version 1
I0821 11:49:03.512478 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_OR' version 1
I0821 11:49:03.522623 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 11:49:03.527078 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 11:49:03.556433 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 11:49:03.559924 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_TA' version 1
I0821 11:49:03.562178 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_decoder_EN' version 1
I0821 11:49:03.576431 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 11:49:03.750350 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 11:49:03.897262 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 11:49:04.342382 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 11:49:05.342547 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 11:49:06.342697 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 11:49:07.342875 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 11:49:08.343048 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 11:49:09.343219 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 11:49:10.343416 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 11:49:11.343573 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 11:49:27.677211 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fb7a6000000' with size 268435456
I0821 11:49:27.677546 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 11:49:27.684401 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 11:49:27.684652 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 11:49:27.684781 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 11:49:27.684922 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 11:49:27.685113 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 11:49:27.685331 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 11:49:27.685508 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 11:49:27.685709 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 11:49:27.685922 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 11:49:27.686121 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 11:49:27.686312 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 11:49:27.686490 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 11:49:27.686658 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 11:49:27.686825 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 11:49:27.686980 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 11:49:27.687139 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 11:49:27.687445 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 11:49:27.687648 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 11:49:27.687827 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 11:49:27.688018 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 11:49:27.688231 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 11:49:27.690626 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 11:49:27.694491 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 11:49:27.694684 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 11:49:27.694863 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 11:49:27.695021 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 11:49:28.233490 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 11:49:28.233544 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 11:49:28.233553 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 11:49:28.237949 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 11:49:28.238169 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 11:49:28.238338 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 11:49:28.238506 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 11:49:28.254053 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 11:49:28.255754 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 11:49:28.256564 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 11:49:28.256582 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 11:49:28.256587 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 11:49:28.256592 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 11:49:28.256603 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 11:49:28.257122 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 11:49:28.257498 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 11:49:28.257514 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 11:49:28.257518 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 11:49:28.257523 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 11:49:28.257553 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 11:49:28.258160 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 11:49:28.258583 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 11:49:28.258601 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 11:49:28.258606 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 11:49:28.258611 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 11:49:28.258668 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 11:49:31.410622 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 11:49:31.411039 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 11:49:31.411440 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 11:49:31.411460 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 11:49:31.411465 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 11:49:31.411469 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 11:49:31.412116 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:49:31.413741 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 11:49:34.159433 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:49:36.599251 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:49:39.014746 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:49:46.779462 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 11:49:46.780197 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 11:50:47.025589 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 11:50:48.936533 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 11:50:48.940448 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 11:50:50.900242 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 11:50:50.900702 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 11:50:50.901186 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 11:50:50.901220 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 11:50:50.901226 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 11:50:50.901231 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 11:50:50.901274 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 11:50:50.901849 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 11:50:52.930563 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 11:50:52.931787 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 11:50:54.323356 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 11:50:55.682706 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 11:50:57.131554 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 11:50:58.423034 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 11:50:58.740968 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 11:50:58.741104 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 11:50:59.078902 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 11:50:59.079049 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 11:50:59.546368 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 11:50:59.546560 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 11:50:59.878911 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 11:50:59.879135 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 11:51:01.317325 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 11:51:01.317764 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 11:51:08.853664 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 11:51:08.853848 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 11:51:11.149289 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 11:51:11.149430 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 11:51:14.824900 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 11:51:14.825294 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 11:51:31.075692 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 11:51:31.075855 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 11:51:50.289659 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 11:51:50.289842 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 11:52:02.115837 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 11:52:02.115992 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 11:52:02.119405 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 11:52:02.119596 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 11:52:03.510747 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 11:52:04.967952 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 11:52:06.527614 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 11:52:07.891905 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 11:52:09.287437 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 11:52:10.747483 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 11:52:12.267833 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 11:52:13.672352 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 11:52:15.021868 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 11:52:16.466192 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 11:52:18.048911 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 11:52:19.392940 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 11:52:20.778150 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 11:52:22.220799 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 11:52:23.749518 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 11:52:25.108597 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 11:52:26.437379 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 11:52:27.892688 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 11:52:29.421655 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 11:52:30.813476 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 11:52:32.119911 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 11:52:33.521922 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 11:52:35.028544 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 11:52:36.353095 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 11:52:37.693719 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 11:52:37.694097 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 11:52:39.086032 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 11:52:39.086328 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 11:52:40.604244 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 11:52:40.604802 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 11:52:41.971768 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 11:52:41.973654 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 11:52:41.973727 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 11:52:41.973780 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 11:52:41.973831 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 11:52:41.973878 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 11:52:41.973926 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 11:52:41.973973 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 11:52:41.974021 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 11:52:41.974073 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 11:52:41.974130 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 11:52:41.974445 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 11:52:41.974515 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 11:52:41.974553 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 11:52:41.974593 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 11:52:41.974613 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 11:52:41.974672 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 11:52:41.974698 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 11:52:41.974903 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 11:52:41.975139 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 11:52:41.975213 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 11:52:41.975658 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 11:52:42.004440 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 11:52:42.004724 1 metrics.cc:757] Collecting CPU metrics
I0821 11:52:42.004911 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 11:52:42.005051 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 11:52:42.005138 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 11:52:42.005365 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 11:52:42.005448 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 11:52:42.005460 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 11:52:42.005654 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:52:42.005539 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 11:52:42.005561 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 11:52:42.006257 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 11:52:42.006414 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:52:42.006455 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:52:42.006492 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:52:42.006857 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:52:42.007064 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:52:42.007278 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 11:52:42.008129 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:52:42.008165 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 11:52:42.008410 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 11:52:42.008564 1 server.cc:295] All models are stopped, unloading models
I0821 11:52:42.008646 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 11:52:42.008659 1 server.cc:302] Timeout 30: Found 20 live models and 0 in-flight non-inference requests
I0821 11:52:42.021338 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:52:42.022067 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 11:52:42.044060 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:52:42.053669 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:52:42.053724 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 11:52:42.053727 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:52:42.053816 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:52:42.053863 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 11:52:42.053943 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 11:52:42.054185 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 11:52:43.009182 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 11:52:43.084515 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 11:52:43.272430 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 11:52:43.313674 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 11:52:43.319103 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 11:52:43.338356 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 11:52:43.346930 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 11:52:43.393145 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 11:52:43.417690 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 11:52:43.493801 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 11:52:43.501445 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 11:52:44.009456 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:45.009701 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:46.010049 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:47.010225 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:48.010375 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:49.010658 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:50.011029 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:51.011434 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:52.011771 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 11:52:52.645115 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 11:52:52.800365 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 11:52:52.990794 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 11:52:52.997613 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 11:52:53.012088 1 server.cc:302] Timeout 19: Found 0 live models and 0 in-flight non-inference requests
I0821 11:52:59.129389 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f5e2e000000' with size 268435456
I0821 11:52:59.129747 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 11:52:59.134896 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 11:52:59.134922 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 11:52:59.134927 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 11:52:59.134930 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 11:52:59.134968 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 11:52:59.135001 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 11:52:59.135027 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 11:52:59.135059 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 11:52:59.135249 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 11:52:59.135297 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 11:52:59.135328 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 11:52:59.135355 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 11:52:59.135383 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 11:52:59.135413 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 11:52:59.135441 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 11:52:59.135465 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 11:52:59.136016 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 11:52:59.136084 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 11:52:59.136154 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 11:52:59.136285 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 11:52:59.136341 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 11:52:59.136383 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 11:52:59.136438 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 11:52:59.137056 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 11:52:59.137112 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 11:52:59.137131 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 11:52:59.509327 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 11:52:59.509388 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 11:52:59.509398 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 11:52:59.511490 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 11:52:59.512107 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 11:52:59.512629 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 11:52:59.512651 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 11:52:59.512660 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 11:52:59.512668 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 11:52:59.512735 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 11:53:02.035180 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 11:53:02.035624 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 11:53:02.036050 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 11:53:02.036070 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 11:53:02.036089 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 11:53:02.036094 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 11:53:02.036150 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
I0821 11:53:02.036291 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
W0821 11:53:02.036669 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 11:53:02.037305 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 11:53:02.037329 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 11:53:02.037336 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 11:53:02.037343 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 11:53:02.037387 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 11:53:02.037775 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 11:53:02.038189 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 11:53:02.038210 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 11:53:02.038215 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 11:53:02.038220 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 11:53:02.039553 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 11:53:02.039587 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 11:53:02.039598 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 11:53:02.039605 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 11:53:02.048925 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:53:04.778990 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:53:07.223648 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:53:12.359666 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:53:17.482498 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 11:53:19.264588 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 11:53:19.265813 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 11:53:19.268303 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 11:53:19.268536 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 11:53:21.159061 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 11:53:21.159581 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 11:53:21.160004 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 11:53:21.160028 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 11:53:21.160037 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 11:53:21.160045 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 11:53:21.160354 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 11:53:36.012221 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 11:53:36.012917 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 11:54:20.707997 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 11:54:22.011705 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 11:54:23.415330 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 11:54:24.819883 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 11:54:25.264901 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 11:54:25.265087 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 11:54:25.620135 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 11:54:25.620290 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 11:54:26.935113 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 11:54:27.235956 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 11:54:27.236221 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 11:54:27.550725 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 11:54:27.550939 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 11:54:29.299972 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 11:54:29.301198 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 11:54:32.708705 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 11:54:32.708871 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 11:54:45.003368 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 11:54:45.003534 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 11:54:46.099152 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 11:54:46.099454 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 11:55:06.448746 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 11:55:06.449142 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 11:55:10.415298 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 11:55:10.415481 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 11:55:27.480319 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 11:55:27.480672 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 11:55:29.903027 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 11:55:29.903244 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 11:55:31.377281 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 11:55:32.870855 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 11:55:34.448658 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 11:55:35.843340 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 11:55:37.274470 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 11:55:38.780698 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 11:55:40.375388 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 11:55:41.770385 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 11:55:43.165667 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 11:55:44.644988 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 11:55:46.218600 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 11:55:47.653523 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 11:55:49.180406 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 11:55:50.667068 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 11:55:52.233423 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 11:55:53.640298 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 11:55:55.028870 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 11:55:56.497400 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 11:55:58.205185 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 11:55:59.552791 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 11:56:00.958204 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 11:56:02.410091 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 11:56:03.997329 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 11:56:05.414019 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 11:56:06.861226 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 11:56:06.861446 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 11:56:08.378253 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 11:56:08.378525 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 11:56:09.887558 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 11:56:09.887817 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 11:56:11.285750 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 11:56:11.287809 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 11:56:11.287923 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 11:56:11.287992 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 11:56:11.288057 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 11:56:11.288116 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 11:56:11.288176 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 11:56:11.288232 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 11:56:11.288293 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 11:56:11.288366 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 11:56:11.288440 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 11:56:11.288522 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 11:56:11.288600 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 11:56:11.289039 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 11:56:11.289143 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 11:56:11.289236 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 11:56:11.289350 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 11:56:11.289407 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 11:56:11.289441 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 11:56:11.289600 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 11:56:11.289675 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 11:56:11.289831 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 11:56:11.306634 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 11:56:11.306843 1 metrics.cc:757] Collecting CPU metrics
I0821 11:56:11.306975 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 11:56:11.307006 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 11:56:11.307043 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 11:56:11.307234 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 11:56:11.307271 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 11:56:11.307500 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 11:56:11.307505 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:56:11.307523 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 11:56:11.307534 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 11:56:11.307863 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:56:11.307908 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 11:56:11.308202 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:56:11.308243 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:56:11.308412 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:56:11.308565 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:56:11.308673 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 11:56:11.308624 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:56:11.309077 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 11:56:11.310053 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 11:56:11.318224 1 server.cc:295] All models are stopped, unloading models
I0821 11:56:11.318238 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 11:56:11.318262 1 server.cc:302] Timeout 30: Found 20 live models and 0 in-flight non-inference requests
I0821 11:56:11.320142 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:56:11.320879 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 11:56:11.354922 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:56:11.355118 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 11:56:11.355518 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:56:11.359188 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 11:56:11.371549 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:56:11.371566 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:56:11.371761 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 11:56:11.371869 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 11:56:12.318545 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 11:56:12.405071 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 11:56:12.414125 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 11:56:12.418546 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 11:56:12.432131 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 11:56:12.538399 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 11:56:12.540578 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 11:56:12.566290 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 11:56:12.592488 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 11:56:12.605790 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 11:56:12.636248 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 11:56:13.319118 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:14.319305 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:15.319488 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:16.319676 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:17.319850 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:18.320012 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:19.320247 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:20.320525 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:21.320730 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:22.320920 1 server.cc:302] Timeout 19: Found 4 live models and 0 in-flight non-inference requests
I0821 11:56:22.605610 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 11:56:22.615672 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 11:56:22.675281 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 11:56:22.942570 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 11:56:23.321116 1 server.cc:302] Timeout 18: Found 0 live models and 0 in-flight non-inference requests
I0821 11:56:29.645059 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7ff6dc000000' with size 268435456
I0821 11:56:29.645437 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 11:56:29.651065 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 11:56:29.651090 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 11:56:29.651095 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 11:56:29.651098 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 11:56:29.651133 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 11:56:29.651165 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 11:56:29.651189 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 11:56:29.651221 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 11:56:29.651319 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 11:56:29.651353 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 11:56:29.651382 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 11:56:29.651407 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 11:56:29.651435 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 11:56:29.651540 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 11:56:29.651573 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 11:56:29.651597 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 11:56:29.651906 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 11:56:29.651940 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 11:56:29.651973 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 11:56:29.652029 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 11:56:29.652066 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 11:56:29.652103 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 11:56:29.652135 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 11:56:29.652163 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 11:56:29.652225 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 11:56:29.652239 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 11:56:30.054207 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 11:56:30.054273 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 11:56:30.054279 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 11:56:30.056590 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 11:56:30.057297 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 11:56:30.057782 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 11:56:30.057803 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 11:56:30.057808 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 11:56:30.057813 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 11:56:30.057864 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 11:56:30.058471 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 11:56:30.059114 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 11:56:30.059155 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 11:56:30.059165 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 11:56:30.059174 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 11:56:30.059206 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 11:56:30.059675 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 11:56:30.060188 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 11:56:30.060214 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 11:56:30.060231 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 11:56:30.060242 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 11:56:30.061868 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 11:56:30.061920 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 11:56:30.061934 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 11:56:30.061939 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 11:56:30.073115 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 11:56:32.881933 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 11:56:32.883132 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 11:56:34.931209 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 11:56:34.932615 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 11:56:36.893797 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:56:36.894574 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 11:56:39.660603 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 11:56:39.661085 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 11:56:39.661520 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 11:56:39.661541 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 11:56:39.661546 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 11:56:39.661550 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 11:56:39.661615 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 11:56:39.662057 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 11:56:39.662519 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 11:56:39.662541 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 11:56:39.662546 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 11:56:39.662550 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 11:56:39.663040 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:56:42.436332 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:56:49.308736 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 11:56:53.463297 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 11:56:53.463866 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 11:57:57.049562 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 11:57:58.514843 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 11:58:00.421995 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 11:58:00.423199 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 11:58:00.425449 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 11:58:00.425677 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 11:58:01.936982 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 11:58:03.490146 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 11:58:03.814484 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 11:58:03.814650 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 11:58:04.326131 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 11:58:04.326421 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 11:58:04.708790 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 11:58:04.708939 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 11:58:06.070498 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 11:58:06.386956 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 11:58:06.387119 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 11:58:07.700722 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 11:58:07.701027 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 11:58:10.818335 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 11:58:10.818934 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 11:58:13.218170 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 11:58:13.218332 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 11:58:15.922792 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 11:58:15.922963 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 11:58:28.466585 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 11:58:28.467253 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 11:58:48.651312 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 11:58:48.651515 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 11:59:05.167464 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 11:59:05.167631 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 11:59:06.471676 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 11:59:07.888024 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 11:59:09.406678 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 11:59:10.743643 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 11:59:12.141430 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 11:59:13.586246 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 11:59:15.076945 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 11:59:16.466613 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 11:59:17.835582 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 11:59:19.271452 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 11:59:20.806361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 11:59:22.125188 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 11:59:23.539107 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 11:59:25.099308 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 11:59:26.708453 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 11:59:28.101862 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 11:59:29.541429 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 11:59:31.024088 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 11:59:32.581068 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 11:59:34.002464 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 11:59:35.407022 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 11:59:36.915919 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 11:59:38.449978 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 11:59:39.831213 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 11:59:41.252577 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 11:59:41.252991 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 11:59:42.708962 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 11:59:42.709230 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 11:59:44.253898 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 11:59:44.264410 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 11:59:45.632607 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 11:59:45.634314 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 11:59:45.634393 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 11:59:45.634455 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 11:59:45.634493 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 11:59:45.634529 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 11:59:45.634595 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 11:59:45.634636 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 11:59:45.634665 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 11:59:45.634730 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 11:59:45.634789 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 11:59:45.634837 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 11:59:45.634868 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 11:59:45.635205 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 11:59:45.635288 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 11:59:45.635376 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 11:59:45.635464 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 11:59:45.635517 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 11:59:45.635563 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 11:59:45.635712 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 11:59:45.635768 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 11:59:45.635877 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 11:59:45.652156 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 11:59:45.652368 1 metrics.cc:757] Collecting CPU metrics
I0821 11:59:45.652497 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 11:59:45.652524 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 11:59:45.652558 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 11:59:45.652728 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 11:59:45.652731 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 11:59:45.652910 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 11:59:45.652964 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 11:59:45.652927 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:59:45.653225 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 11:59:45.653410 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 11:59:45.653614 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:59:45.653657 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:59:45.653878 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:59:45.654052 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:59:45.654557 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 11:59:45.654672 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 11:59:45.655771 1 server.cc:295] All models are stopped, unloading models
I0821 11:59:45.655815 1 server.cc:302] Timeout 30: Found 22 live models and 0 in-flight non-inference requests
I0821 11:59:45.655863 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 11:59:45.655892 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 11:59:45.656011 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:59:45.656390 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 11:59:45.672209 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:59:45.672400 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 11:59:45.680354 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:59:45.680488 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 11:59:45.691347 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:59:45.691503 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 11:59:45.691633 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:59:45.704704 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 11:59:45.704881 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 11:59:45.704944 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 11:59:46.658273 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 11:59:46.771236 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 11:59:46.771550 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 11:59:46.792521 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 11:59:46.826690 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 11:59:46.855668 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 11:59:46.859344 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 11:59:46.886606 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 11:59:46.910821 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 11:59:46.971837 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 11:59:47.147501 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 11:59:47.658419 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:48.658672 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:49.659168 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:50.659663 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:51.660260 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:52.660739 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:53.661018 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:54.661329 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:55.661705 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:56.662046 1 server.cc:302] Timeout 19: Found 4 live models and 0 in-flight non-inference requests
I0821 11:59:56.929533 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 11:59:57.023321 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 11:59:57.103833 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 11:59:57.288983 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 11:59:57.662327 1 server.cc:302] Timeout 18: Found 0 live models and 0 in-flight non-inference requests
I0821 12:00:04.083107 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fe98c000000' with size 268435456
I0821 12:00:04.083453 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:00:04.088620 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:00:04.088644 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:00:04.088649 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:00:04.088653 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:00:04.088688 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:00:04.088723 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:00:04.088749 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:00:04.088778 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:00:04.088892 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:00:04.088950 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:00:04.088989 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:00:04.089018 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:00:04.089050 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:00:04.089095 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:00:04.089122 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:00:04.089149 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:00:04.089278 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:00:04.089323 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:00:04.089357 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:00:04.089602 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:00:04.089965 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:00:04.090280 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:00:04.090594 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:00:04.090671 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:00:04.090757 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:00:04.090791 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:00:04.489611 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:00:04.489689 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:00:04.489702 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:00:04.492835 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:00:04.493423 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:00:04.493912 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:00:04.493933 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:00:04.493939 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:00:04.493944 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:00:04.493987 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:00:04.494465 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:00:04.494963 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:00:04.494988 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:00:04.494994 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:00:04.495001 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:00:04.495041 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:00:04.495485 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:00:04.496002 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:00:04.496027 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:00:04.496033 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:00:04.496038 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:00:04.496065 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:00:04.496401 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:00:04.496768 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:00:04.496787 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:00:04.496792 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:00:04.496797 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:00:04.498363 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:00:04.498415 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:00:04.498424 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:00:04.498444 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:00:04.515165 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:00:04.515736 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:00:04.516277 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:00:04.516302 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:00:04.516309 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:00:04.516316 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:00:04.516345 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:00:07.443588 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:00:07.444790 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:00:09.408258 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:00:09.409906 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:00:11.445635 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:00:11.447117 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:00:13.511631 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:00:13.512434 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:00:16.333183 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:00:16.336626 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:00:16.336862 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:00:16.337416 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:00:17.725372 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:00:20.549195 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:00:23.391023 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:01:33.410733 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 12:01:34.909650 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:01:36.240009 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:01:36.240260 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:01:36.595422 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 12:01:36.595716 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:01:37.997961 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 12:01:39.338051 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 12:01:40.814115 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:01:41.166148 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:01:41.166332 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:01:44.289664 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:01:44.289832 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:01:44.789311 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:01:44.789490 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:01:45.168132 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:01:45.168293 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:01:47.490381 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:01:47.490560 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:01:50.086636 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:01:50.086823 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:02:06.579293 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:02:06.579501 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:02:26.004941 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:02:26.005109 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:02:37.833636 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 12:02:37.833763 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:02:39.152562 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 12:02:40.533691 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 12:02:41.844977 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 12:02:43.329465 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 12:02:44.607609 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 12:02:46.003633 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 12:02:47.327816 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 12:02:48.779388 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 12:02:50.128689 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 12:02:51.549461 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 12:02:52.880010 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 12:02:54.319438 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 12:02:55.646170 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 12:02:57.080928 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 12:02:58.478091 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 12:02:59.934487 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 12:03:01.234243 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 12:03:02.630053 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 12:03:03.953752 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 12:03:05.432855 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 12:03:06.768816 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 12:03:08.191514 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 12:03:09.525699 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 12:03:10.981192 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 12:03:12.331754 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 12:03:12.332191 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:03:13.737722 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 12:03:13.737987 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:03:15.065576 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 12:03:15.066028 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:03:16.519831 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:03:16.521174 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:03:16.521261 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:03:16.521303 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:03:16.521342 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:03:16.521379 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:03:16.521427 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:03:16.521466 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:03:16.521507 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:03:16.521532 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:03:16.521597 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:03:16.521647 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:03:16.521713 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:03:16.522145 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:03:16.522244 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:03:16.522337 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:03:16.522361 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:03:16.522394 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:03:16.522445 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:03:16.522680 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:03:16.522731 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:03:16.522836 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:03:16.538340 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:03:16.538594 1 metrics.cc:757] Collecting CPU metrics
I0821 12:03:16.538750 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:03:16.538780 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:03:16.538816 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:03:16.538995 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:03:16.539005 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:03:16.539185 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:03:16.539259 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:03:16.539303 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:03:16.545494 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:03:16.546131 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:03:16.553938 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:03:16.554944 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:03:16.555255 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:03:16.557319 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:03:16.557324 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:03:16.567574 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:03:16.567630 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:03:16.567874 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:03:16.567978 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:03:16.569636 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:03:16.569671 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:03:16.569711 1 server.cc:295] All models are stopped, unloading models
I0821 12:03:16.570066 1 server.cc:302] Timeout 30: Found 19 live models and 0 in-flight non-inference requests
I0821 12:03:16.590243 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:03:16.591404 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:03:16.599829 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:03:16.599836 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:03:16.600004 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:03:16.611583 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:03:16.612443 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:03:16.618541 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:03:16.618730 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:03:17.570550 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 12:03:17.646242 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:03:17.695489 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:03:17.710184 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:03:17.723109 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 12:03:17.820878 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:03:17.824687 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:03:17.863995 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:03:17.891722 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:03:17.905734 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:03:17.965040 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:03:18.571466 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:19.571871 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:20.572378 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:21.572788 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:22.573160 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:23.573538 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:24.573967 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:25.574155 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:26.574355 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 12:03:27.158937 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 12:03:27.181565 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:03:27.277119 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:03:27.334674 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:03:27.574555 1 server.cc:302] Timeout 19: Found 0 live models and 0 in-flight non-inference requests
I0821 12:03:33.629220 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fd39c000000' with size 268435456
I0821 12:03:33.629547 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:03:33.634577 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:03:33.634609 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:03:33.634614 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:03:33.634618 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:03:33.634654 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:03:33.634687 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:03:33.634713 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:03:33.634740 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:03:33.635015 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:03:33.635090 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:03:33.635148 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:03:33.635179 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:03:33.635229 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:03:33.635260 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:03:33.635284 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:03:33.635306 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:03:33.635567 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:03:33.635596 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:03:33.635641 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:03:33.635691 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:03:33.635724 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:03:33.635751 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:03:33.636805 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:03:33.636844 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:03:33.636879 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:03:33.636891 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:03:33.992226 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:03:33.992281 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:03:33.992289 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:03:33.994242 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:03:33.994766 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:03:33.995134 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:03:33.995153 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:03:33.995157 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:03:33.995162 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:03:33.995195 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:03:33.995648 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:03:33.996176 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:03:33.996202 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:03:33.996210 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:03:33.996218 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:03:33.997879 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:03:33.997950 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:03:33.997959 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:03:33.997967 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:03:34.012245 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:03:34.012829 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:03:34.013426 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:03:34.013452 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:03:34.013460 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:03:34.013467 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:03:34.013487 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:03:34.013792 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:03:34.014169 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:03:34.014189 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:03:34.014194 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:03:34.014199 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:03:34.014234 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:03:34.810855 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:03:34.811108 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:03:36.792805 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:03:36.794170 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:03:38.705065 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:03:38.705688 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:03:41.185271 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:03:43.655239 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:03:50.163388 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:03:53.953897 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:03:55.916190 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:03:55.916897 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:03:55.917360 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:03:55.917527 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:03:55.917621 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:03:55.917702 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:03:55.917894 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:03:55.918147 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:03:55.918790 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:04:55.124435 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 12:04:56.473562 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 12:04:57.808291 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 12:04:59.232628 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:04:59.695290 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:04:59.695438 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:05:00.029036 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:05:00.029193 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:05:00.349687 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 12:05:00.349946 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:05:01.643448 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:05:01.949772 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:05:01.949925 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:05:03.628005 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:05:03.630158 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:05:04.750140 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:05:04.750764 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:05:07.394485 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:05:07.394808 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:05:10.439131 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:05:10.439287 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:05:12.702551 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:05:12.702719 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:05:31.662103 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:05:31.666361 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:05:48.391032 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:05:48.391360 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:05:59.717581 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 12:05:59.717813 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:06:01.085457 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 12:06:02.445830 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 12:06:03.875906 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 12:06:05.160444 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 12:06:06.456465 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 12:06:07.819147 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 12:06:09.250198 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 12:06:10.535671 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 12:06:11.847439 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 12:06:13.217927 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 12:06:14.671758 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 12:06:15.977068 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 12:06:17.287873 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 12:06:18.660186 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 12:06:20.121875 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 12:06:21.507604 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 12:06:22.846464 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 12:06:24.230152 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 12:06:25.616979 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 12:06:26.897713 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 12:06:28.200186 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 12:06:29.656342 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 12:06:31.034569 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 12:06:31.034922 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:06:32.350398 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 12:06:33.659137 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 12:06:33.659604 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:06:35.105271 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 12:06:36.472698 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 12:06:36.473006 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:06:37.941380 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:06:37.943354 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:06:37.943449 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:06:37.943492 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:06:37.943537 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:06:37.943589 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:06:37.943647 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:06:37.943713 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:06:37.943774 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:06:37.943841 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:06:37.943913 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:06:37.943971 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:06:37.944016 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:06:37.944155 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:06:37.944209 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:06:37.944260 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:06:37.944351 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:06:37.944402 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:06:37.944440 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:06:37.946918 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:06:37.946996 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:06:37.947143 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:06:37.965300 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:06:37.965586 1 metrics.cc:757] Collecting CPU metrics
I0821 12:06:37.965767 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:06:37.965820 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:06:37.965876 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:06:37.966079 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:06:37.966084 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:06:37.966236 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:06:37.966437 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:06:37.966311 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:06:37.966527 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:06:37.967119 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:06:37.967236 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:06:37.967306 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:06:37.967426 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:06:37.967675 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:06:37.967937 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:06:37.976131 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:06:37.976395 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:06:37.976425 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:06:37.976771 1 server.cc:295] All models are stopped, unloading models
I0821 12:06:37.976804 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:06:37.976840 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:06:37.977136 1 server.cc:302] Timeout 30: Found 21 live models and 0 in-flight non-inference requests
I0821 12:06:37.987903 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:06:37.988066 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:06:37.997354 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:06:37.997480 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:06:38.012862 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:06:38.012923 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:06:38.013001 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:06:38.013172 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:06:38.013209 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:06:38.013359 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:06:38.977918 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 12:06:39.024770 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:06:39.025647 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:06:39.089379 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:06:39.127701 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 12:06:39.168157 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:06:39.171501 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:06:39.202450 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:06:39.210136 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:06:39.385655 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:06:39.410203 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:06:39.978438 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:40.978752 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:41.979128 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:42.979423 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:43.979739 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:44.980127 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:45.980412 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:46.980709 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:47.981029 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 12:06:48.589169 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 12:06:48.615454 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:06:48.976926 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:06:48.981338 1 server.cc:302] Timeout 19: Found 1 live models and 0 in-flight non-inference requests
I0821 12:06:48.993106 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:06:49.981639 1 server.cc:302] Timeout 18: Found 0 live models and 0 in-flight non-inference requests
I0821 12:06:56.017336 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f47e6000000' with size 268435456
I0821 12:06:56.017679 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:06:56.022764 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:06:56.022790 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:06:56.022795 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:06:56.022798 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:06:56.022835 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:06:56.022870 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:06:56.022898 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:06:56.022940 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:06:56.022996 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:06:56.023042 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:06:56.023086 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:06:56.023117 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:06:56.023146 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:06:56.023177 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:06:56.023206 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:06:56.023232 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:06:56.024416 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:06:56.024444 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:06:56.024586 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:06:56.027514 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:06:56.027569 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:06:56.027599 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:06:56.027670 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:06:56.027700 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:06:56.027741 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:06:56.027770 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:06:56.386383 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:06:56.386454 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:06:56.386464 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:06:56.389110 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:06:56.389611 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:06:56.389974 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:06:56.389992 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:06:56.389997 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:06:56.390001 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:06:56.390048 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:06:56.390367 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:06:56.390782 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:06:56.390802 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:06:56.390807 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:06:56.390811 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:06:56.390847 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:06:56.391244 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:06:56.391623 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:06:56.391644 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:06:56.391649 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:06:56.391654 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:06:56.391688 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:06:56.392126 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:06:56.392537 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:06:56.392558 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:06:56.392564 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:06:56.392569 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:06:56.392627 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:06:56.393261 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:06:56.393870 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:06:56.393904 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:06:56.393913 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:06:56.393921 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:06:56.395656 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:06:56.395726 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:06:56.395739 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:06:56.395747 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:06:56.406287 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:06:58.944532 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:06:58.945640 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:07:00.728491 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:07:00.730231 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:07:00.732209 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:07:00.732481 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:07:03.485815 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:07:05.319083 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:07:05.320187 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:07:09.209588 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:07:15.758989 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:07:18.244346 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:07:19.980945 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:07:19.981589 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:07:19.982171 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:08:20.514238 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 12:08:21.906779 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 12:08:23.366909 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:08:23.704642 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 12:08:23.704942 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:08:25.083064 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:08:25.405114 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:08:25.405241 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:08:25.875312 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:08:25.875508 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:08:26.172169 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 12:08:26.172362 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:08:27.449771 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:08:28.546845 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:08:28.547198 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:08:31.801124 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:08:31.801305 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:08:34.447311 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:08:34.447510 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:08:36.768508 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:08:36.768695 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:08:53.375879 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:08:53.376041 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:09:12.726691 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:09:12.726865 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:09:24.461957 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 12:09:24.462167 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:09:25.817165 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 12:09:27.300025 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 12:09:28.739742 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 12:09:30.019737 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 12:09:31.338822 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 12:09:32.753273 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 12:09:34.142687 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 12:09:35.421567 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 12:09:36.763911 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 12:09:38.216281 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 12:09:39.593604 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 12:09:40.911197 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 12:09:42.176256 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 12:09:43.644361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 12:09:45.022610 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 12:09:46.313682 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 12:09:47.638250 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 12:09:49.124367 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 12:09:50.517711 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 12:09:51.825626 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 12:09:53.114577 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 12:09:54.576780 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 12:09:55.978800 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 12:09:57.293052 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 12:09:58.614190 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 12:09:58.614417 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:10:00.126091 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 12:10:00.126381 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:10:01.545039 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 12:10:01.545300 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:10:02.897227 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:10:02.899173 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:10:02.899265 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:10:02.899312 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:10:02.899362 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:10:02.899421 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:10:02.899468 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:10:02.899507 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:10:02.899541 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:10:02.899583 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:10:02.899630 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:10:02.899696 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:10:02.899751 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:10:02.900172 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:10:02.900254 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:10:02.900307 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:10:02.900388 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:10:02.900455 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:10:02.900501 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:10:02.900602 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:10:02.900657 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:10:02.900770 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:10:02.917031 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:10:02.917284 1 metrics.cc:757] Collecting CPU metrics
I0821 12:10:02.917435 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:10:02.917465 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:10:02.917502 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:10:02.917685 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:10:02.917735 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:10:02.917772 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:10:02.917825 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:10:02.917876 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:10:02.918033 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:10:02.918509 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:10:02.918671 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:10:02.918898 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:10:02.919060 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:10:02.919135 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:10:02.919188 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:10:02.919799 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:10:02.920101 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:10:02.920394 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:10:02.920573 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:10:02.920898 1 server.cc:295] All models are stopped, unloading models
I0821 12:10:02.920941 1 server.cc:302] Timeout 30: Found 20 live models and 0 in-flight non-inference requests
I0821 12:10:02.921377 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:10:02.931730 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:10:02.932699 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:10:02.948966 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:10:02.949115 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:10:02.964333 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:10:02.964399 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:10:02.964468 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:10:02.964512 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:10:02.965945 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:10:02.966103 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:10:03.933460 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 12:10:03.972326 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:10:03.998420 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:10:04.053814 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:10:04.094489 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:10:04.104333 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:10:04.152414 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:10:04.202561 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 12:10:04.341036 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:10:04.364401 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:10:04.403346 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:10:04.933642 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:05.933807 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:06.933967 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:07.934106 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:08.934258 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:09.934419 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:10.934590 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:11.934741 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:12.934910 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 12:10:13.328632 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:10:13.431561 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 12:10:13.935075 1 server.cc:302] Timeout 19: Found 2 live models and 0 in-flight non-inference requests
I0821 12:10:14.186390 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:10:14.348911 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:10:14.935228 1 server.cc:302] Timeout 18: Found 0 live models and 0 in-flight non-inference requests
I0821 12:10:21.060247 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f0f8e000000' with size 268435456
I0821 12:10:21.060587 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:10:21.065637 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:10:21.065772 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:10:21.065846 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:10:21.065905 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:10:21.066000 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:10:21.066109 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:10:21.066209 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:10:21.066339 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:10:21.066503 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:10:21.066616 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:10:21.066731 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:10:21.066833 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:10:21.067012 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:10:21.067124 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:10:21.067223 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:10:21.067332 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:10:21.067532 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:10:21.067624 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:10:21.067729 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:10:21.067857 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:10:21.068003 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:10:21.068119 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:10:21.068223 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:10:21.068343 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:10:21.068451 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:10:21.068547 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:10:21.445387 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:10:21.445454 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:10:21.445462 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:10:21.448111 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:10:21.448814 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:10:21.449435 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:10:21.449468 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:10:21.449477 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:10:21.449484 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:10:21.449517 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:10:21.449869 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:10:21.450321 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:10:21.450347 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:10:21.450358 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:10:21.450366 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:10:21.450403 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:10:24.093293 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:10:24.093864 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:10:24.094349 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:10:24.094375 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:10:24.094382 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:10:24.094388 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:10:24.094461 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
I0821 12:10:24.094687 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
W0821 12:10:24.094974 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:10:24.095416 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:10:24.095440 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:10:24.095446 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:10:24.095450 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:10:24.096732 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:10:24.096791 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:10:24.096804 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:10:24.096809 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:10:24.105850 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:10:24.106569 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:10:24.107180 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:10:24.107215 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:10:24.107223 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:10:24.107230 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:10:24.107290 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:10:24.114164 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:10:24.114368 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:10:26.869378 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:10:29.303730 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:10:37.098284 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:10:38.820648 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:10:38.821835 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:10:40.602035 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:10:40.603612 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:10:42.496698 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:10:42.497292 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:10:44.952133 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:10:44.952873 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:11:44.232549 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 12:11:45.640552 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 12:11:47.138959 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 12:11:48.399861 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:11:48.749320 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:11:48.749458 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:11:49.098623 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:11:49.098868 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:11:49.539721 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:11:49.539845 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:11:49.842255 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 12:11:49.842440 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:11:51.119572 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:11:52.220449 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:11:52.220750 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:11:54.836361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:11:54.836562 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:11:57.099733 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:11:57.099901 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:12:00.181592 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:12:00.181762 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:12:16.539742 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:12:16.539953 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:12:35.709491 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:12:35.709671 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:12:47.147461 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 12:12:47.147690 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:12:48.544677 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 12:12:49.985233 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 12:12:51.290779 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 12:12:52.624365 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 12:12:53.995776 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 12:12:55.466559 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 12:12:56.786086 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 12:12:58.100582 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 12:12:59.500417 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 12:13:00.944371 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 12:13:02.270632 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 12:13:03.574513 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 12:13:04.952140 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 12:13:06.421199 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 12:13:07.816201 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 12:13:09.160534 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 12:13:10.524259 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 12:13:11.984146 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 12:13:13.298735 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 12:13:14.608497 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 12:13:16.027814 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 12:13:17.490250 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 12:13:18.845981 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 12:13:20.202222 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 12:13:21.591986 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 12:13:21.592433 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:13:23.084427 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 12:13:23.084659 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:13:24.407510 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 12:13:24.408088 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:13:25.789168 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:13:25.790545 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:13:25.790627 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:13:25.790664 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:13:25.790702 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:13:25.790738 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:13:25.790779 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:13:25.790816 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:13:25.790853 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:13:25.790891 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:13:25.790987 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:13:25.791061 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:13:25.791128 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:13:25.791631 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:13:25.791766 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:13:25.791876 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:13:25.791977 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:13:25.792044 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:13:25.792088 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:13:25.792216 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:13:25.792271 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:13:25.792391 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:13:25.813254 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:13:25.813478 1 metrics.cc:757] Collecting CPU metrics
I0821 12:13:25.813612 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:13:25.813639 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:13:25.813679 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:13:25.813838 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:13:25.813926 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:13:25.813995 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:13:25.814052 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:13:25.814132 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:13:25.814377 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:13:25.814618 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:13:25.814746 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:13:25.815232 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:13:25.815295 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:13:25.815375 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:13:25.815427 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:13:25.815743 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:13:25.816359 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:13:25.817934 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:13:25.818515 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:13:25.818867 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:13:25.818889 1 server.cc:295] All models are stopped, unloading models
I0821 12:13:25.818939 1 server.cc:302] Timeout 30: Found 19 live models and 0 in-flight non-inference requests
I0821 12:13:25.832066 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:13:25.832464 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:13:25.855326 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:13:25.855600 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:13:25.856097 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:13:25.856142 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:13:25.856361 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:13:25.868620 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:13:25.879144 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:13:25.879335 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:13:26.819067 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 12:13:26.942619 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:13:26.996634 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:13:27.011828 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:13:27.038569 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:13:27.080271 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:13:27.091614 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 12:13:27.171146 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:13:27.195532 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:13:27.200448 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:13:27.262202 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:13:27.826143 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:28.826295 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:29.826441 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:30.826584 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:31.826730 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:32.826897 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:33.827062 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:34.827246 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:35.827744 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 12:13:36.420172 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:13:36.529700 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:13:36.684994 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 12:13:36.828186 1 server.cc:302] Timeout 19: Found 1 live models and 0 in-flight non-inference requests
I0821 12:13:36.835550 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:13:37.828398 1 server.cc:302] Timeout 18: Found 0 live models and 0 in-flight non-inference requests
I0821 12:13:43.860697 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7ff41c000000' with size 268435456
I0821 12:13:43.861032 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:13:43.866104 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:13:43.866135 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:13:43.866140 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:13:43.866144 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:13:43.866181 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:13:43.866215 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:13:43.866241 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:13:43.866269 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:13:43.866302 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:13:43.866350 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:13:43.866392 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:13:43.866444 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:13:43.866499 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:13:43.866532 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:13:43.866565 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:13:43.866586 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:13:43.866707 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:13:43.866731 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:13:43.866763 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:13:43.866918 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:13:43.867121 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:13:43.867289 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:13:43.867329 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:13:43.867360 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:13:43.867396 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:13:43.867408 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:13:44.231147 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:13:44.231209 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:13:44.231218 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:13:44.233315 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:13:44.233867 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:13:44.234293 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:13:44.234313 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:13:44.234318 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:13:44.234323 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:13:44.234343 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:13:44.234742 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:13:44.235176 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:13:44.235200 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:13:44.235205 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:13:44.235210 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:13:44.236595 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:13:44.236765 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:13:44.236874 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:13:44.236960 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:13:44.246997 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:13:46.900159 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:13:46.901050 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:13:46.901459 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:13:46.908206 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:13:46.908337 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:13:46.908444 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:13:46.908544 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:13:46.908709 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:13:48.801925 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:13:48.802426 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:13:48.802983 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:13:48.803012 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:13:48.803021 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:13:48.803029 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:13:48.803077 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
I0821 12:13:48.803147 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
W0821 12:13:48.803517 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:13:48.804015 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:13:48.804042 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:13:48.804047 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:13:48.804052 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:13:48.804541 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:13:52.920769 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:13:55.408991 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:13:57.905116 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:14:02.025372 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:14:02.025998 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:15:04.811795 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:15:06.512783 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:15:06.515315 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:15:08.351375 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:15:08.352700 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:15:08.356208 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 12:15:08.356514 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:15:09.683464 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:15:10.012212 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 12:15:10.013173 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:15:11.287001 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 12:15:12.726721 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 12:15:14.093678 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:15:14.457226 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:15:14.457360 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:15:15.577681 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:15:15.578220 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:15:15.940706 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:15:15.941286 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:15:19.472439 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:15:19.472585 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:15:22.155703 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:15:22.156018 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:15:22.715619 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:15:22.715770 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:15:25.113949 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:15:25.114123 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:15:41.172425 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:15:41.172566 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:15:53.235093 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:15:53.235479 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:16:12.663971 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 12:16:12.664117 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:16:13.976284 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 12:16:15.330181 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 12:16:16.863903 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 12:16:18.266339 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 12:16:19.590422 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 12:16:20.910039 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 12:16:22.364732 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 12:16:23.743188 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 12:16:25.077421 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 12:16:26.370731 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 12:16:27.824358 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 12:16:29.220063 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 12:16:30.524246 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 12:16:31.910287 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 12:16:33.422524 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 12:16:34.786311 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 12:16:36.092664 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 12:16:37.462347 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 12:16:38.930884 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 12:16:40.328962 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 12:16:41.646127 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 12:16:42.958127 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 12:16:44.393857 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 12:16:45.780345 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 12:16:47.151648 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 12:16:47.151890 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:16:48.503267 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 12:16:48.503502 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:16:50.024565 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 12:16:50.024694 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:16:51.503132 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:16:51.504662 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:16:51.504753 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:16:51.504798 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:16:51.504842 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:16:51.504880 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:16:51.504920 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:16:51.504973 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:16:51.505026 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:16:51.505085 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:16:51.505268 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:16:51.505691 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:16:51.505754 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:16:51.505875 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:16:51.505969 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:16:51.506022 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:16:51.506068 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:16:51.506123 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:16:51.506163 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:16:51.506478 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:16:51.506560 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:16:51.506675 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:16:51.524830 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:16:51.525076 1 metrics.cc:757] Collecting CPU metrics
I0821 12:16:51.525237 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:16:51.525273 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:16:51.525323 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:16:51.525536 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:16:51.525585 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:16:51.525809 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:16:51.525945 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:16:51.525747 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:16:51.525707 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:16:51.526384 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:16:51.526409 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:16:51.526683 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:16:51.526851 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:16:51.526957 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:16:51.527155 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:16:51.527872 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:16:51.528091 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:16:51.528415 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:16:51.528460 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:16:51.528769 1 server.cc:295] All models are stopped, unloading models
I0821 12:16:51.528772 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:16:51.528821 1 server.cc:302] Timeout 30: Found 20 live models and 0 in-flight non-inference requests
I0821 12:16:51.538146 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:16:51.538460 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:16:51.546717 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:16:51.546890 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:16:51.555014 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:16:51.555169 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:16:51.566845 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:16:51.566892 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:16:51.567011 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:16:51.567149 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:16:52.541116 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 12:16:52.662534 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:16:52.699854 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:16:52.701573 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:16:52.720404 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:16:52.748250 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:16:52.787383 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:16:52.874643 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:16:52.920047 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:16:52.986455 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 12:16:53.013259 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:16:53.541326 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 12:16:54.541487 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 12:16:55.541639 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 12:16:56.541791 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 12:16:57.541957 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 12:16:58.542124 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 12:16:59.542308 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 12:17:00.542865 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 12:17:01.543010 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 12:17:02.241373 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:17:02.351181 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:17:02.410070 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 12:17:02.543152 1 server.cc:302] Timeout 19: Found 1 live models and 0 in-flight non-inference requests
I0821 12:17:02.739771 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:17:03.543404 1 server.cc:302] Timeout 18: Found 0 live models and 0 in-flight non-inference requests
I0821 12:17:09.646976 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fb93c000000' with size 268435456
I0821 12:17:09.647343 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:17:09.652484 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:17:09.652619 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:17:09.652774 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:17:09.652915 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:17:09.653101 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:17:09.653313 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:17:09.653486 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:17:09.653687 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:17:09.653881 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:17:09.654067 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:17:09.654239 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:17:09.654414 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:17:09.654648 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:17:09.654812 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:17:09.654978 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:17:09.655155 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:17:09.655396 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:17:09.655545 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:17:09.655712 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:17:09.655920 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:17:09.656118 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:17:09.656317 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:17:09.656526 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:17:09.656736 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:17:09.656950 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:17:09.657160 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:17:10.002754 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:17:10.002822 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:17:10.002830 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:17:10.005819 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:17:10.006807 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:17:10.007492 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:17:10.007536 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:17:10.007544 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:17:10.007551 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:17:10.007623 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:17:12.672400 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:17:12.672831 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:17:12.673280 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:17:12.673305 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:17:12.673311 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:17:12.673315 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:17:12.673356 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:17:12.674795 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:17:14.498528 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:17:14.499177 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:17:14.499826 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:17:14.499866 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:17:14.499875 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:17:14.499883 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:17:14.499931 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:17:14.499937 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:17:16.377343 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:17:16.378094 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:17:16.378484 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:17:16.378916 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:17:16.379048 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:17:16.379158 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:17:16.379262 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:17:16.379802 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:17:19.161913 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:17:21.930991 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:17:24.429982 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:17:32.369409 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:17:32.369970 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:17:32.370557 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:17:32.370590 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:17:32.370599 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:17:32.370623 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:17:32.370677 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:17:32.375259 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:17:32.375684 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:17:34.105459 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 12:17:34.107174 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:17:35.459420 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 12:17:36.892508 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 12:17:38.405455 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 12:17:39.731614 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:17:40.100844 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:17:40.100996 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:17:40.463424 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:17:40.463579 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:17:40.957148 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:17:40.957377 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:17:41.268752 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:17:41.270321 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:17:41.270400 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:17:41.270411 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:17:41.270420 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:17:41.281707 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 12:17:42.641473 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 12:17:44.136915 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 12:17:45.425410 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 12:17:46.686832 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:17:46.687421 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:18:44.488782 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 12:18:45.875963 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0821 12:18:47.306644 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 12:18:48.591463 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 12:18:49.951660 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:18:51.081526 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:18:51.081955 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:18:54.159514 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:18:54.159681 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:18:57.649012 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:18:57.649176 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:18:59.874229 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:18:59.874362 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:19:16.386700 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:19:16.386884 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:19:34.996675 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:19:34.996876 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:19:46.687907 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 12:19:46.688101 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:19:48.075751 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0821 12:19:49.579032 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 12:19:50.873180 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 12:19:52.198134 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 12:19:53.580040 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0821 12:19:55.045153 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 12:19:56.343876 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 12:19:57.645053 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 12:19:59.004811 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0821 12:20:00.483122 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 12:20:01.792639 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 12:20:03.128844 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 12:20:04.553549 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0821 12:20:06.028612 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 12:20:07.353362 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 12:20:08.710215 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 12:20:10.126198 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0821 12:20:10.126512 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:20:11.567429 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 12:20:11.567635 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:20:12.892269 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 12:20:12.892565 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:20:14.222967 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:20:14.224652 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:20:14.224747 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:20:14.224788 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:20:14.224829 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:20:14.224865 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:20:14.224922 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:20:14.224959 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:20:14.225004 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:20:14.225063 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:20:14.225115 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:20:14.225211 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:20:14.225303 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:20:14.225474 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:20:14.225535 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:20:14.225581 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:20:14.225641 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:20:14.225687 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:20:14.225734 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:20:14.225831 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:20:14.225883 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:20:14.225987 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:20:14.243170 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:20:14.243398 1 metrics.cc:757] Collecting CPU metrics
I0821 12:20:14.243532 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:20:14.243567 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:20:14.243604 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:20:14.243760 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:20:14.243827 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:20:14.243985 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:20:14.244022 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:20:14.244028 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:20:14.244332 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:20:14.244536 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:20:14.244634 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:20:14.244832 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:20:14.244970 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:20:14.245025 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:20:14.245139 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:20:14.245586 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:20:14.245963 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:20:14.245994 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:20:14.246584 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:20:14.246785 1 server.cc:295] All models are stopped, unloading models
I0821 12:20:14.246815 1 server.cc:302] Timeout 30: Found 20 live models and 0 in-flight non-inference requests
I0821 12:20:14.246995 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:20:14.271145 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:20:14.272027 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:20:14.278879 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:20:14.279068 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:20:14.300403 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:20:14.300579 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:20:14.305756 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:20:14.305786 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:20:14.306048 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:20:14.306162 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:20:15.252554 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 12:20:15.330745 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:20:15.361180 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:20:15.423556 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:20:15.465732 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:20:15.490111 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:20:15.503649 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:20:15.516537 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 12:20:15.529490 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:20:15.608216 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:20:15.612766 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:20:16.254589 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:17.254781 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:18.254946 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:19.255099 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:20.255257 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:21.255426 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:22.255618 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:23.255848 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:24.256034 1 server.cc:302] Timeout 20: Found 4 live models and 0 in-flight non-inference requests
I0821 12:20:24.872884 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:20:24.961405 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:20:25.061902 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:20:25.229402 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 12:20:25.256198 1 server.cc:302] Timeout 19: Found 0 live models and 0 in-flight non-inference requests
I0821 12:20:31.397241 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7efd26000000' with size 268435456
I0821 12:20:31.397590 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:20:31.402648 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:20:31.402676 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:20:31.402682 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:20:31.402685 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:20:31.402722 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:20:31.402755 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:20:31.402780 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:20:31.402808 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:20:31.403050 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:20:31.403100 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:20:31.403143 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:20:31.403174 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:20:31.403204 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:20:31.403279 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:20:31.403321 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:20:31.403346 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:20:31.403648 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:20:31.403682 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:20:31.403716 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:20:31.403751 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:20:31.403782 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:20:31.403812 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:20:31.403846 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:20:31.403873 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:20:31.403904 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:20:31.405355 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:20:31.766304 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:20:31.766368 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:20:31.766374 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:20:31.768727 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:20:31.769261 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:20:31.769639 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:20:31.769662 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:20:31.769667 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:20:31.769672 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:20:31.769710 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:20:31.770274 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:20:31.770915 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:20:31.770949 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:20:31.770958 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:20:31.770965 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:20:31.771004 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:20:31.771386 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:20:31.771783 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:20:31.771807 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:20:31.771813 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:20:31.771818 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:20:31.771854 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:20:31.772357 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:20:31.772926 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:20:31.772957 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:20:31.772965 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:20:31.772972 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:20:31.773007 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:20:31.773360 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:20:31.773749 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:20:31.773772 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:20:31.773785 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:20:31.773790 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:20:31.773829 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:20:32.563372 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:20:32.563682 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:20:34.316855 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:20:34.320071 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:20:36.021578 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:20:36.022536 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:20:38.463454 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:20:40.360679 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:20:40.361441 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:20:42.807566 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:20:45.294191 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:20:53.173401 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:20:55.064131 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:20:55.064206 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:20:55.064218 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:20:55.064224 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:20:55.065185 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:20:55.073142 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 12:20:56.419241 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 12:20:57.696875 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0821 12:20:59.150217 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:20:59.485223 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:20:59.485372 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:20:59.798392 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:20:59.798589 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:21:00.254370 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:21:00.254522 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:21:00.560441 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 12:21:00.560592 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:21:01.940330 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:21:01.940786 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:22:01.242274 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 12:22:02.567645 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 12:22:03.852198 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0821 12:22:03.852530 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 12:22:05.251645 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
E0821 12:22:05.268877 1 model_lifecycle.cc:597] failed to load 'asr_pyctc_decoder_OR' version 1: Internal: model.py does not exist in the model repository path: /models/model_repository/asr_pyctc_decoder_OR/1/model.py
I0821 12:22:06.377804 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:22:06.378117 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:22:10.724067 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:22:10.724229 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:22:13.760926 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:22:13.761269 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:22:16.127207 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:22:16.127376 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:22:16.127441 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
E0821 12:22:16.127495 1 model_lifecycle.cc:597] failed to load 'itn_OR' version 1: Internal: model.py does not exist in the model repository path: /models/model_repository/itn_OR/1/model.py
I0821 12:22:33.540593 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:22:33.540754 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:22:46.030166 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 12:22:46.030335 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:22:47.335980 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 12:22:48.636187 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 12:22:50.003785 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 12:22:51.355599 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 12:22:52.713252 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 12:22:54.122470 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 12:22:55.463174 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 12:22:56.777786 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 12:22:58.164309 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 12:22:59.492403 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 12:23:00.818310 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 12:23:02.210577 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 12:23:03.519037 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 12:23:04.881963 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 12:23:06.223125 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 12:23:07.519045 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:23:07.521917 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 12:23:08.849987 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 12:23:08.850215 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:23:10.218472 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
E0821 12:23:10.219414 1 model_repository_manager.cc:487] Invalid argument: ensemble 'asr_pyctc_ensemble_OR' depends on 'asr_pyctc_decoder_OR' which has no loaded version
E0821 12:23:10.219473 1 model_repository_manager.cc:487] Invalid argument: ensemble 'pipeline_pyctc_ensemble_OR' depends on 'itn_OR' which has no loaded version
I0821 12:23:10.219544 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:23:10.219584 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:23:10.219621 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:23:10.219662 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:23:10.219703 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:23:10.219748 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:23:10.219788 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:23:10.219861 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:23:10.219949 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:23:10.220029 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:23:10.220410 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:23:10.220461 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:23:10.220545 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:23:10.220638 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:23:10.220761 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:23:10.220810 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:23:10.220912 1 server.cc:633] 
+----------------------------+---------+---------------------------------------------------------------------------------------------------------------------------------------+
| Model                      | Version | Status                                                                                                                                |
+----------------------------+---------+---------------------------------------------------------------------------------------------------------------------------------------+
| asr_am_EN                  | 1       | READY                                                                                                                                 |
| asr_am_HI                  | 1       | READY                                                                                                                                 |
| asr_am_OR                  | 1       | READY                                                                                                                                 |
| asr_am_TA                  | 1       | READY                                                                                                                                 |
| asr_preprocessor           | 1       | READY                                                                                                                                 |
| asr_pyctc_decoder_EN       | 1       | READY                                                                                                                                 |
| asr_pyctc_decoder_HI       | 1       | READY                                                                                                                                 |
| asr_pyctc_decoder_OR       | 1       | UNAVAILABLE: Internal: model.py does not exist in the model repository path: /models/model_repository/asr_pyctc_decoder_OR/1/model.py |
| asr_pyctc_decoder_TA       | 1       | READY                                                                                                                                 |
| asr_pyctc_ensemble_EN      | 1       | READY                                                                                                                                 |
| asr_pyctc_ensemble_HI      | 1       | READY                                                                                                                                 |
| asr_pyctc_ensemble_TA      | 1       | READY                                                                                                                                 |
| entity_EN                  | 1       | READY                                                                                                                                 |
| entity_HI                  | 1       | READY                                                                                                                                 |
| entity_OR                  | 1       | READY                                                                                                                                 |
| entity_TA                  | 1       | READY                                                                                                                                 |
| intent_ensemble            | 1       | READY                                                                                                                                 |
| intent_model_onnx          | 1       | READY                                                                                                                                 |
| intent_postprocessor       | 1       | READY                                                                                                                                 |
| intent_preprocessor        | 1       | READY                                                                                                                                 |
| itn_EN                     | 1       | READY                                                                                                                                 |
| itn_HI                     | 1       | READY                                                                                                                                 |
| itn_OR                     | 1       | UNAVAILABLE: Internal: model.py does not exist in the model repository path: /models/model_repository/itn_OR/1/model.py               |
| itn_TA                     | 1       | READY                                                                                                                                 |
| pipeline_pyctc_ensemble_EN | 1       | READY                                                                                                                                 |
| pipeline_pyctc_ensemble_HI | 1       | READY                                                                                                                                 |
| pipeline_pyctc_ensemble_TA | 1       | READY                                                                                                                                 |
+----------------------------+---------+---------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:23:10.236428 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:23:10.236654 1 metrics.cc:757] Collecting CPU metrics
I0821 12:23:10.236813 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:23:10.236862 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:23:10.236895 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:23:10.237057 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:23:10.237084 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:23:10.237210 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:23:10.237233 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:23:10.237166 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:23:10.237561 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:23:10.238030 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:23:10.238085 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:23:10.238221 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:23:10.238316 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:23:10.238388 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:23:10.238875 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:23:10.239831 1 server.cc:295] All models are stopped, unloading models
I0821 12:23:10.240005 1 server.cc:302] Timeout 30: Found 19 live models and 0 in-flight non-inference requests
I0821 12:23:10.240227 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:23:10.240556 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:23:10.240830 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:23:10.249435 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:23:10.250171 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:23:10.284605 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:23:10.284763 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:23:10.284635 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:23:10.284785 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:23:10.284612 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:23:10.285494 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:23:10.285645 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:23:10.290952 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:23:11.245304 1 server.cc:302] Timeout 29: Found 12 live models and 0 in-flight non-inference requests
I0821 12:23:11.351904 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:23:11.383192 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:23:11.407574 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:23:11.603183 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:23:11.608613 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:23:11.627083 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:23:11.658189 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:23:11.694233 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:23:11.790655 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:23:12.246176 1 server.cc:302] Timeout 28: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:13.246376 1 server.cc:302] Timeout 27: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:14.247054 1 server.cc:302] Timeout 26: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:15.247195 1 server.cc:302] Timeout 25: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:16.247335 1 server.cc:302] Timeout 24: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:17.247471 1 server.cc:302] Timeout 23: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:18.247633 1 server.cc:302] Timeout 22: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:19.247799 1 server.cc:302] Timeout 21: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:20.248050 1 server.cc:302] Timeout 20: Found 3 live models and 0 in-flight non-inference requests
I0821 12:23:20.821735 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:23:20.992109 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:23:21.248433 1 server.cc:302] Timeout 19: Found 1 live models and 0 in-flight non-inference requests
I0821 12:23:21.256763 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:23:22.248680 1 server.cc:302] Timeout 18: Found 0 live models and 0 in-flight non-inference requests
I0821 12:23:28.453208 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fd4ec000000' with size 268435456
I0821 12:23:28.453573 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0821 12:23:28.458769 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:23:28.458972 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:23:28.459146 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:23:28.459323 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0821 12:23:28.459503 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0821 12:23:28.459732 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0821 12:23:28.459951 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0821 12:23:28.460185 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:23:28.460418 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:23:28.460656 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:23:28.460874 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:23:28.461089 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:23:28.461296 1 model_lifecycle.cc:459] loading: entity_HI:1
W0821 12:23:28.461637 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:23:28.461849 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:23:28.462086 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:23:28.462300 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:23:28.462544 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:23:28.462766 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:23:28.462975 1 model_lifecycle.cc:459] loading: itn_HI:1
W0821 12:23:28.463209 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:23:28.463394 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:23:28.823108 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:23:28.823163 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:23:28.823169 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:23:28.825003 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:23:28.825616 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:23:28.826094 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:23:28.826119 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:23:28.826124 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:23:28.826129 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:23:28.826178 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:23:31.332220 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:23:31.332890 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:23:31.333511 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:23:31.333547 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:23:31.333557 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:23:31.333566 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:23:31.333564 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:23:31.335294 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:23:31.335355 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:23:31.335372 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:23:31.335380 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
E0821 12:23:31.565468 1 model_lifecycle.cc:597] failed to load 'asr_greedy_decoder_EN' version 1: Internal: ModuleNotFoundError: No module named 'swig_decoders'

At:
  /models/model_repository/asr_greedy_decoder_EN/1/model.py(3): <module>
  <frozen importlib._bootstrap>(219): _call_with_frames_removed
  <frozen importlib._bootstrap_external>(848): exec_module
  <frozen importlib._bootstrap>(686): _load_unlocked
  <frozen importlib._bootstrap>(975): _find_and_load_unlocked
  <frozen importlib._bootstrap>(991): _find_and_load

E0821 12:23:31.756509 1 model_lifecycle.cc:597] failed to load 'asr_greedy_decoder_HI' version 1: Internal: ModuleNotFoundError: No module named 'swig_decoders'

At:
  /models/model_repository/asr_greedy_decoder_HI/1/model.py(3): <module>
  <frozen importlib._bootstrap>(219): _call_with_frames_removed
  <frozen importlib._bootstrap_external>(848): exec_module
  <frozen importlib._bootstrap>(686): _load_unlocked
  <frozen importlib._bootstrap>(975): _find_and_load_unlocked
  <frozen importlib._bootstrap>(991): _find_and_load

E0821 12:23:31.957816 1 model_lifecycle.cc:597] failed to load 'asr_greedy_decoder_TA' version 1: Internal: ModuleNotFoundError: No module named 'swig_decoders'

At:
  /models/model_repository/asr_greedy_decoder_TA/1/model.py(3): <module>
  <frozen importlib._bootstrap>(219): _call_with_frames_removed
  <frozen importlib._bootstrap_external>(848): exec_module
  <frozen importlib._bootstrap>(686): _load_unlocked
  <frozen importlib._bootstrap>(975): _find_and_load_unlocked
  <frozen importlib._bootstrap>(991): _find_and_load

I0821 12:23:31.957831 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_greedy_top1 (version 1)
W0821 12:23:31.958502 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_greedy_top1': not supported for pytorch backend
I0821 12:23:31.959053 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_greedy_top1'
I0821 12:23:31.959082 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_greedy_top1'
I0821 12:23:31.959090 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_greedy_top1'
I0821 12:23:31.959097 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_greedy_top1'
I0821 12:23:31.959154 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:23:31.959932 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:23:31.960575 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:23:31.960614 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:23:31.960625 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:23:31.960634 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:23:31.961067 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:23:34.407520 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:23:36.844076 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:23:43.340329 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:23:45.087976 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:23:45.088427 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:23:45.088854 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:23:45.088880 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:23:45.088886 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:23:45.088891 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:23:45.088965 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:23:45.089551 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:23:45.090090 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:24:23.848663 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_greedy_top1_0 (GPU device 0)
I0821 12:24:23.849931 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:24:23.850201 1 model_lifecycle.cc:694] successfully loaded 'asr_greedy_top1' version 1
I0821 12:24:23.854549 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0821 12:24:23.854809 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:24:25.253359 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0821 12:24:26.551599 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0821 12:24:27.830814 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:24:28.195177 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:24:28.195366 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:24:28.544981 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:24:28.545143 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:24:28.819997 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:24:28.820097 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:24:30.633812 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:24:30.635173 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:24:31.779718 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:24:31.780004 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:24:35.239837 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:24:35.240126 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:24:37.514181 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:24:37.514456 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:24:40.156757 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:24:40.156856 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:24:56.560490 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:24:56.560756 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:25:08.646958 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0821 12:25:08.647126 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:25:10.106952 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0821 12:25:11.460743 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0821 12:25:12.744161 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0821 12:25:14.196686 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0821 12:25:15.567891 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0821 12:25:16.909480 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0821 12:25:18.461303 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0821 12:25:19.832668 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0821 12:25:21.239561 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0821 12:25:22.678413 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0821 12:25:24.040446 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0821 12:25:25.368292 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0821 12:25:26.787119 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0821 12:25:28.166045 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0821 12:25:29.522340 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0821 12:25:31.002363 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0821 12:25:32.357762 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0821 12:25:33.672710 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0821 12:25:35.142198 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0821 12:25:35.142634 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:25:36.550977 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0821 12:25:36.551196 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:25:37.973053 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
E0821 12:25:37.974526 1 model_repository_manager.cc:487] Invalid argument: ensemble 'asr_greedy_ensemble_EN' depends on 'asr_greedy_decoder_EN' which has no loaded version
E0821 12:25:37.974693 1 model_repository_manager.cc:487] Invalid argument: ensemble 'asr_greedy_ensemble_HI' depends on 'asr_greedy_decoder_HI' which has no loaded version
E0821 12:25:37.974887 1 model_repository_manager.cc:487] Invalid argument: ensemble 'asr_greedy_ensemble_TA' depends on 'asr_greedy_decoder_TA' which has no loaded version
E0821 12:25:37.975034 1 model_repository_manager.cc:487] Invalid argument: ensemble 'pipeline_greedy_ensemble_EN' depends on 'asr_greedy_decoder_EN' which has no loaded version
E0821 12:25:37.975175 1 model_repository_manager.cc:487] Invalid argument: ensemble 'pipeline_greedy_ensemble_HI' depends on 'asr_greedy_decoder_HI' which has no loaded version
E0821 12:25:37.975315 1 model_repository_manager.cc:487] Invalid argument: ensemble 'pipeline_greedy_ensemble_TA' depends on 'asr_greedy_decoder_TA' which has no loaded version
I0821 12:25:37.975533 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:25:37.975726 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:25:37.975969 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:25:37.976259 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:25:37.976547 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:25:37.976829 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:25:37.977116 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:25:37.977399 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:25:37.977781 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:25:37.978031 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:25:37.978167 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:25:37.978261 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:25:37.978339 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:25:37.978455 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:25:37.978738 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:25:37.978832 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:25:37.979066 1 server.cc:633] 
+----------------------------+---------+-----------------------------------------------------------------------------+
| Model                      | Version | Status                                                                      |
+----------------------------+---------+-----------------------------------------------------------------------------+
| asr_am_EN                  | 1       | READY                                                                       |
| asr_am_HI                  | 1       | READY                                                                       |
| asr_am_TA                  | 1       | READY                                                                       |
| asr_greedy_decoder_EN      | 1       | UNAVAILABLE: Internal: ModuleNotFoundError: No module named 'swig_decoders' |
|                            |         |                                                                             |
|                            |         | At:                                                                         |
|                            |         |   /models/model_repository/asr_greedy_decoder_EN/1/model.py(3): <module>    |
|                            |         |   <frozen importlib._bootstrap>(219): _call_with_frames_removed             |
|                            |         |   <frozen importlib._bootstrap_external>(848): exec_module                  |
|                            |         |   <frozen importlib._bootstrap>(686): _load_unlocked                        |
|                            |         |   <frozen importlib._bootstrap>(975): _find_and_load_unlocked               |
|                            |         |   <frozen importlib._bootstrap>(991): _find_and_load                        |
| asr_greedy_decoder_HI      | 1       | UNAVAILABLE: Internal: ModuleNotFoundError: No module named 'swig_decoders' |
|                            |         |                                                                             |
|                            |         | At:                                                                         |
|                            |         |   /models/model_repository/asr_greedy_decoder_HI/1/model.py(3): <module>    |
|                            |         |   <frozen importlib._bootstrap>(219): _call_with_frames_removed             |
|                            |         |   <frozen importlib._bootstrap_external>(848): exec_module                  |
|                            |         |   <frozen importlib._bootstrap>(686): _load_unlocked                        |
|                            |         |   <frozen importlib._bootstrap>(975): _find_and_load_unlocked               |
|                            |         |   <frozen importlib._bootstrap>(991): _find_and_load                        |
| asr_greedy_decoder_TA      | 1       | UNAVAILABLE: Internal: ModuleNotFoundError: No module named 'swig_decoders' |
|                            |         |                                                                             |
|                            |         | At:                                                                         |
|                            |         |   /models/model_repository/asr_greedy_decoder_TA/1/model.py(3): <module>    |
|                            |         |   <frozen importlib._bootstrap>(219): _call_with_frames_removed             |
|                            |         |   <frozen importlib._bootstrap_external>(848): exec_module                  |
|                            |         |   <frozen importlib._bootstrap>(686): _load_unlocked                        |
|                            |         |   <frozen importlib._bootstrap>(975): _find_and_load_unlocked               |
|                            |         |   <frozen importlib._bootstrap>(991): _find_and_load                        |
| asr_greedy_top1            | 1       | READY                                                                       |
| asr_preprocessor           | 1       | READY                                                                       |
| asr_pyctc_decoder_EN       | 1       | READY                                                                       |
| asr_pyctc_decoder_HI       | 1       | READY                                                                       |
| asr_pyctc_decoder_TA       | 1       | READY                                                                       |
| asr_pyctc_ensemble_EN      | 1       | READY                                                                       |
| asr_pyctc_ensemble_HI      | 1       | READY                                                                       |
| asr_pyctc_ensemble_TA      | 1       | READY                                                                       |
| entity_EN                  | 1       | READY                                                                       |
| entity_HI                  | 1       | READY                                                                       |
| entity_TA                  | 1       | READY                                                                       |
| intent_ensemble            | 1       | READY                                                                       |
| intent_model_onnx          | 1       | READY                                                                       |
| intent_postprocessor       | 1       | READY                                                                       |
| intent_preprocessor        | 1       | READY                                                                       |
| itn_EN                     | 1       | READY                                                                       |
| itn_HI                     | 1       | READY                                                                       |
| itn_TA                     | 1       | READY                                                                       |
| pipeline_pyctc_ensemble_EN | 1       | READY                                                                       |
| pipeline_pyctc_ensemble_HI | 1       | READY                                                                       |
| pipeline_pyctc_ensemble_TA | 1       | READY                                                                       |
+----------------------------+---------+-----------------------------------------------------------------------------+

I0821 12:25:37.995987 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:25:37.996214 1 metrics.cc:757] Collecting CPU metrics
I0821 12:25:37.996346 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:25:37.996376 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:25:37.996408 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:25:37.996709 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:25:37.996777 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:25:37.996964 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:25:37.997007 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:25:37.997233 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:25:37.997467 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:25:37.997824 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:25:37.997835 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:25:37.999284 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:25:37.999587 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:25:38.004798 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:25:38.005282 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:25:38.007250 1 model_lifecycle.cc:579] successfully unloaded 'asr_greedy_top1' version 1
I0821 12:25:38.008169 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:25:38.008874 1 server.cc:295] All models are stopped, unloading models
I0821 12:25:38.008912 1 server.cc:302] Timeout 30: Found 17 live models and 0 in-flight non-inference requests
I0821 12:25:38.009337 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:25:38.024118 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:25:38.025650 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:25:38.038876 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:25:38.038873 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:25:38.039086 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:25:38.039327 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:25:38.052843 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:25:38.052891 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:25:38.053106 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:25:38.053135 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:25:39.022680 1 server.cc:302] Timeout 29: Found 11 live models and 0 in-flight non-inference requests
I0821 12:25:39.086130 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:25:39.146053 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:25:39.153947 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:25:39.167361 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:25:39.209735 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:25:39.252847 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:25:39.434819 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:25:39.468549 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:25:40.023027 1 server.cc:302] Timeout 28: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:41.023533 1 server.cc:302] Timeout 27: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:42.024103 1 server.cc:302] Timeout 26: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:43.024601 1 server.cc:302] Timeout 25: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:44.024791 1 server.cc:302] Timeout 24: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:45.025762 1 server.cc:302] Timeout 23: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:46.025975 1 server.cc:302] Timeout 22: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:47.026152 1 server.cc:302] Timeout 21: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:48.026360 1 server.cc:302] Timeout 20: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:49.026561 1 server.cc:302] Timeout 19: Found 3 live models and 0 in-flight non-inference requests
I0821 12:25:49.044814 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:25:49.415208 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:25:49.534969 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:25:50.027029 1 server.cc:302] Timeout 18: Found 0 live models and 0 in-flight non-inference requests
I0821 12:25:56.313063 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f3b7a000000' with size 268435456
I0821 12:25:56.313401 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0821 12:25:56.318765 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:25:56.318956 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:25:56.319096 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:25:56.319323 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_EN:1
I0821 12:25:56.319483 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_HI:1
I0821 12:25:56.319629 1 model_lifecycle.cc:459] loading: asr_greedy_decoder_TA:1
I0821 12:25:56.319852 1 model_lifecycle.cc:459] loading: asr_greedy_top1:1
I0821 12:25:56.320078 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:25:56.320287 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:25:56.322527 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:25:56.322830 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:25:56.323028 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:25:56.323224 1 model_lifecycle.cc:459] loading: entity_HI:1
W0821 12:25:56.323568 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:25:56.323735 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:25:56.323924 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:25:56.324123 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:25:56.324318 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:25:56.324583 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:25:56.324795 1 model_lifecycle.cc:459] loading: itn_HI:1
W0821 12:25:56.324981 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:25:56.325121 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:25:56.769088 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:25:56.769139 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:25:56.769148 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:25:56.771750 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:25:56.772359 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:25:56.772940 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:25:56.772964 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:25:56.772970 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:25:56.772975 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:25:56.773028 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:25:59.682088 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:25:59.682679 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:25:59.683358 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:25:59.683521 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:25:59.683763 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:25:59.683632 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:25:59.683932 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
E0821 12:25:59.934466 1 model_lifecycle.cc:597] failed to load 'asr_greedy_decoder_EN' version 1: Internal: ModuleNotFoundError: No module named 'swig_decoders'

At:
  /models/model_repository/asr_greedy_decoder_EN/1/model.py(3): <module>
  <frozen importlib._bootstrap>(219): _call_with_frames_removed
  <frozen importlib._bootstrap_external>(848): exec_module
  <frozen importlib._bootstrap>(686): _load_unlocked
  <frozen importlib._bootstrap>(975): _find_and_load_unlocked
  <frozen importlib._bootstrap>(991): _find_and_load

I0821 12:25:59.935775 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:25:59.935828 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:25:59.935834 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:25:59.935838 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
E0821 12:26:00.152920 1 model_lifecycle.cc:597] failed to load 'asr_greedy_decoder_HI' version 1: Internal: ModuleNotFoundError: No module named 'swig_decoders'

At:
  /models/model_repository/asr_greedy_decoder_HI/1/model.py(3): <module>
  <frozen importlib._bootstrap>(219): _call_with_frames_removed
  <frozen importlib._bootstrap_external>(848): exec_module
  <frozen importlib._bootstrap>(686): _load_unlocked
  <frozen importlib._bootstrap>(975): _find_and_load_unlocked
  <frozen importlib._bootstrap>(991): _find_and_load

I0821 12:26:00.153304 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:26:03.101074 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
E0821 12:26:03.101072 1 model_lifecycle.cc:597] failed to load 'asr_greedy_decoder_TA' version 1: Internal: ModuleNotFoundError: No module named 'swig_decoders'

At:
  /models/model_repository/asr_greedy_decoder_TA/1/model.py(3): <module>
  <frozen importlib._bootstrap>(219): _call_with_frames_removed
  <frozen importlib._bootstrap_external>(848): exec_module
  <frozen importlib._bootstrap>(686): _load_unlocked
  <frozen importlib._bootstrap>(975): _find_and_load_unlocked
  <frozen importlib._bootstrap>(991): _find_and_load

W0821 12:26:03.101480 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:26:03.101893 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:26:03.101916 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:26:03.101921 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:26:03.101926 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:26:03.101983 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:26:03.105278 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:26:03.105587 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:26:05.859718 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:26:12.638274 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:26:14.640237 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:26:14.640698 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:26:14.641139 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:26:14.641161 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:26:14.641166 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:26:14.641171 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:26:14.641241 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:26:14.641644 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:26:14.641665 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:36:21.154631 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f9976000000' with size 268435456
I0821 12:36:21.154974 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:36:21.162416 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:36:21.162902 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:36:21.163240 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:36:21.163548 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:36:21.163916 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:36:21.164164 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:36:21.164369 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:36:21.164591 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:36:21.164812 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:36:21.165033 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:36:21.165262 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:36:21.165468 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:36:21.165748 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:36:21.165994 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:36:21.166206 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:36:21.166445 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:36:21.182529 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:36:21.182825 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:36:21.183064 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:36:21.202566 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:36:21.202891 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:36:21.210483 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:36:21.218519 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:36:21.218804 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:36:21.219090 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:36:21.222506 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:36:21.844852 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:36:21.844926 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:36:21.844955 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:36:21.849312 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:36:21.849590 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:36:21.849832 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:36:21.850084 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:36:21.862877 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:36:21.863444 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:36:21.863843 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:36:21.863862 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:36:21.863868 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:36:21.863873 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:36:21.863909 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:36:21.864287 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:36:21.864819 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:36:21.864928 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:36:21.865006 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:36:21.865069 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:36:21.865147 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:36:21.865444 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:36:21.865801 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:36:21.865823 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:36:21.865828 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:36:21.865833 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:36:21.866221 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:36:24.627369 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:36:24.628240 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:36:24.628923 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:36:24.629164 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:36:24.629351 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:36:24.629528 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:36:24.630050 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:36:29.558820 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:36:31.934299 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:36:31.935121 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:36:31.935943 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:36:31.936167 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:36:31.936359 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:36:31.936558 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:36:31.937226 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:36:36.869141 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:36:39.624436 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:36:39.626073 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:36:41.682592 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:36:41.683898 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:36:43.715880 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:36:47.043988 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:36:47.044632 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:37:15.165321 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f153e000000' with size 268435456
I0821 12:37:15.165699 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:37:15.171066 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:37:15.171428 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:37:15.171616 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:37:15.171800 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:37:15.172024 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:37:15.172274 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:37:15.172498 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:37:15.172753 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:37:15.173002 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:37:15.173269 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:37:15.173515 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:37:15.173736 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:37:15.173951 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:37:15.174206 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:37:15.174422 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:37:15.174647 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:37:15.180462 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:37:15.180715 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:37:15.180947 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:37:15.181223 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:37:15.181468 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:37:15.181711 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:37:15.181951 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:37:15.182196 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:37:15.182464 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:37:15.182668 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:37:15.833735 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:37:15.833809 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:37:15.833827 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:37:15.834141 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:37:15.835417 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:37:15.836130 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:37:15.836163 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:37:15.836174 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:37:15.836184 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:37:15.836235 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:37:18.840211 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:37:18.840650 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:37:18.841068 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:37:18.841093 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:37:18.841099 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:37:18.841104 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:37:18.841145 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:37:18.843901 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:37:20.691813 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:37:20.761339 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:37:23.124350 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:37:23.124924 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:37:23.125525 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:37:23.125562 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:37:23.125571 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:37:23.125579 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:37:23.126105 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:37:25.592195 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:37:25.592796 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:37:25.593209 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:37:25.593237 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:37:25.593243 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:37:25.593248 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:37:25.594680 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:37:25.594719 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:37:25.594732 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:37:25.594738 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:37:26.939353 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:37:30.730340 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:37:30.730849 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:37:30.731284 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:37:30.731312 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:37:30.731318 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:37:30.731324 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:37:33.414774 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0821 12:37:34.691978 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:37:34.692138 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:37:34.697275 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0821 12:37:34.697605 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:37:36.014173 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:37:36.014362 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:37:37.856539 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:37:37.858017 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:37:40.293916 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:37:40.294593 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:38:41.001881 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:38:41.362657 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0821 12:38:41.362817 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:38:42.667969 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:38:42.668130 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:38:43.014893 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:38:43.015004 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:38:44.840691 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:38:44.841936 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:38:45.152081 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:38:45.152268 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:38:45.604970 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0821 12:38:45.605318 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:38:47.039471 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:38:47.039655 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:38:48.244719 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:38:48.245162 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:38:55.424357 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:38:55.424600 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:38:59.036652 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:38:59.036894 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:39:01.351811 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:39:01.351985 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:39:17.930234 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:39:17.930563 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:39:37.425471 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:39:37.425698 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:39:49.064811 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:39:49.066833 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:39:49.066961 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:39:49.067026 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:39:49.067077 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:39:49.067120 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:39:49.067179 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:39:49.067234 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:39:49.067291 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:39:49.067353 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:39:49.068023 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:39:49.068101 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:39:49.068128 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:39:49.068162 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:39:49.068197 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:39:49.068240 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:39:49.068322 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:39:49.068375 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:39:49.068458 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:39:49.068599 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:39:49.068681 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:39:49.068863 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:39:49.087969 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:39:49.088286 1 metrics.cc:757] Collecting CPU metrics
I0821 12:39:49.088467 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:39:49.088522 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:39:49.088577 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:39:49.088827 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:39:49.088900 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:39:49.089086 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:39:49.089136 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:39:49.089192 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:39:49.089518 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:39:49.090072 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:39:49.090184 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:39:49.090347 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:39:49.090410 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:39:49.090497 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:39:49.090902 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:39:49.091924 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:39:49.092141 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:39:49.092361 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:39:49.092633 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:39:49.092821 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:39:49.092951 1 server.cc:295] All models are stopped, unloading models
I0821 12:39:49.093199 1 server.cc:302] Timeout 30: Found 19 live models and 0 in-flight non-inference requests
I0821 12:39:49.106534 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:39:49.106700 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:39:49.111110 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:39:49.111249 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:39:49.129732 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:39:49.129783 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:39:49.129821 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:39:49.129961 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:39:49.130029 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:39:49.135906 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:39:50.093456 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 12:39:50.127123 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:39:50.137384 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:39:50.217564 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:39:50.248226 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:39:50.266162 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:39:50.339153 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 12:39:50.340871 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:39:50.348302 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:39:50.440043 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:39:50.451479 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 12:39:50.482012 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:39:50.492556 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:39:50.532725 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:39:50.604647 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:39:51.094245 1 server.cc:302] Timeout 28: Found 0 live models and 0 in-flight non-inference requests
I0821 12:39:57.242369 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7efcf6000000' with size 268435456
I0821 12:39:57.242759 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:39:57.248025 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:39:57.248060 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:39:57.248066 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:39:57.248070 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:39:57.248106 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:39:57.248143 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:39:57.248171 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:39:57.248199 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:39:57.248231 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:39:57.248278 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:39:57.248312 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:39:57.248340 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:39:57.248368 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:39:57.248620 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:39:57.248781 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:39:57.248894 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:39:57.249196 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:39:57.249309 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:39:57.249422 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:39:57.249542 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:39:57.249743 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:39:57.249922 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:39:57.250096 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:39:57.250271 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:39:57.250461 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:39:57.250612 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:39:57.626656 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:39:57.626711 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:39:57.626719 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:39:57.631330 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:39:57.631381 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:39:57.631392 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:39:57.631397 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:39:57.640360 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:39:57.641050 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:39:57.641629 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:39:57.641662 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:39:57.641669 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:39:57.641673 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:39:57.641697 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:39:57.642014 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:39:57.642390 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:39:57.642413 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:39:57.642419 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:39:57.642425 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:39:57.642470 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:40:00.228680 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:40:00.229241 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:40:00.229792 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:40:00.229821 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:40:00.229829 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:40:00.229836 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:40:00.229994 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:40:00.230311 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:40:02.644348 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:40:05.073459 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:40:05.073955 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:40:05.074399 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:40:05.074451 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:40:05.074459 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:40:05.074464 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:40:05.075093 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:40:07.501498 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:40:15.246199 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:40:16.976527 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:40:16.977119 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:40:16.977560 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:40:16.977589 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:40:16.977595 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:40:16.977601 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:40:16.977674 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:40:16.977712 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:40:16.978338 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:41:16.698656 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:41:18.399740 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0821 12:41:18.401238 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:41:19.845927 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0821 12:41:19.846096 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:41:21.156125 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:41:21.156262 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:41:21.161069 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0821 12:41:21.161438 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0821 12:41:22.526987 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0821 12:41:22.527414 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:41:23.874402 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:41:23.874729 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:41:24.218821 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:41:24.218977 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:41:24.566914 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:41:24.567020 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:41:25.007633 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:41:25.007808 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:41:25.298187 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:41:25.298347 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:41:26.951385 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:41:26.952815 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:41:28.064291 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:41:28.064627 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:41:31.100745 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:41:31.100981 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:41:33.819227 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:41:33.819841 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:41:36.120615 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:41:36.120832 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:41:55.199688 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:41:55.199857 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:42:11.259931 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:42:11.260135 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:42:22.946047 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:42:22.947531 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:42:22.947622 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:42:22.947670 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:42:22.947706 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:42:22.947754 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:42:22.947793 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:42:22.947829 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:42:22.947866 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:42:22.947910 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:42:22.948011 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:42:22.948068 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:42:22.948132 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:42:22.948428 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:42:22.948523 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:42:22.948597 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:42:22.948709 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:42:22.948751 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:42:22.948803 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:42:22.948903 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:42:22.948951 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:42:22.949047 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:42:22.964199 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:42:22.964428 1 metrics.cc:757] Collecting CPU metrics
I0821 12:42:22.964583 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:42:22.964618 1 server.cc:264] Waiting for in-flight requests to complete.
I0821 12:42:22.964663 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0821 12:42:22.964826 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:42:22.964844 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:42:22.965031 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:42:22.965060 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:42:22.964849 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:42:22.965447 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:42:22.965458 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:42:22.964927 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:42:22.966000 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:42:22.975023 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:42:22.979866 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0821 12:42:22.980015 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:42:22.980311 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:42:22.980452 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0821 12:42:22.981227 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0821 12:42:22.981720 1 server.cc:295] All models are stopped, unloading models
I0821 12:42:22.981767 1 server.cc:302] Timeout 30: Found 21 live models and 0 in-flight non-inference requests
I0821 12:42:22.982302 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:42:22.982572 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:42:22.986195 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:42:22.991869 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0821 12:42:22.994507 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:42:22.994669 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0821 12:42:23.023997 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:42:23.024001 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:42:23.024106 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0821 12:42:23.024198 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0821 12:42:23.024250 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0821 12:42:23.024423 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0821 12:42:23.981963 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0821 12:42:24.047987 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0821 12:42:24.101138 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0821 12:42:24.137967 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0821 12:42:24.139117 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0821 12:42:24.155993 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0821 12:42:24.177172 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0821 12:42:24.263481 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0821 12:42:24.291493 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0821 12:42:24.322245 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0821 12:42:24.346896 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0821 12:42:24.386088 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0821 12:42:24.440346 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0821 12:42:24.448528 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0821 12:42:24.531731 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0821 12:42:24.982754 1 server.cc:302] Timeout 28: Found 0 live models and 0 in-flight non-inference requests
I0821 12:42:31.101383 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7ff5aa000000' with size 268435456
I0821 12:42:31.101807 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
E0821 12:42:31.107194 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_EN contains models that are not available: asr_greedy_top1, asr_greedy_decoder_EN
E0821 12:42:31.107362 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_HI contains models that are not available: asr_greedy_decoder_HI
E0821 12:42:31.107636 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_OR contains models that are not available: asr_greedy_decoder_OR
E0821 12:42:31.107816 1 model_repository_manager.cc:487] Invalid argument: ensemble pipeline_greedy_ensemble_TA contains models that are not available: asr_greedy_decoder_TA
I0821 12:42:31.108037 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:42:31.108268 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:42:31.108483 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:42:31.108741 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:42:31.108986 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:42:31.109221 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:42:31.109449 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:42:31.109673 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:42:31.109891 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:42:31.110109 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:42:31.110324 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:42:31.110563 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:42:31.110926 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:42:31.111141 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:42:31.111371 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:42:31.111714 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:42:31.112050 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:42:31.112275 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:42:31.112518 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:42:31.112754 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:42:31.112999 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:42:31.113204 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:42:31.488457 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:42:31.488519 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:42:31.488535 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:42:31.491822 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:42:31.491861 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:42:31.491868 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:42:31.491872 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:42:31.500962 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:42:31.501905 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:42:31.502780 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:42:31.502808 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:42:31.502817 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:42:31.502825 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:42:31.502875 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:42:31.503216 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:42:31.503749 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:42:31.503868 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:42:31.504070 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:42:31.504215 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:42:31.504355 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:42:34.141821 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:42:34.142405 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:42:34.143038 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:42:34.143289 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:42:34.143419 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:42:34.143521 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:42:34.143621 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:42:34.143765 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:42:35.849240 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:42:35.849869 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:42:38.370786 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:42:40.821154 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:42:43.248745 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:46:02.890619 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fad8a000000' with size 268435456
I0821 12:46:02.890978 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0821 12:46:02.895553 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:46:02.895972 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:46:02.896260 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:46:02.896552 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:46:02.896842 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:46:02.897137 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:46:02.897438 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:46:02.897718 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:46:02.898001 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:46:02.898280 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:46:02.898579 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:46:02.898851 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:46:02.899192 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:46:02.899467 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:46:02.899738 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:46:02.918482 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:46:02.922526 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:46:02.926477 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:46:02.930552 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:46:02.930845 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:46:02.931140 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:46:02.931417 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:46:03.586197 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:46:03.586262 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:46:03.586277 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:46:03.588701 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:46:03.589266 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:46:03.589734 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:46:03.589755 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:46:03.589761 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:46:03.589766 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:46:03.589793 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:46:03.590483 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:46:03.591224 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:46:03.591254 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:46:03.591265 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:46:03.591274 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:46:03.591838 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:46:06.636149 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:46:06.637025 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:46:06.637037 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:46:06.637043 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:46:06.646750 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:46:09.235778 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:46:11.913981 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:46:15.692415 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:46:15.693175 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:46:15.693856 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:46:15.694006 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:46:15.694118 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:46:15.694225 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:46:15.694399 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:46:15.694960 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:46:15.695532 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:46:15.695567 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:46:15.695577 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:46:15.695586 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:46:15.696045 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:46:18.112207 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0821 12:46:18.112684 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:46:18.113145 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:46:18.113172 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:46:18.113178 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:46:18.113183 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:46:19.446773 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0821 12:46:20.707488 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:46:20.707671 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:46:22.579706 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:46:22.580412 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:46:22.581179 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:46:39.849081 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f5d6a000000' with size 268435456
I0821 12:46:39.849527 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0821 12:46:39.856084 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0821 12:46:39.856603 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0821 12:46:39.856933 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0821 12:46:39.857265 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0821 12:46:39.857592 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0821 12:46:39.857915 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0821 12:46:39.858238 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0821 12:46:39.858580 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0821 12:46:39.870544 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0821 12:46:39.878503 1 model_lifecycle.cc:459] loading: entity_EN:1
I0821 12:46:39.878901 1 model_lifecycle.cc:459] loading: entity_HI:1
I0821 12:46:39.879251 1 model_lifecycle.cc:459] loading: entity_OR:1
W0821 12:46:39.879678 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0821 12:46:39.879974 1 model_lifecycle.cc:459] loading: entity_TA:1
I0821 12:46:39.880303 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0821 12:46:39.880634 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0821 12:46:39.886488 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0821 12:46:39.886738 1 model_lifecycle.cc:459] loading: itn_EN:1
I0821 12:46:39.886954 1 model_lifecycle.cc:459] loading: itn_HI:1
I0821 12:46:39.887173 1 model_lifecycle.cc:459] loading: itn_OR:1
W0821 12:46:39.887390 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0821 12:46:39.887592 1 model_lifecycle.cc:459] loading: itn_TA:1
I0821 12:46:40.357601 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0821 12:46:40.357667 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0821 12:46:40.357675 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0821 12:46:40.361319 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0821 12:46:40.361395 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0821 12:46:40.361406 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0821 12:46:40.361411 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0821 12:46:40.371391 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0821 12:46:40.372013 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0821 12:46:40.372428 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0821 12:46:40.372451 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0821 12:46:40.372459 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0821 12:46:40.372464 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0821 12:46:40.372508 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0821 12:46:43.264501 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0821 12:46:43.264956 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0821 12:46:43.265107 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0821 12:46:43.265767 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0821 12:46:43.265941 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0821 12:46:43.266163 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0821 12:46:43.266381 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0821 12:46:43.267067 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:46:45.682218 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:46:48.106336 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0821 12:46:48.106827 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0821 12:46:48.107277 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0821 12:46:48.107305 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0821 12:46:48.107311 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0821 12:46:48.107316 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0821 12:46:48.107366 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0821 12:46:48.110481 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
I0821 12:46:48.110699 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
W0821 12:46:48.111119 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0821 12:46:48.111636 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0821 12:46:48.111667 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0821 12:46:48.111677 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0821 12:46:48.111705 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0821 12:46:49.771131 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0821 12:46:49.771627 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0821 12:46:49.772083 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0821 12:46:49.772112 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0821 12:46:49.772118 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0821 12:46:49.772124 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0821 12:46:49.772183 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0821 12:46:51.623762 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0821 12:47:55.380474 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:47:57.802278 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0821 12:47:59.538958 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0821 12:47:59.540096 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0821 12:48:01.009828 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0821 12:48:01.010448 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0821 12:48:02.297345 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0821 12:48:02.297569 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0821 12:48:04.729865 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0821 12:48:06.390487 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0821 12:48:06.391765 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0821 12:48:09.569642 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0821 12:48:09.570491 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0821 12:48:09.570964 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0821 12:48:09.571636 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0821 12:48:13.965418 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0821 12:48:13.965615 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0821 12:48:16.323423 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0821 12:48:16.323768 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0821 12:48:35.623095 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0821 12:48:35.623260 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0821 12:48:35.942758 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0821 12:48:35.943002 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0821 12:48:36.256624 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0821 12:48:36.256744 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0821 12:48:36.763489 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0821 12:48:36.763614 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0821 12:48:53.649558 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0821 12:48:53.649721 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0821 12:48:53.989960 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0821 12:48:53.990277 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0821 12:49:05.611269 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0821 12:49:05.611396 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0821 12:49:06.991564 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0821 12:49:06.991807 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0821 12:49:08.279094 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0821 12:49:08.282067 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0821 12:49:09.511637 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0821 12:49:09.513321 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0821 12:49:09.513412 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0821 12:49:09.513597 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0821 12:49:09.513761 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0821 12:49:09.513916 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0821 12:49:09.514075 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0821 12:49:09.514235 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0821 12:49:09.514402 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0821 12:49:09.514610 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0821 12:49:09.514758 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0821 12:49:09.514897 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0821 12:49:09.514970 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0821 12:49:09.515058 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0821 12:49:09.515089 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0821 12:49:09.515125 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0821 12:49:09.515186 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0821 12:49:09.515259 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0821 12:49:09.515323 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0821 12:49:09.515423 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0821 12:49:09.515482 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:49:09.515624 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0821 12:49:09.531250 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0821 12:49:09.531471 1 metrics.cc:757] Collecting CPU metrics
I0821 12:49:09.531795 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0821 12:49:09.532916 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0821 12:49:09.533107 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0821 12:49:09.574238 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0822 06:29:30.314569 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fdb9c000000' with size 268435456
I0822 06:29:30.314894 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0822 06:29:30.319651 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0822 06:29:30.319691 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0822 06:29:30.319713 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0822 06:29:30.319752 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0822 06:29:30.319804 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0822 06:29:30.319834 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0822 06:29:30.319931 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0822 06:29:30.319962 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0822 06:29:30.319990 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0822 06:29:30.320016 1 model_lifecycle.cc:459] loading: entity_EN:1
I0822 06:29:30.320045 1 model_lifecycle.cc:459] loading: entity_HI:1
I0822 06:29:30.320066 1 model_lifecycle.cc:459] loading: entity_OR:1
W0822 06:29:30.320372 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0822 06:29:30.320400 1 model_lifecycle.cc:459] loading: entity_TA:1
I0822 06:29:30.320448 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0822 06:29:30.320484 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0822 06:29:30.320511 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0822 06:29:30.320603 1 model_lifecycle.cc:459] loading: itn_EN:1
I0822 06:29:30.320634 1 model_lifecycle.cc:459] loading: itn_HI:1
I0822 06:29:30.320658 1 model_lifecycle.cc:459] loading: itn_OR:1
W0822 06:29:30.320697 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0822 06:29:30.320711 1 model_lifecycle.cc:459] loading: itn_TA:1
I0822 06:29:30.744948 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0822 06:29:30.744984 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0822 06:29:30.744989 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0822 06:29:30.748144 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0822 06:29:30.748735 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0822 06:29:30.749163 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0822 06:29:30.749172 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0822 06:29:30.749175 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0822 06:29:30.749179 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0822 06:29:30.749208 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0822 06:29:30.749550 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0822 06:29:30.749968 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0822 06:29:30.749979 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0822 06:29:30.749984 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0822 06:29:30.749989 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0822 06:29:30.750025 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0822 06:29:33.870768 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0822 06:29:33.871281 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0822 06:29:33.871749 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0822 06:29:33.871760 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0822 06:29:33.871764 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0822 06:29:33.871768 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0822 06:29:33.871931 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0822 06:29:33.873103 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0822 06:29:33.873117 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0822 06:29:33.873127 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0822 06:29:33.873130 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0822 06:29:33.882063 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0822 06:29:33.882785 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0822 06:29:33.883234 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0822 06:29:33.883242 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0822 06:29:33.883246 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0822 06:29:33.883250 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0822 06:29:33.883665 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 06:29:36.605767 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0822 06:29:36.606181 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0822 06:29:36.606566 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0822 06:29:36.606587 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0822 06:29:36.606591 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0822 06:29:36.606594 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0822 06:29:37.930407 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 06:29:40.346253 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 06:29:42.745105 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 06:29:51.084370 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0822 06:29:53.096422 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0822 06:29:53.097770 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0822 06:29:55.187295 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0822 06:29:55.187797 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0822 06:29:55.188299 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0822 06:29:55.188312 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0822 06:29:57.305571 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0822 06:30:53.924556 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0822 06:30:55.215514 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0822 06:30:55.218693 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0822 06:30:55.218934 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0822 06:30:55.516383 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0822 06:30:55.516541 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0822 06:30:56.901507 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0822 06:30:58.243550 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0822 06:30:59.504846 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0822 06:30:59.993319 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0822 06:30:59.993489 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0822 06:31:00.352155 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0822 06:31:00.352293 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0822 06:31:00.665749 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0822 06:31:00.665895 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0822 06:31:03.337632 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0822 06:31:03.337873 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0822 06:31:04.613518 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0822 06:31:04.613907 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0822 06:31:21.155573 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0822 06:31:21.155755 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0822 06:31:23.393398 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0822 06:31:23.393538 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0822 06:31:41.824730 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0822 06:31:41.824884 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0822 06:31:44.438439 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0822 06:31:44.438637 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0822 06:31:55.655781 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0822 06:31:55.655941 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0822 06:31:56.966369 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0822 06:31:58.443076 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0822 06:31:59.840005 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0822 06:32:01.169549 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0822 06:32:02.481009 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0822 06:32:03.941788 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0822 06:32:05.348494 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0822 06:32:06.630055 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0822 06:32:07.944265 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0822 06:32:09.395093 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0822 06:32:10.795703 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0822 06:32:12.127535 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0822 06:32:13.463740 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0822 06:32:14.934899 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0822 06:32:16.338115 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0822 06:32:17.724574 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0822 06:32:19.097643 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0822 06:32:20.534263 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0822 06:32:21.985605 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0822 06:32:23.304994 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0822 06:32:24.704486 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0822 06:32:26.195319 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0822 06:32:27.651654 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0822 06:32:29.052706 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0822 06:32:30.390874 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0822 06:32:30.391127 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0822 06:32:31.877842 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0822 06:32:31.878075 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0822 06:32:33.226830 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0822 06:32:33.227009 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0822 06:32:34.539417 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0822 06:32:34.540601 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0822 06:32:34.540658 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0822 06:32:34.540692 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0822 06:32:34.540724 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0822 06:32:34.540755 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0822 06:32:34.540789 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0822 06:32:34.540822 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0822 06:32:34.540855 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0822 06:32:34.540891 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0822 06:32:34.540931 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0822 06:32:34.540988 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0822 06:32:34.541043 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0822 06:32:34.541294 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0822 06:32:34.541350 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0822 06:32:34.541388 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0822 06:32:34.541438 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0822 06:32:34.541483 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0822 06:32:34.541516 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0822 06:32:34.541602 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0822 06:32:34.541640 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0822 06:32:34.541728 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0822 06:32:34.559177 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0822 06:32:34.559365 1 metrics.cc:757] Collecting CPU metrics
I0822 06:32:34.559495 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0822 06:32:34.560583 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0822 06:32:34.560746 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0822 06:32:34.602117 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0822 06:33:42.133046 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f924c000000' with size 268435456
I0822 06:33:42.133360 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0822 06:33:42.137874 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0822 06:33:42.137912 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0822 06:33:42.137944 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0822 06:33:42.137969 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0822 06:33:42.137998 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0822 06:33:42.138112 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0822 06:33:42.138140 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0822 06:33:42.138304 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0822 06:33:42.138337 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0822 06:33:42.138366 1 model_lifecycle.cc:459] loading: entity_EN:1
I0822 06:33:42.138386 1 model_lifecycle.cc:459] loading: entity_HI:1
I0822 06:33:42.138408 1 model_lifecycle.cc:459] loading: entity_OR:1
W0822 06:33:42.138749 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0822 06:33:42.138768 1 model_lifecycle.cc:459] loading: entity_TA:1
I0822 06:33:42.138824 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0822 06:33:42.138873 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0822 06:33:42.138914 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0822 06:33:42.138942 1 model_lifecycle.cc:459] loading: itn_EN:1
I0822 06:33:42.138965 1 model_lifecycle.cc:459] loading: itn_HI:1
I0822 06:33:42.139047 1 model_lifecycle.cc:459] loading: itn_OR:1
W0822 06:33:42.139080 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0822 06:33:42.139091 1 model_lifecycle.cc:459] loading: itn_TA:1
I0822 06:33:42.490654 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0822 06:33:42.490687 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0822 06:33:42.490692 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0822 06:33:42.492385 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0822 06:33:42.492856 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0822 06:33:42.493221 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0822 06:33:42.493240 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0822 06:33:42.493243 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0822 06:33:42.493246 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0822 06:33:42.493284 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0822 06:33:42.493656 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0822 06:33:42.494006 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0822 06:33:42.494014 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0822 06:33:42.494017 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0822 06:33:42.494021 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0822 06:33:42.494050 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0822 06:33:42.494399 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0822 06:33:42.494770 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0822 06:33:42.494779 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0822 06:33:42.494783 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0822 06:33:42.494786 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0822 06:33:42.496142 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0822 06:33:42.496166 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0822 06:33:42.496176 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0822 06:33:42.496179 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0822 06:33:42.505040 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0822 06:33:45.130845 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 06:33:45.131433 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0822 06:33:47.553737 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0822 06:33:49.439696 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0822 06:33:49.440798 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0822 06:33:49.442900 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
I0822 06:33:49.443137 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
W0822 06:33:49.443279 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0822 06:33:49.443664 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0822 06:33:49.443672 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0822 06:33:49.443676 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0822 06:33:49.443679 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0822 06:33:49.443742 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0822 06:33:49.444179 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0822 06:33:49.444545 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0822 06:33:49.444555 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0822 06:33:49.444558 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0822 06:33:49.444562 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0822 06:33:49.444909 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 06:33:51.868134 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 06:33:54.289100 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 06:34:02.052641 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0822 06:34:02.053126 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0822 06:34:59.026758 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0822 06:35:00.329583 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0822 06:35:02.182188 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0822 06:35:02.183579 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0822 06:35:04.055858 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0822 06:35:04.057010 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0822 06:35:05.312391 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0822 06:35:06.716730 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0822 06:35:08.061804 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0822 06:35:08.372969 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0822 06:35:08.373100 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0822 06:35:08.697268 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0822 06:35:08.697399 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0822 06:35:09.150281 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0822 06:35:09.150383 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0822 06:35:09.467071 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0822 06:35:09.467284 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0822 06:35:10.535763 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0822 06:35:10.536079 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0822 06:35:13.889006 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0822 06:35:13.889134 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0822 06:35:18.260779 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0822 06:35:18.260894 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0822 06:35:20.482056 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0822 06:35:20.482190 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0822 06:35:32.315202 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0822 06:35:32.315395 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0822 06:35:48.260294 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0822 06:35:48.260430 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0822 06:36:06.963531 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0822 06:36:06.963714 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0822 06:36:08.311274 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0822 06:36:09.593736 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0822 06:36:11.075613 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0822 06:36:12.443823 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0822 06:36:13.732539 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0822 06:36:15.040357 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0822 06:36:16.488777 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0822 06:36:17.871067 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0822 06:36:19.169584 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0822 06:36:20.450476 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0822 06:36:21.881247 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0822 06:36:23.246879 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0822 06:36:24.535137 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0822 06:36:25.831436 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0822 06:36:27.262447 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0822 06:36:28.630282 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0822 06:36:29.919250 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0822 06:36:31.225741 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0822 06:36:32.660189 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0822 06:36:34.024157 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0822 06:36:35.315270 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0822 06:36:36.600070 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0822 06:36:38.052300 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0822 06:36:39.403755 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0822 06:36:40.689628 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0822 06:36:40.689830 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0822 06:36:41.975605 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0822 06:36:41.975804 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0822 06:36:43.430603 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0822 06:36:43.430821 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0822 06:36:44.779669 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0822 06:36:44.780867 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0822 06:36:44.780929 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0822 06:36:44.780963 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0822 06:36:44.781003 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0822 06:36:44.781035 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0822 06:36:44.781070 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0822 06:36:44.781106 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0822 06:36:44.781145 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0822 06:36:44.781197 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0822 06:36:44.781230 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0822 06:36:44.781262 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0822 06:36:44.781293 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0822 06:36:44.781594 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0822 06:36:44.781655 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0822 06:36:44.781746 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0822 06:36:44.781823 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0822 06:36:44.781877 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0822 06:36:44.781944 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0822 06:36:44.782050 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0822 06:36:44.782088 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0822 06:36:44.782177 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0822 06:36:44.797458 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0822 06:36:44.797646 1 metrics.cc:757] Collecting CPU metrics
I0822 06:36:44.797754 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0822 06:36:44.798820 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0822 06:36:44.798987 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0822 06:36:44.840336 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0822 11:12:21.641415 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7effca000000' with size 268435456
I0822 11:12:21.641747 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0822 11:12:21.646695 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0822 11:12:21.646735 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0822 11:12:21.646760 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0822 11:12:21.646789 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0822 11:12:21.646857 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0822 11:12:21.646951 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0822 11:12:21.646980 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0822 11:12:21.647029 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0822 11:12:21.647057 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0822 11:12:21.647084 1 model_lifecycle.cc:459] loading: entity_EN:1
I0822 11:12:21.647105 1 model_lifecycle.cc:459] loading: entity_HI:1
I0822 11:12:21.647126 1 model_lifecycle.cc:459] loading: entity_OR:1
W0822 11:12:21.647325 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0822 11:12:21.647347 1 model_lifecycle.cc:459] loading: entity_TA:1
I0822 11:12:21.647388 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0822 11:12:21.647466 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0822 11:12:21.647505 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0822 11:12:21.647537 1 model_lifecycle.cc:459] loading: itn_EN:1
I0822 11:12:21.647619 1 model_lifecycle.cc:459] loading: itn_HI:1
I0822 11:12:21.647642 1 model_lifecycle.cc:459] loading: itn_OR:1
W0822 11:12:21.648409 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0822 11:12:21.648426 1 model_lifecycle.cc:459] loading: itn_TA:1
I0822 11:12:22.079864 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0822 11:12:22.079898 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0822 11:12:22.079905 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0822 11:12:22.082347 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0822 11:12:22.082853 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0822 11:12:22.083208 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0822 11:12:22.083217 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0822 11:12:22.083221 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0822 11:12:22.083225 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0822 11:12:22.083261 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0822 11:12:22.083620 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0822 11:12:22.083972 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0822 11:12:22.083982 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0822 11:12:22.083995 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0822 11:12:22.083999 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0822 11:12:22.084022 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0822 11:12:22.084275 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0822 11:12:22.084607 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0822 11:12:22.084617 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0822 11:12:22.084621 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0822 11:12:22.084624 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0822 11:12:22.084651 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0822 11:12:25.013746 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0822 11:12:25.014222 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0822 11:12:25.014597 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0822 11:12:25.014607 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0822 11:12:25.014611 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0822 11:12:25.014615 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0822 11:12:25.015067 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0822 11:12:25.016275 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0822 11:12:25.016295 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0822 11:12:25.016309 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0822 11:12:25.016316 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0822 11:12:25.034058 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0822 11:12:25.038804 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
I0822 11:12:25.039046 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
W0822 11:12:25.039223 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0822 11:12:25.039653 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0822 11:12:25.039665 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0822 11:12:25.039670 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0822 11:12:25.039675 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0822 11:12:26.370898 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 11:12:29.097328 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 11:12:31.826535 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 11:12:38.243051 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0822 11:12:40.652447 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0822 11:12:42.715417 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0822 11:12:42.716774 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0822 11:12:44.860515 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0822 11:12:44.860987 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0822 11:12:44.861553 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0822 11:13:42.229125 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0822 11:13:44.301913 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0822 11:13:44.303709 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0822 11:13:44.750517 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0822 11:13:44.750644 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0822 11:13:46.182297 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0822 11:13:47.466136 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0822 11:13:48.840304 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0822 11:13:49.203229 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0822 11:13:49.203359 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0822 11:13:49.511114 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0822 11:13:49.511299 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0822 11:13:49.804569 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0822 11:13:49.804758 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0822 11:13:51.078919 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0822 11:13:52.461375 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0822 11:13:52.461663 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0822 11:13:55.481781 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0822 11:13:55.481953 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0822 11:13:59.423420 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0822 11:13:59.423569 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0822 11:14:01.797615 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0822 11:14:01.797811 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0822 11:14:12.857080 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0822 11:14:12.857213 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0822 11:14:28.495893 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0822 11:14:28.496967 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0822 11:14:46.985023 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0822 11:14:46.985174 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0822 11:14:48.554849 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0822 11:14:49.993164 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0822 11:14:51.373624 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0822 11:14:52.663967 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0822 11:14:54.115639 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0822 11:14:55.437941 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0822 11:14:56.831209 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0822 11:14:58.121483 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0822 11:14:59.590344 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0822 11:15:00.921808 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0822 11:15:02.509031 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0822 11:15:03.997256 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0822 11:15:05.596059 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0822 11:15:06.900299 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0822 11:15:08.275361 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0822 11:15:09.634215 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0822 11:15:11.088214 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0822 11:15:12.384527 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0822 11:15:13.766348 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0822 11:15:15.102919 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0822 11:15:16.684950 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0822 11:15:18.035932 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0822 11:15:19.477190 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0822 11:15:20.809204 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0822 11:15:22.253881 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0822 11:15:22.254122 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0822 11:15:23.661242 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0822 11:15:23.661473 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0822 11:15:25.058932 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0822 11:15:25.059113 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0822 11:15:26.421180 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0822 11:15:26.422491 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0822 11:15:26.422538 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0822 11:15:26.422575 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0822 11:15:26.422607 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0822 11:15:26.422638 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0822 11:15:26.422673 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0822 11:15:26.422705 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0822 11:15:26.422737 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0822 11:15:26.422797 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0822 11:15:26.422847 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0822 11:15:26.422911 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0822 11:15:26.422977 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0822 11:15:26.423249 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0822 11:15:26.423296 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0822 11:15:26.423338 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0822 11:15:26.423389 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0822 11:15:26.423449 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0822 11:15:26.423541 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0822 11:15:26.423667 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0822 11:15:26.423718 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0822 11:15:26.423830 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0822 11:15:26.446864 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0822 11:15:26.447055 1 metrics.cc:757] Collecting CPU metrics
I0822 11:15:26.447182 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0822 11:15:26.448420 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0822 11:15:26.448597 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0822 11:15:26.490070 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0823 17:37:13.869193 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f99fe000000' with size 268435456
I0823 17:37:13.869530 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0823 17:37:13.874478 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0823 17:37:13.874520 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0823 17:37:13.874545 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0823 17:37:13.874602 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0823 17:37:13.874691 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0823 17:37:13.874722 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0823 17:37:13.874747 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0823 17:37:13.874770 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0823 17:37:13.874915 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0823 17:37:13.874945 1 model_lifecycle.cc:459] loading: entity_EN:1
I0823 17:37:13.874971 1 model_lifecycle.cc:459] loading: entity_HI:1
I0823 17:37:13.874993 1 model_lifecycle.cc:459] loading: entity_OR:1
W0823 17:37:13.875190 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0823 17:37:13.875214 1 model_lifecycle.cc:459] loading: entity_TA:1
I0823 17:37:13.875261 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0823 17:37:13.875310 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0823 17:37:13.875346 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0823 17:37:13.876421 1 model_lifecycle.cc:459] loading: itn_EN:1
I0823 17:37:13.876502 1 model_lifecycle.cc:459] loading: itn_HI:1
I0823 17:37:13.876530 1 model_lifecycle.cc:459] loading: itn_OR:1
W0823 17:37:13.876560 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0823 17:37:13.876573 1 model_lifecycle.cc:459] loading: itn_TA:1
I0823 17:37:14.320399 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0823 17:37:14.320441 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0823 17:37:14.320447 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0823 17:37:14.322908 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0823 17:37:14.323398 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0823 17:37:14.323787 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0823 17:37:14.323797 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0823 17:37:14.323801 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0823 17:37:14.323804 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0823 17:37:14.323845 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0823 17:37:14.324271 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0823 17:37:14.324669 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0823 17:37:14.324678 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0823 17:37:14.324682 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0823 17:37:14.324685 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0823 17:37:14.324716 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0823 17:37:14.325138 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0823 17:37:14.325566 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0823 17:37:14.325575 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0823 17:37:14.325578 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0823 17:37:14.325594 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0823 17:37:14.326997 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0823 17:37:14.327158 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0823 17:37:14.327171 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0823 17:37:14.327175 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0823 17:37:14.336050 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0823 17:37:17.572192 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0823 17:37:17.573335 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0823 17:37:19.725744 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0823 17:37:19.726517 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0823 17:37:22.465743 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0823 17:37:24.575602 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0823 17:37:24.576073 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0823 17:37:24.576433 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0823 17:37:24.576442 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0823 17:37:24.576446 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0823 17:37:24.576457 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0823 17:37:24.576998 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0823 17:37:24.577011 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0823 17:37:27.021060 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0823 17:37:27.021611 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0823 17:37:27.021998 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0823 17:37:27.022008 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0823 17:37:27.022012 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0823 17:37:27.022016 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0823 17:37:27.022514 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0823 17:37:30.827099 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0823 17:37:37.335030 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0823 17:37:37.335502 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0823 17:38:36.256006 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0823 17:38:37.690301 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0823 17:38:39.825027 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0823 17:38:39.826732 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0823 17:38:41.097278 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0823 17:38:41.100642 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0823 17:38:41.100868 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0823 17:38:42.449893 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0823 17:38:42.793204 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0823 17:38:42.793326 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0823 17:38:44.057043 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0823 17:38:44.509791 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0823 17:38:44.509959 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0823 17:38:44.813015 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0823 17:38:44.813205 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0823 17:38:45.113877 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0823 17:38:45.114050 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0823 17:38:46.458275 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0823 17:38:46.458592 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0823 17:38:49.582316 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0823 17:38:49.582495 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0823 17:38:53.384341 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0823 17:38:53.384487 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0823 17:38:55.695624 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0823 17:38:55.695846 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0823 17:39:07.989409 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0823 17:39:07.989586 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0823 17:39:24.073600 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0823 17:39:24.073774 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0823 17:39:43.622905 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0823 17:39:43.623059 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0823 17:39:45.229192 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0823 17:39:46.741570 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0823 17:39:48.310181 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0823 17:39:49.618138 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0823 17:39:51.101744 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0823 17:39:52.434171 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0823 17:39:53.841136 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0823 17:39:55.155481 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0823 17:39:56.635497 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0823 17:39:57.951336 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0823 17:39:59.348573 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0823 17:40:00.789568 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0823 17:40:02.527895 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0823 17:40:04.001318 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0823 17:40:05.423835 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0823 17:40:06.786900 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0823 17:40:08.274819 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0823 17:40:09.600082 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0823 17:40:10.976101 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0823 17:40:12.293728 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0823 17:40:13.771932 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0823 17:40:15.182033 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0823 17:40:16.680304 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0823 17:40:17.974020 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0823 17:40:19.482237 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0823 17:40:19.482677 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0823 17:40:20.854529 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0823 17:40:20.854810 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0823 17:40:22.249833 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0823 17:40:22.250029 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0823 17:40:23.646640 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0823 17:40:23.647815 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0823 17:40:23.647878 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0823 17:40:23.647913 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0823 17:40:23.647946 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0823 17:40:23.647981 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0823 17:40:23.648018 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0823 17:40:23.648055 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0823 17:40:23.648098 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0823 17:40:23.648137 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0823 17:40:23.648171 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0823 17:40:23.648206 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0823 17:40:23.648237 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0823 17:40:23.648563 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0823 17:40:23.648600 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0823 17:40:23.648651 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0823 17:40:23.648733 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0823 17:40:23.648800 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0823 17:40:23.648862 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0823 17:40:23.648984 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0823 17:40:23.649026 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0823 17:40:23.649121 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0823 17:40:23.671103 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0823 17:40:23.671302 1 metrics.cc:757] Collecting CPU metrics
I0823 17:40:23.671436 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0823 17:40:23.672731 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0823 17:40:23.672902 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0823 17:40:23.714353 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0824 08:45:02.872692 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f14d6000000' with size 268435456
I0824 08:45:02.873024 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0824 08:45:02.877943 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0824 08:45:02.877986 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0824 08:45:02.878018 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0824 08:45:02.878049 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0824 08:45:02.878151 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0824 08:45:02.878199 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0824 08:45:02.878225 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0824 08:45:02.878249 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0824 08:45:02.878275 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0824 08:45:02.878324 1 model_lifecycle.cc:459] loading: entity_EN:1
I0824 08:45:02.878351 1 model_lifecycle.cc:459] loading: entity_HI:1
I0824 08:45:02.878372 1 model_lifecycle.cc:459] loading: entity_OR:1
W0824 08:45:02.878788 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0824 08:45:02.878808 1 model_lifecycle.cc:459] loading: entity_TA:1
I0824 08:45:02.878854 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0824 08:45:02.878910 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0824 08:45:02.878955 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0824 08:45:02.879015 1 model_lifecycle.cc:459] loading: itn_EN:1
I0824 08:45:02.879061 1 model_lifecycle.cc:459] loading: itn_HI:1
I0824 08:45:02.879089 1 model_lifecycle.cc:459] loading: itn_OR:1
W0824 08:45:02.879128 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0824 08:45:02.879141 1 model_lifecycle.cc:459] loading: itn_TA:1
I0824 08:45:03.324359 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0824 08:45:03.324394 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0824 08:45:03.324400 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0824 08:45:03.326860 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0824 08:45:03.327381 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0824 08:45:03.327795 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0824 08:45:03.327805 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0824 08:45:03.327808 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0824 08:45:03.327812 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0824 08:45:03.327842 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0824 08:45:03.328157 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0824 08:45:03.328508 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0824 08:45:03.328518 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0824 08:45:03.328522 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0824 08:45:03.328525 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0824 08:45:03.328554 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0824 08:45:03.328889 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0824 08:45:03.329260 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0824 08:45:03.329271 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0824 08:45:03.329275 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0824 08:45:03.329279 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0824 08:45:03.329321 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0824 08:45:03.329752 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0824 08:45:03.330191 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0824 08:45:03.330201 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0824 08:45:03.330205 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0824 08:45:03.330229 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0824 08:45:03.330258 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0824 08:45:03.330761 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0824 08:45:03.331180 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0824 08:45:03.331189 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0824 08:45:03.331193 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0824 08:45:03.331197 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0824 08:45:03.332491 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0824 08:45:03.332511 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0824 08:45:03.332516 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0824 08:45:03.332519 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0824 08:45:03.341597 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0824 08:45:06.545211 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0824 08:45:06.546196 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0824 08:45:09.334525 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0824 08:45:11.358121 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0824 08:45:14.035698 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0824 08:45:16.483130 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0824 08:45:18.906719 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0824 08:45:24.015921 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0824 08:45:24.019521 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0824 08:45:24.019769 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0824 08:45:26.205377 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0824 08:45:26.206842 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0824 08:45:28.326375 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0824 08:45:28.326882 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0824 08:45:28.328473 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0824 08:46:27.249763 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0824 08:46:28.596479 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0824 08:46:28.916603 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0824 08:46:28.916738 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0824 08:46:29.274004 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0824 08:46:29.274185 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0824 08:46:30.705530 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0824 08:46:32.040076 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0824 08:46:33.358227 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0824 08:46:33.847619 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0824 08:46:33.847817 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0824 08:46:34.213208 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0824 08:46:34.213361 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0824 08:46:35.644500 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0824 08:46:35.644765 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0824 08:46:38.620831 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0824 08:46:38.620970 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0824 08:46:42.472313 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0824 08:46:42.472494 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0824 08:46:44.731411 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0824 08:46:44.731598 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0824 08:47:00.852083 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0824 08:47:00.852320 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0824 08:47:12.869476 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0824 08:47:12.869627 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0824 08:47:31.508631 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0824 08:47:31.508776 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0824 08:47:32.947068 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0824 08:47:34.583571 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0824 08:47:36.136550 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0824 08:47:37.527202 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0824 08:47:38.886216 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0824 08:47:40.384477 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0824 08:47:41.768395 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0824 08:47:43.105181 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0824 08:47:44.435035 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0824 08:47:45.899217 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0824 08:47:47.289157 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0824 08:47:48.595125 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0824 08:47:50.043981 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0824 08:47:51.700196 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0824 08:47:53.297427 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0824 08:47:54.663331 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0824 08:47:55.990058 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0824 08:47:57.464614 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0824 08:47:58.872575 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0824 08:48:00.183948 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0824 08:48:01.505503 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0824 08:48:02.995092 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0824 08:48:04.513156 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0824 08:48:05.981824 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0824 08:48:07.307536 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0824 08:48:07.307825 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0824 08:48:08.767155 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0824 08:48:08.767375 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0824 08:48:10.295787 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0824 08:48:10.296418 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0824 08:48:11.615425 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0824 08:48:11.616627 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0824 08:48:11.616698 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0824 08:48:11.616736 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0824 08:48:11.616769 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0824 08:48:11.616802 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0824 08:48:11.616857 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0824 08:48:11.616898 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0824 08:48:11.616937 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0824 08:48:11.616977 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0824 08:48:11.617017 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0824 08:48:11.617068 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0824 08:48:11.617091 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0824 08:48:11.617344 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0824 08:48:11.617414 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0824 08:48:11.617500 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0824 08:48:11.617562 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0824 08:48:11.617601 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0824 08:48:11.617639 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0824 08:48:11.617749 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0824 08:48:11.617786 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0824 08:48:11.617890 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0824 08:48:11.633481 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0824 08:48:11.633686 1 metrics.cc:757] Collecting CPU metrics
I0824 08:48:11.633799 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0824 08:48:11.634866 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0824 08:48:11.635035 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0824 08:48:11.676485 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0824 09:32:34.635319 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fa41c000000' with size 268435456
I0824 09:32:34.635674 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0824 09:32:34.640806 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0824 09:32:34.640847 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0824 09:32:34.640879 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0824 09:32:34.640928 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0824 09:32:34.640990 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0824 09:32:34.641113 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0824 09:32:34.641157 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0824 09:32:34.641271 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0824 09:32:34.641298 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0824 09:32:34.641322 1 model_lifecycle.cc:459] loading: entity_EN:1
I0824 09:32:34.641345 1 model_lifecycle.cc:459] loading: entity_HI:1
I0824 09:32:34.641367 1 model_lifecycle.cc:459] loading: entity_OR:1
W0824 09:32:34.641610 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0824 09:32:34.641627 1 model_lifecycle.cc:459] loading: entity_TA:1
I0824 09:32:34.641676 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0824 09:32:34.641750 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0824 09:32:34.641877 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0824 09:32:34.641938 1 model_lifecycle.cc:459] loading: itn_EN:1
I0824 09:32:34.641965 1 model_lifecycle.cc:459] loading: itn_HI:1
I0824 09:32:34.642045 1 model_lifecycle.cc:459] loading: itn_OR:1
W0824 09:32:34.642090 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0824 09:32:34.642169 1 model_lifecycle.cc:459] loading: itn_TA:1
I0824 09:32:35.048540 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0824 09:32:35.048582 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0824 09:32:35.048590 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0824 09:32:35.051474 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0824 09:32:35.052049 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0824 09:32:35.052511 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0824 09:32:35.052521 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0824 09:32:35.052525 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0824 09:32:35.052529 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0824 09:32:35.052575 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0824 09:32:35.052973 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0824 09:32:35.053379 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0824 09:32:35.053392 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0824 09:32:35.053396 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0824 09:32:35.053400 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0824 09:32:35.053453 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0824 09:32:35.053922 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0824 09:32:35.054308 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0824 09:32:35.054318 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0824 09:32:35.054322 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0824 09:32:35.054326 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0824 09:32:35.054362 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0824 09:32:35.054695 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0824 09:32:35.055046 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0824 09:32:35.055055 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0824 09:32:35.055059 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0824 09:32:35.055071 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0824 09:32:35.055091 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0824 09:32:35.055438 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0824 09:32:35.055800 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0824 09:32:35.055811 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0824 09:32:35.055815 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0824 09:32:35.055818 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0824 09:32:35.057252 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0824 09:32:35.057512 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0824 09:32:35.057525 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0824 09:32:35.057529 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0824 09:32:35.067941 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0824 09:32:38.377920 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0824 09:32:38.379257 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0824 09:32:40.627006 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0824 09:32:40.627741 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0824 09:32:43.386580 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0824 09:32:48.829466 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0824 09:32:51.669102 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0824 09:32:57.492515 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0824 09:32:59.529006 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0824 09:32:59.530151 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0824 09:33:01.836611 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0824 09:33:01.838010 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0824 09:33:01.839838 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0824 09:33:01.840016 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0824 09:33:01.840306 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0824 09:34:02.367783 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0824 09:34:03.763579 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0824 09:34:05.313933 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0824 09:34:05.640450 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0824 09:34:05.640593 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0824 09:34:06.134975 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0824 09:34:06.135117 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0824 09:34:07.630694 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0824 09:34:09.202162 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0824 09:34:09.605791 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0824 09:34:09.605976 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0824 09:34:13.239130 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0824 09:34:13.239259 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0824 09:34:14.595929 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0824 09:34:14.596264 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0824 09:34:16.957522 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0824 09:34:16.957731 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0824 09:34:37.406907 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0824 09:34:37.407060 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0824 09:34:53.779173 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0824 09:34:53.779363 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0824 09:34:57.735761 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0824 09:34:57.735910 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0824 09:35:10.382274 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0824 09:35:10.382480 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0824 09:35:10.749200 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0824 09:35:10.749336 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0824 09:35:12.224726 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0824 09:35:13.868997 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0824 09:35:15.546291 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0824 09:35:17.231413 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0824 09:35:18.651063 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0824 09:35:20.254598 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0824 09:35:21.647168 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0824 09:35:23.204456 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0824 09:35:24.665800 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0824 09:35:26.275984 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0824 09:35:27.714049 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0824 09:35:29.226527 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0824 09:35:30.816937 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0824 09:35:32.618723 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0824 09:35:34.241154 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0824 09:35:35.882325 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0824 09:35:37.314200 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0824 09:35:38.871154 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0824 09:35:40.287761 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0824 09:35:41.805621 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0824 09:35:43.278172 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0824 09:35:44.857516 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0824 09:35:46.290276 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0824 09:35:47.928787 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0824 09:35:49.409633 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0824 09:35:49.409898 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0824 09:35:51.007432 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0824 09:35:51.007717 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0824 09:35:52.433773 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0824 09:35:52.434055 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0824 09:35:54.008530 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0824 09:35:54.009730 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0824 09:35:54.009800 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0824 09:35:54.009848 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0824 09:35:54.009895 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0824 09:35:54.009942 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0824 09:35:54.009993 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0824 09:35:54.010049 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0824 09:35:54.010102 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0824 09:35:54.010148 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0824 09:35:54.010188 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0824 09:35:54.010230 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0824 09:35:54.010264 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0824 09:35:54.010521 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0824 09:35:54.010626 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0824 09:35:54.010690 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0824 09:35:54.010749 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0824 09:35:54.010808 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0824 09:35:54.010841 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0824 09:35:54.010963 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0824 09:35:54.011005 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0824 09:35:54.011108 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0824 09:35:54.027737 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0824 09:35:54.027921 1 metrics.cc:757] Collecting CPU metrics
I0824 09:35:54.028032 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0824 09:35:54.029167 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0824 09:35:54.029347 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0824 09:35:54.070805 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0825 14:20:48.217603 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fcdba000000' with size 268435456
I0825 14:20:48.217947 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0825 14:20:48.224320 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0825 14:20:48.224372 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0825 14:20:48.224399 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0825 14:20:48.224432 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0825 14:20:48.224562 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0825 14:20:48.224603 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0825 14:20:48.224643 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0825 14:20:48.224672 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0825 14:20:48.224712 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0825 14:20:48.224764 1 model_lifecycle.cc:459] loading: entity_EN:1
I0825 14:20:48.224795 1 model_lifecycle.cc:459] loading: entity_HI:1
I0825 14:20:48.224820 1 model_lifecycle.cc:459] loading: entity_OR:1
W0825 14:20:48.225055 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0825 14:20:48.225077 1 model_lifecycle.cc:459] loading: entity_TA:1
I0825 14:20:48.225119 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0825 14:20:48.225168 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0825 14:20:48.225209 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0825 14:20:48.225258 1 model_lifecycle.cc:459] loading: itn_EN:1
I0825 14:20:48.225308 1 model_lifecycle.cc:459] loading: itn_HI:1
I0825 14:20:48.225332 1 model_lifecycle.cc:459] loading: itn_OR:1
W0825 14:20:48.225371 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0825 14:20:48.225416 1 model_lifecycle.cc:459] loading: itn_TA:1
I0825 14:20:48.629547 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0825 14:20:48.629593 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0825 14:20:48.629599 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0825 14:20:48.632128 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0825 14:20:48.632598 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0825 14:20:48.632957 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0825 14:20:48.632967 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0825 14:20:48.632971 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0825 14:20:48.632974 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0825 14:20:48.633007 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0825 14:20:48.633398 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0825 14:20:48.633776 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0825 14:20:48.633786 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0825 14:20:48.633790 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0825 14:20:48.633794 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0825 14:20:48.633831 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0825 14:20:48.634267 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0825 14:20:48.634793 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0825 14:20:48.634806 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0825 14:20:48.634811 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0825 14:20:48.634816 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0825 14:20:48.634854 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0825 14:20:48.635165 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0825 14:20:48.635617 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0825 14:20:48.635627 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0825 14:20:48.635630 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0825 14:20:48.635634 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0825 14:20:48.635657 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0825 14:20:48.636112 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0825 14:20:48.636524 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0825 14:20:48.636535 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0825 14:20:48.636539 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0825 14:20:48.636543 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0825 14:20:48.637964 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0825 14:20:48.638002 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0825 14:20:48.638015 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0825 14:20:48.638021 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0825 14:20:48.653109 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0825 14:20:52.050468 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0825 14:20:52.051755 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0825 14:20:54.032202 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0825 14:20:54.033315 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0825 14:20:54.035576 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0825 14:20:54.035726 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0825 14:20:56.786923 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0825 14:20:58.849059 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0825 14:21:01.534842 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0825 14:21:03.996793 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0825 14:21:07.784525 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0825 14:21:16.696504 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0825 14:21:18.741696 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0825 14:21:18.742221 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0825 14:21:18.742900 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0825 14:22:11.596137 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0825 14:22:12.897353 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0825 14:22:13.217975 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0825 14:22:13.218196 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0825 14:22:13.543970 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0825 14:22:13.544106 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0825 14:22:14.800501 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0825 14:22:16.129259 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0825 14:22:16.646984 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0825 14:22:16.647156 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0825 14:22:18.172938 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0825 14:22:18.527044 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0825 14:22:18.527199 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0825 14:22:21.251124 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0825 14:22:21.251280 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0825 14:22:23.501355 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0825 14:22:23.501463 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0825 14:22:24.862799 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0825 14:22:24.863154 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0825 14:22:28.271919 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0825 14:22:28.272072 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0825 14:22:44.618360 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0825 14:22:44.618530 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0825 14:23:03.280362 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0825 14:23:03.280548 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0825 14:23:14.934478 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0825 14:23:14.934603 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0825 14:23:16.255456 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0825 14:23:17.685774 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0825 14:23:19.219735 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0825 14:23:20.845056 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0825 14:23:22.354345 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0825 14:23:23.734194 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0825 14:23:25.110035 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0825 14:23:26.552666 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0825 14:23:27.896194 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0825 14:23:29.231930 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0825 14:23:30.611576 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0825 14:23:32.036563 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0825 14:23:33.332900 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0825 14:23:34.666708 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0825 14:23:36.194798 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0825 14:23:37.827987 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0825 14:23:39.381887 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0825 14:23:40.829616 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0825 14:23:42.210107 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0825 14:23:43.661348 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0825 14:23:44.986253 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0825 14:23:46.294666 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0825 14:23:47.676012 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0825 14:23:49.111295 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0825 14:23:50.409744 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0825 14:23:50.409935 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0825 14:23:51.828499 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0825 14:23:51.828752 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0825 14:23:53.252542 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0825 14:23:53.252734 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0825 14:23:54.756245 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0825 14:23:54.757428 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0825 14:23:54.757500 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0825 14:23:54.757552 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0825 14:23:54.757586 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0825 14:23:54.757618 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0825 14:23:54.757653 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0825 14:23:54.757687 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0825 14:23:54.757721 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0825 14:23:54.757759 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0825 14:23:54.757790 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0825 14:23:54.757834 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0825 14:23:54.757871 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0825 14:23:54.758245 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0825 14:23:54.758312 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0825 14:23:54.758357 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0825 14:23:54.758415 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0825 14:23:54.758488 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0825 14:23:54.758531 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0825 14:23:54.758621 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0825 14:23:54.758662 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0825 14:23:54.758746 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0825 14:23:54.774822 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0825 14:23:54.775005 1 metrics.cc:757] Collecting CPU metrics
I0825 14:23:54.775118 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0825 14:23:54.776176 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0825 14:23:54.776342 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0825 14:23:54.817781 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0826 12:57:39.105392 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f0866000000' with size 268435456
I0826 12:57:39.105733 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0826 12:57:39.111453 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0826 12:57:39.111499 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0826 12:57:39.111550 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0826 12:57:39.111587 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0826 12:57:39.111661 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0826 12:57:39.111701 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0826 12:57:39.111727 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0826 12:57:39.111830 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0826 12:57:39.111866 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0826 12:57:39.111923 1 model_lifecycle.cc:459] loading: entity_EN:1
I0826 12:57:39.111950 1 model_lifecycle.cc:459] loading: entity_HI:1
I0826 12:57:39.111974 1 model_lifecycle.cc:459] loading: entity_OR:1
W0826 12:57:39.112211 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0826 12:57:39.112232 1 model_lifecycle.cc:459] loading: entity_TA:1
I0826 12:57:39.112295 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0826 12:57:39.112335 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0826 12:57:39.112404 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0826 12:57:39.112481 1 model_lifecycle.cc:459] loading: itn_EN:1
I0826 12:57:39.112509 1 model_lifecycle.cc:459] loading: itn_HI:1
I0826 12:57:39.112560 1 model_lifecycle.cc:459] loading: itn_OR:1
W0826 12:57:39.112595 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0826 12:57:39.112630 1 model_lifecycle.cc:459] loading: itn_TA:1
I0826 12:57:39.524565 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0826 12:57:39.524603 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0826 12:57:39.524607 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0826 12:57:39.527205 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0826 12:57:39.527825 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0826 12:57:39.528188 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0826 12:57:39.528197 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0826 12:57:39.528201 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0826 12:57:39.528205 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0826 12:57:39.528246 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0826 12:57:39.528603 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0826 12:57:39.528958 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0826 12:57:39.528967 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0826 12:57:39.528970 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0826 12:57:39.528974 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0826 12:57:39.529006 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0826 12:57:39.529382 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0826 12:57:39.529810 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0826 12:57:39.529821 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0826 12:57:39.529825 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0826 12:57:39.529830 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0826 12:57:39.529876 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0826 12:57:39.530243 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0826 12:57:39.530621 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0826 12:57:39.530631 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0826 12:57:39.530644 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0826 12:57:39.530648 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0826 12:57:39.530677 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0826 12:57:39.530942 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0826 12:57:39.531264 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0826 12:57:39.531272 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0826 12:57:39.531276 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0826 12:57:39.531280 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0826 12:57:39.532828 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0826 12:57:39.532873 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0826 12:57:39.532881 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0826 12:57:39.532885 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0826 12:57:39.542036 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0826 12:57:42.682807 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0826 12:57:42.687819 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0826 12:57:44.648187 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0826 12:57:44.648943 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0826 12:57:48.739118 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0826 12:57:53.913284 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0826 12:57:56.364406 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0826 12:57:56.368158 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0826 12:57:56.368446 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0826 12:58:01.816314 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0826 12:58:03.827933 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0826 12:58:03.829352 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0826 12:58:05.920513 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0826 12:58:05.921048 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0826 12:58:05.921660 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0826 12:59:03.788946 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0826 12:59:05.088806 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0826 12:59:05.534807 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0826 12:59:05.534929 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0826 12:59:06.837114 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0826 12:59:07.147328 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0826 12:59:07.147444 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0826 12:59:07.490662 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0826 12:59:07.490876 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0826 12:59:08.961783 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0826 12:59:10.350703 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0826 12:59:10.652381 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0826 12:59:10.652538 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0826 12:59:14.385095 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0826 12:59:14.385246 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0826 12:59:15.689184 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0826 12:59:15.689449 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0826 12:59:18.091976 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0826 12:59:18.092138 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0826 12:59:21.923259 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0826 12:59:21.923397 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0826 12:59:33.139157 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0826 12:59:33.139342 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0826 12:59:49.142404 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0826 12:59:49.142571 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0826 13:00:08.445999 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0826 13:00:08.446172 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0826 13:00:09.823136 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0826 13:00:11.175743 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0826 13:00:12.745269 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0826 13:00:14.294677 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0826 13:00:15.756541 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0826 13:00:17.246393 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0826 13:00:18.798041 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0826 13:00:20.175341 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0826 13:00:21.504742 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0826 13:00:22.814305 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0826 13:00:24.263391 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0826 13:00:25.653138 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0826 13:00:26.984279 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0826 13:00:28.279869 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0826 13:00:29.737103 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0826 13:00:31.202814 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0826 13:00:32.675696 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0826 13:00:34.137225 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0826 13:00:35.761473 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0826 13:00:37.192681 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0826 13:00:38.542995 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0826 13:00:39.859790 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0826 13:00:41.317178 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0826 13:00:42.692454 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0826 13:00:44.023173 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0826 13:00:44.023439 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0826 13:00:45.356127 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0826 13:00:45.356316 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0826 13:00:46.833138 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0826 13:00:46.833393 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0826 13:00:48.339279 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0826 13:00:48.340449 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0826 13:00:48.340503 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0826 13:00:48.340534 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0826 13:00:48.340564 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0826 13:00:48.340595 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0826 13:00:48.340630 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0826 13:00:48.340664 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0826 13:00:48.340696 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0826 13:00:48.340733 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0826 13:00:48.340765 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0826 13:00:48.340813 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0826 13:00:48.340881 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0826 13:00:48.341235 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0826 13:00:48.341271 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0826 13:00:48.341346 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0826 13:00:48.341405 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0826 13:00:48.341448 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0826 13:00:48.341490 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0826 13:00:48.341578 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0826 13:00:48.341614 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0826 13:00:48.341698 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0826 13:00:48.357364 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0826 13:00:48.357663 1 metrics.cc:757] Collecting CPU metrics
I0826 13:00:48.357772 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0826 13:00:48.358827 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0826 13:00:48.358995 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0826 13:00:48.400359 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0828 15:14:35.550057 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f1ada000000' with size 268435456
I0828 15:14:35.550412 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0828 15:14:35.556304 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0828 15:14:35.556362 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0828 15:14:35.556393 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0828 15:14:35.556432 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0828 15:14:35.556535 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0828 15:14:35.556574 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0828 15:14:35.556613 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0828 15:14:35.556644 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0828 15:14:35.556688 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0828 15:14:35.556751 1 model_lifecycle.cc:459] loading: entity_EN:1
I0828 15:14:35.556785 1 model_lifecycle.cc:459] loading: entity_HI:1
I0828 15:14:35.556810 1 model_lifecycle.cc:459] loading: entity_OR:1
W0828 15:14:35.557010 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0828 15:14:35.557036 1 model_lifecycle.cc:459] loading: entity_TA:1
I0828 15:14:35.557070 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0828 15:14:35.557129 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0828 15:14:35.557302 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0828 15:14:35.557407 1 model_lifecycle.cc:459] loading: itn_EN:1
I0828 15:14:35.557509 1 model_lifecycle.cc:459] loading: itn_HI:1
I0828 15:14:35.557607 1 model_lifecycle.cc:459] loading: itn_OR:1
W0828 15:14:35.557720 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0828 15:14:35.557804 1 model_lifecycle.cc:459] loading: itn_TA:1
I0828 15:14:36.014868 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0828 15:14:36.014925 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0828 15:14:36.014931 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0828 15:14:36.017321 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0828 15:14:36.018093 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0828 15:14:36.018700 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0828 15:14:36.018726 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0828 15:14:36.018735 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0828 15:14:36.018743 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0828 15:14:36.018784 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0828 15:14:36.019134 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0828 15:14:36.019480 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0828 15:14:36.019496 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0828 15:14:36.019501 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0828 15:14:36.019506 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0828 15:14:36.019535 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0828 15:14:36.019863 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0828 15:14:36.020205 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0828 15:14:36.020223 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0828 15:14:36.020228 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0828 15:14:36.020233 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0828 15:14:36.020269 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0828 15:14:36.020639 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0828 15:14:36.021005 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0828 15:14:36.021023 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0828 15:14:36.021028 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0828 15:14:36.021033 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0828 15:14:36.021070 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0828 15:14:36.021494 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0828 15:14:36.021884 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0828 15:14:36.021902 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0828 15:14:36.021906 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0828 15:14:36.021911 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0828 15:14:36.023405 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0828 15:14:36.023455 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0828 15:14:36.023466 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0828 15:14:36.023471 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0828 15:14:36.034862 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0828 15:14:39.139018 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0828 15:14:39.140181 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0828 15:14:41.159521 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 15:14:41.160248 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0828 15:14:43.883598 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0828 15:14:46.005920 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 15:14:46.006893 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0828 15:14:48.469778 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 15:14:51.228126 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 15:14:59.042666 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0828 15:14:59.045921 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0828 15:14:59.046133 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0828 15:15:01.266837 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0828 15:15:01.267484 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0828 15:15:01.267913 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0828 15:15:58.648097 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0828 15:15:59.957114 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0828 15:16:01.319346 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0828 15:16:02.734193 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0828 15:16:04.000075 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0828 15:16:04.306991 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0828 15:16:04.307138 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0828 15:16:04.742827 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0828 15:16:04.742997 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0828 15:16:05.111271 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0828 15:16:05.111544 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0828 15:16:05.417042 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0828 15:16:05.417196 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0828 15:16:06.850327 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0828 15:16:06.850695 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0828 15:16:10.762617 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0828 15:16:10.762774 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0828 15:16:14.274126 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0828 15:16:14.274288 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0828 15:16:16.517132 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0828 15:16:16.517363 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0828 15:16:27.736129 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0828 15:16:27.736243 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0828 15:16:43.408663 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0828 15:16:43.408836 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0828 15:17:01.897079 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0828 15:17:01.897234 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0828 15:17:03.345059 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0828 15:17:04.789326 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0828 15:17:06.282186 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0828 15:17:07.611929 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0828 15:17:08.928269 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0828 15:17:10.310680 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0828 15:17:11.769177 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0828 15:17:13.059325 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0828 15:17:14.349217 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0828 15:17:15.839148 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0828 15:17:17.504814 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0828 15:17:18.974683 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0828 15:17:20.306091 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0828 15:17:21.661149 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0828 15:17:23.097186 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0828 15:17:24.408051 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0828 15:17:25.763811 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0828 15:17:27.153201 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0828 15:17:28.753569 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0828 15:17:30.099206 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0828 15:17:31.551173 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0828 15:17:32.983649 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0828 15:17:34.537126 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0828 15:17:35.932132 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0828 15:17:37.275795 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0828 15:17:37.276075 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0828 15:17:38.679380 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0828 15:17:38.679616 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0828 15:17:40.137502 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0828 15:17:40.137727 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0828 15:17:41.464002 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0828 15:17:41.465206 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0828 15:17:41.465276 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0828 15:17:41.465314 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0828 15:17:41.465374 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0828 15:17:41.465417 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0828 15:17:41.465455 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0828 15:17:41.465493 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0828 15:17:41.465529 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0828 15:17:41.465570 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0828 15:17:41.465622 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0828 15:17:41.465697 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0828 15:17:41.465777 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0828 15:17:41.465942 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0828 15:17:41.465983 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0828 15:17:41.466014 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0828 15:17:41.466080 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0828 15:17:41.466151 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0828 15:17:41.466214 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0828 15:17:41.466329 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0828 15:17:41.466378 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0828 15:17:41.466494 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0828 15:17:41.483048 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0828 15:17:41.483258 1 metrics.cc:757] Collecting CPU metrics
I0828 15:17:41.483399 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0828 15:17:41.484506 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0828 15:17:41.484691 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0828 15:17:41.526080 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0828 15:22:18.073473 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f7aee000000' with size 268435456
I0828 15:22:18.073826 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0828 15:22:18.078366 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0828 15:22:18.078418 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0828 15:22:18.078460 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0828 15:22:18.078493 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0828 15:22:18.078630 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0828 15:22:18.078673 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0828 15:22:18.078706 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0828 15:22:18.078731 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0828 15:22:18.078896 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0828 15:22:18.078934 1 model_lifecycle.cc:459] loading: entity_EN:1
I0828 15:22:18.078959 1 model_lifecycle.cc:459] loading: entity_HI:1
I0828 15:22:18.078981 1 model_lifecycle.cc:459] loading: entity_OR:1
W0828 15:22:18.079462 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0828 15:22:18.079488 1 model_lifecycle.cc:459] loading: entity_TA:1
I0828 15:22:18.079546 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0828 15:22:18.079600 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0828 15:22:18.079636 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0828 15:22:18.079661 1 model_lifecycle.cc:459] loading: itn_EN:1
I0828 15:22:18.080495 1 model_lifecycle.cc:459] loading: itn_HI:1
I0828 15:22:18.080538 1 model_lifecycle.cc:459] loading: itn_OR:1
W0828 15:22:18.080573 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0828 15:22:18.080586 1 model_lifecycle.cc:459] loading: itn_TA:1
I0828 15:22:18.439731 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0828 15:22:18.439786 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0828 15:22:18.439795 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0828 15:22:18.441798 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0828 15:22:18.442348 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0828 15:22:18.442723 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0828 15:22:18.442741 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0828 15:22:18.442746 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0828 15:22:18.442750 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0828 15:22:18.442787 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0828 15:22:18.443163 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0828 15:22:18.443537 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0828 15:22:18.443555 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0828 15:22:18.443560 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0828 15:22:18.443564 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0828 15:22:18.443589 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0828 15:22:18.443976 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0828 15:22:18.444488 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0828 15:22:18.444507 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0828 15:22:18.444514 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0828 15:22:18.444521 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0828 15:22:18.444556 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0828 15:22:18.444924 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0828 15:22:18.445373 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0828 15:22:18.445393 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0828 15:22:18.445400 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0828 15:22:18.445409 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0828 15:22:18.445453 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0828 15:22:18.445860 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0828 15:22:18.446249 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0828 15:22:18.446266 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0828 15:22:18.446271 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0828 15:22:18.446276 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0828 15:22:18.447373 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0828 15:22:18.447417 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0828 15:22:18.447432 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0828 15:22:18.447439 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0828 15:22:18.456197 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0828 15:22:21.088117 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0828 15:22:21.089310 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0828 15:22:22.903674 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 15:22:22.904394 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0828 15:22:26.674033 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 15:22:29.107676 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 15:22:31.534553 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 15:22:37.970256 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0828 15:22:39.712638 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0828 15:22:39.714151 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0828 15:22:39.715759 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0828 15:22:39.715885 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0828 15:22:41.574884 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0828 15:22:41.575416 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0828 15:22:41.575993 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0828 15:23:40.774054 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0828 15:23:42.107725 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0828 15:23:42.554641 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0828 15:23:42.554800 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0828 15:23:43.826277 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0828 15:23:45.269650 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0828 15:23:46.654607 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0828 15:23:46.989669 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0828 15:23:46.989904 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0828 15:23:47.294843 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0828 15:23:47.295009 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0828 15:23:47.594633 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0828 15:23:47.594769 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0828 15:23:48.750838 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0828 15:23:48.751148 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0828 15:23:52.709731 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0828 15:23:52.709837 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0828 15:23:56.187068 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0828 15:23:56.187246 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0828 15:23:58.449285 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0828 15:23:58.449445 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0828 15:24:17.806366 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0828 15:24:17.806565 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0828 15:24:33.080364 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0828 15:24:33.080508 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0828 15:24:44.860959 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0828 15:24:44.861134 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0828 15:24:46.162619 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0828 15:24:47.445177 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0828 15:24:48.850958 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0828 15:24:50.208464 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0828 15:24:51.490655 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0828 15:24:52.757328 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0828 15:24:54.171868 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0828 15:24:55.531580 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0828 15:24:56.828045 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0828 15:24:58.108992 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0828 15:24:59.542386 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0828 15:25:00.978584 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0828 15:25:02.280632 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0828 15:25:03.615483 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0828 15:25:05.060359 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0828 15:25:06.456940 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0828 15:25:07.761757 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0828 15:25:09.122117 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0828 15:25:10.556477 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0828 15:25:11.973282 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0828 15:25:13.284426 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0828 15:25:14.577283 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0828 15:25:16.003880 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0828 15:25:17.390384 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0828 15:25:18.706653 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0828 15:25:18.706866 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0828 15:25:20.006313 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0828 15:25:20.063793 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0828 15:25:21.423352 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0828 15:25:21.478383 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0828 15:25:22.773926 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0828 15:25:22.775118 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0828 15:25:22.775195 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0828 15:25:22.775233 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0828 15:25:22.775269 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0828 15:25:22.775304 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0828 15:25:22.775344 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0828 15:25:22.775390 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0828 15:25:22.775428 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0828 15:25:22.775468 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0828 15:25:22.775505 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0828 15:25:22.775547 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0828 15:25:22.775617 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0828 15:25:22.775882 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0828 15:25:22.775955 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0828 15:25:22.776026 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0828 15:25:22.776065 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0828 15:25:22.776116 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0828 15:25:22.776165 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0828 15:25:22.776284 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0828 15:25:22.776323 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0828 15:25:22.776428 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0828 15:25:22.792118 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0828 15:25:22.792319 1 metrics.cc:757] Collecting CPU metrics
I0828 15:25:22.792436 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0828 15:25:22.793585 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0828 15:25:22.793764 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0828 15:25:22.835095 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0828 21:33:44.303117 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f8b4a000000' with size 268435456
I0828 21:33:44.303646 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0828 21:33:44.308850 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0828 21:33:44.308910 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0828 21:33:44.308939 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0828 21:33:44.309000 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0828 21:33:44.309104 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0828 21:33:44.309147 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0828 21:33:44.309181 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0828 21:33:44.309230 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0828 21:33:44.309276 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0828 21:33:44.309313 1 model_lifecycle.cc:459] loading: entity_EN:1
I0828 21:33:44.309342 1 model_lifecycle.cc:459] loading: entity_HI:1
I0828 21:33:44.309367 1 model_lifecycle.cc:459] loading: entity_OR:1
W0828 21:33:44.309708 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0828 21:33:44.309743 1 model_lifecycle.cc:459] loading: entity_TA:1
I0828 21:33:44.309780 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0828 21:33:44.309837 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0828 21:33:44.309875 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0828 21:33:44.309964 1 model_lifecycle.cc:459] loading: itn_EN:1
I0828 21:33:44.310541 1 model_lifecycle.cc:459] loading: itn_HI:1
I0828 21:33:44.310583 1 model_lifecycle.cc:459] loading: itn_OR:1
W0828 21:33:44.310621 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0828 21:33:44.310638 1 model_lifecycle.cc:459] loading: itn_TA:1
I0828 21:33:44.704943 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0828 21:33:44.704994 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0828 21:33:44.705000 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0828 21:33:44.707445 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0828 21:33:44.707995 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0828 21:33:44.708440 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0828 21:33:44.708461 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0828 21:33:44.708470 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0828 21:33:44.708478 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0828 21:33:44.708521 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0828 21:33:44.708958 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0828 21:33:44.709316 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0828 21:33:44.709334 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0828 21:33:44.709339 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0828 21:33:44.709345 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0828 21:33:44.709374 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0828 21:33:44.709653 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0828 21:33:44.709990 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0828 21:33:44.710006 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0828 21:33:44.710012 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0828 21:33:44.710016 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0828 21:33:44.710049 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0828 21:33:44.710491 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0828 21:33:44.710966 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0828 21:33:44.710987 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0828 21:33:44.710993 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0828 21:33:44.710998 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0828 21:33:44.711025 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0828 21:33:44.711291 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0828 21:33:44.711680 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0828 21:33:44.711697 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0828 21:33:44.711702 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0828 21:33:44.711706 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0828 21:33:44.713144 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0828 21:33:44.713184 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0828 21:33:44.713196 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0828 21:33:44.713200 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0828 21:33:44.722514 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0828 21:33:47.746804 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0828 21:33:47.748189 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0828 21:33:49.809721 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 21:33:49.810528 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0828 21:33:52.564525 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 21:33:54.996541 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 21:34:01.465793 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0828 21:34:05.583361 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0828 21:34:05.586594 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0828 21:34:05.586854 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0828 21:34:07.812850 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0828 21:34:07.814148 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0828 21:34:10.160288 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0828 21:34:10.160900 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0828 21:34:10.162077 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0828 21:35:10.326703 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0828 21:35:11.749376 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0828 21:35:13.221124 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0828 21:35:14.604887 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0828 21:35:15.076244 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0828 21:35:15.076400 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0828 21:35:15.401040 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0828 21:35:15.401217 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0828 21:35:15.757332 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0828 21:35:15.757478 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0828 21:35:17.322516 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0828 21:35:17.645285 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0828 21:35:17.645474 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0828 21:35:19.028191 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0828 21:35:19.028458 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0828 21:35:22.556916 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0828 21:35:22.557116 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0828 21:35:26.506210 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0828 21:35:26.506424 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0828 21:35:28.941896 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0828 21:35:28.942085 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0828 21:35:45.776890 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0828 21:35:45.777115 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0828 21:36:05.259003 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0828 21:36:05.259188 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0828 21:36:17.336196 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0828 21:36:17.336423 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0828 21:36:18.940946 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0828 21:36:20.515281 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0828 21:36:21.894364 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0828 21:36:23.455107 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0828 21:36:24.847700 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0828 21:36:26.356380 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0828 21:36:27.796189 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0828 21:36:29.338832 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0828 21:36:30.730942 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0828 21:36:32.290812 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0828 21:36:33.912677 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0828 21:36:35.661167 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0828 21:36:37.123220 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0828 21:36:38.639587 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0828 21:36:40.058833 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0828 21:36:41.637084 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0828 21:36:43.057123 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0828 21:36:44.526028 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0828 21:36:45.922850 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0828 21:36:47.646644 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0828 21:36:49.115303 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0828 21:36:50.642400 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0828 21:36:52.074283 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0828 21:36:53.721032 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0828 21:36:55.133588 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0828 21:36:55.133865 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0828 21:36:56.681453 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0828 21:36:56.681645 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0828 21:36:58.093284 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0828 21:36:58.093424 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0828 21:36:59.768948 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0828 21:36:59.770213 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0828 21:36:59.770283 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0828 21:36:59.770337 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0828 21:36:59.770391 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0828 21:36:59.770449 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0828 21:36:59.770504 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0828 21:36:59.770547 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0828 21:36:59.770600 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0828 21:36:59.770658 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0828 21:36:59.770690 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0828 21:36:59.770776 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0828 21:36:59.770857 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0828 21:36:59.771248 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0828 21:36:59.771296 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0828 21:36:59.771378 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0828 21:36:59.771481 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0828 21:36:59.771530 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0828 21:36:59.771640 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0828 21:36:59.771773 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0828 21:36:59.771824 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0828 21:36:59.771954 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0828 21:36:59.792895 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0828 21:36:59.793129 1 metrics.cc:757] Collecting CPU metrics
I0828 21:36:59.793275 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0828 21:36:59.794755 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0828 21:36:59.794967 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0828 21:36:59.836529 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 05:02:07.220940 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fc2fc000000' with size 268435456
I0829 05:02:07.221343 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 05:02:07.227630 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 05:02:07.227697 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 05:02:07.227738 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 05:02:07.227774 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 05:02:07.227834 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 05:02:07.227901 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 05:02:07.227953 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 05:02:07.227995 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 05:02:07.228033 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 05:02:07.228112 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 05:02:07.228153 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 05:02:07.228182 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 05:02:07.228589 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 05:02:07.228631 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 05:02:07.228715 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 05:02:07.228761 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 05:02:07.228861 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 05:02:07.228961 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 05:02:07.229032 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 05:02:07.229100 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 05:02:07.229144 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 05:02:07.229166 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 05:02:07.649857 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 05:02:07.649902 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 05:02:07.649910 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 05:02:07.652400 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 05:02:07.653103 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 05:02:07.653528 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 05:02:07.653604 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 05:02:07.653662 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 05:02:07.653727 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 05:02:07.653815 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 05:02:07.654441 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 05:02:07.654852 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 05:02:07.654870 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 05:02:07.654877 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 05:02:07.654881 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 05:02:07.654937 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 05:02:07.655375 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 05:02:07.655778 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 05:02:07.655798 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 05:02:07.655803 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 05:02:07.655810 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 05:02:07.655841 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 05:02:07.656144 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 05:02:07.656553 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 05:02:07.656573 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 05:02:07.656578 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 05:02:07.656584 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 05:02:07.656619 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 05:02:07.657015 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 05:02:07.657390 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 05:02:07.657406 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 05:02:07.657411 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 05:02:07.657416 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 05:02:07.660039 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 05:02:07.660072 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 05:02:07.660083 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 05:02:07.660089 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 05:02:07.670148 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 05:02:10.384202 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 05:02:13.095954 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 05:02:15.784850 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 05:02:19.780888 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 05:02:23.014375 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 05:02:25.688249 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 05:02:27.988816 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 05:02:27.990589 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 05:02:27.992805 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 05:02:27.993101 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 05:02:30.208566 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 05:02:30.209861 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 05:02:32.299836 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 05:02:32.300414 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 05:02:32.302861 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 05:03:34.103727 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0829 05:03:35.621875 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0829 05:03:37.155415 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0829 05:03:38.542641 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0829 05:03:39.925282 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 05:03:40.264499 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 05:03:40.264664 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 05:03:40.627032 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 05:03:40.627197 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 05:03:41.102400 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 05:03:41.102626 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 05:03:42.591492 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 05:03:42.591761 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 05:03:42.956356 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 05:03:42.956596 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 05:03:45.649131 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 05:03:45.649213 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 05:03:49.992047 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 05:03:49.992257 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 05:03:52.428675 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 05:03:52.428851 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 05:04:08.482371 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 05:04:08.482564 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 05:04:26.808490 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 05:04:26.808736 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 05:04:38.188232 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0829 05:04:38.188364 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 05:04:39.586176 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0829 05:04:41.033398 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0829 05:04:42.319908 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0829 05:04:43.608551 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0829 05:04:44.983744 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0829 05:04:46.462254 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0829 05:04:47.942665 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0829 05:04:49.424983 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0829 05:04:50.884342 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0829 05:04:52.323543 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0829 05:04:53.609761 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0829 05:04:54.880456 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0829 05:04:56.259842 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0829 05:04:57.712050 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0829 05:04:59.135605 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0829 05:05:00.500567 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0829 05:05:01.885809 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0829 05:05:03.361634 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0829 05:05:04.710588 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0829 05:05:06.031262 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0829 05:05:07.406606 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0829 05:05:08.901121 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0829 05:05:10.242760 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0829 05:05:11.545161 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0829 05:05:12.953685 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0829 05:05:12.954034 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 05:05:14.423487 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0829 05:05:14.423838 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 05:05:15.739030 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0829 05:05:15.739238 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 05:05:17.028846 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 05:05:17.029959 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 05:05:17.030011 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 05:05:17.030047 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 05:05:17.030082 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 05:05:17.030116 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 05:05:17.030154 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 05:05:17.030190 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 05:05:17.030224 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 05:05:17.030264 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 05:05:17.030298 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 05:05:17.030368 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 05:05:17.030409 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 05:05:17.030721 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 05:05:17.030751 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 05:05:17.030787 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 05:05:17.030839 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 05:05:17.030872 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 05:05:17.030903 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 05:05:17.031007 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 05:05:17.031049 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 05:05:17.031137 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 05:05:17.046251 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 05:05:17.046459 1 metrics.cc:757] Collecting CPU metrics
I0829 05:05:17.046578 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 05:05:17.047804 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 05:05:17.047984 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 05:05:17.089281 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 05:48:44.633187 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f9a2a000000' with size 268435456
I0829 05:48:44.633523 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 05:48:44.638315 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 05:48:44.638371 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 05:48:44.638400 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 05:48:44.638469 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 05:48:44.638522 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 05:48:44.638585 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 05:48:44.638717 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 05:48:44.638765 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 05:48:44.638796 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 05:48:44.638826 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 05:48:44.638857 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 05:48:44.638882 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 05:48:44.639065 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 05:48:44.639093 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 05:48:44.639127 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 05:48:44.639158 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 05:48:44.639188 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 05:48:44.639262 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 05:48:44.639299 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 05:48:44.639328 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 05:48:44.639362 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 05:48:44.639385 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 05:48:45.026694 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 05:48:45.026750 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 05:48:45.026760 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 05:48:45.029081 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 05:48:45.029704 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 05:48:45.030104 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 05:48:45.030123 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 05:48:45.030128 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 05:48:45.030132 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 05:48:45.030168 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 05:48:45.030589 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 05:48:45.030981 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 05:48:45.030998 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 05:48:45.031005 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 05:48:45.031013 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 05:48:45.031043 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 05:48:45.031442 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 05:48:45.031907 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 05:48:45.031924 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 05:48:45.031930 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 05:48:45.031934 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 05:48:45.033239 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 05:48:45.033270 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 05:48:45.033280 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 05:48:45.033285 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 05:48:45.042077 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 05:48:47.968006 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 05:48:47.968982 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 05:48:50.215618 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 05:48:50.216305 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 05:48:52.943682 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 05:48:54.999942 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 05:48:55.000328 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 05:48:55.000693 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 05:48:55.000711 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 05:48:55.000716 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 05:48:55.000721 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 05:48:55.000764 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
I0829 05:48:55.001039 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
W0829 05:48:55.001127 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 05:48:55.001675 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 05:48:55.001755 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 05:48:55.001820 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 05:48:55.001897 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 05:48:55.002462 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 05:48:57.462445 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 05:49:02.590595 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 05:49:11.047074 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 05:49:11.047576 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 05:49:45.302227 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 05:49:57.407248 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0829 05:49:57.407524 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 05:49:58.658777 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 05:50:00.549352 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 05:50:00.550631 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 05:50:00.552785 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0829 05:50:00.553083 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 05:50:01.986525 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0829 05:50:03.335521 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 05:50:03.767907 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 05:50:03.768114 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 05:50:04.101275 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0829 05:50:04.101433 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 05:50:05.362972 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 05:50:05.669101 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 05:50:05.669260 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 05:50:08.607578 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 05:50:08.607761 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 05:50:08.895861 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 05:50:08.896023 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 05:50:11.967614 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 05:50:11.967767 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 05:50:13.239228 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 05:50:13.239523 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 05:50:15.576694 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 05:50:15.576856 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 05:50:31.405476 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 05:50:50.607261 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0829 05:50:51.905976 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0829 05:50:53.326632 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0829 05:50:54.681582 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0829 05:50:55.990897 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 05:51:14.304980 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0829 05:51:14.305145 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 05:51:15.609332 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0829 05:51:17.110366 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0829 05:51:18.682520 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0829 05:51:20.157340 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0829 05:51:21.438252 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0829 05:51:22.871184 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0829 05:51:24.230042 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0829 05:51:25.531462 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0829 05:51:26.835039 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0829 05:51:28.324423 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0829 05:51:29.876250 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0829 05:51:31.248318 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0829 05:51:32.593796 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0829 05:51:34.165173 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0829 05:51:35.638471 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0829 05:51:37.012954 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0829 05:51:38.423304 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0829 05:51:39.918099 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0829 05:51:41.457785 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0829 05:51:42.879684 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0829 05:51:44.250283 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0829 05:51:44.250546 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 05:51:45.994937 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0829 05:51:45.995190 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 05:51:47.634288 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0829 05:51:47.635793 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 05:51:49.147689 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 05:51:49.148980 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 05:51:49.149069 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 05:51:49.149109 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 05:51:49.149145 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 05:51:49.149181 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 05:51:49.149219 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 05:51:49.149275 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 05:51:49.149326 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 05:51:49.149367 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 05:51:49.149406 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 05:51:49.149469 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 05:51:49.149557 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 05:51:49.149769 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 05:51:49.149827 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 05:51:49.149918 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 05:51:49.150016 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 05:51:49.150060 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 05:51:49.150093 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 05:51:49.150221 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 05:51:49.150267 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 05:51:49.150361 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 05:51:49.166694 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 05:51:49.166894 1 metrics.cc:757] Collecting CPU metrics
I0829 05:51:49.167012 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 05:51:49.168236 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 05:51:49.168424 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 05:51:49.210408 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 09:28:51.622509 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f81ec000000' with size 268435456
I0829 09:28:51.622836 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 09:28:51.627584 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 09:28:51.627638 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 09:28:51.627675 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 09:28:51.627708 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 09:28:51.627756 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 09:28:51.627794 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 09:28:51.627824 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 09:28:51.627854 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 09:28:51.627887 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 09:28:51.627942 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 09:28:51.627973 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 09:28:51.627998 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 09:28:51.628314 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 09:28:51.628342 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 09:28:51.628379 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 09:28:51.628414 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 09:28:51.628449 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 09:28:51.628483 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 09:28:51.628535 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 09:28:51.628568 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 09:28:51.628608 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 09:28:51.628628 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 09:28:52.065515 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 09:28:52.065573 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 09:28:52.065581 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 09:28:52.068053 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 09:28:52.068617 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 09:28:52.068985 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 09:28:52.069003 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 09:28:52.069009 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 09:28:52.069013 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 09:28:52.069044 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 09:28:52.069295 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 09:28:52.069637 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 09:28:52.069655 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 09:28:52.069660 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 09:28:52.069664 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 09:28:52.069689 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 09:28:55.178999 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 09:28:55.179435 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 09:28:55.179815 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 09:28:55.179834 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 09:28:55.179839 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 09:28:55.179843 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 09:28:55.179907 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
I0829 09:28:55.180158 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
W0829 09:28:55.180464 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 09:28:55.180840 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 09:28:55.180858 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 09:28:55.180863 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 09:28:55.180867 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 09:28:55.182867 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 09:28:55.182912 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 09:28:55.182922 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 09:28:55.182927 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 09:28:55.193232 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 09:28:55.193666 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 09:28:55.194025 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 09:28:55.194042 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 09:28:55.194047 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 09:28:55.194053 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 09:28:55.194470 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 09:28:57.934197 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 09:29:00.354109 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 09:29:05.431831 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 09:29:10.502951 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 09:29:10.506282 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 09:29:10.506516 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 09:29:12.764046 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 09:29:12.765244 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 09:29:15.078000 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 09:29:15.078986 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 09:29:17.198600 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 09:29:17.199146 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 09:29:17.199923 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 09:30:15.797882 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0829 09:30:17.102965 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0829 09:30:18.516791 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0829 09:30:19.859254 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 09:30:20.161668 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 09:30:20.161820 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 09:30:20.611148 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0829 09:30:20.611270 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 09:30:21.887309 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 09:30:22.227492 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 09:30:22.227681 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 09:30:22.544064 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 09:30:22.544255 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 09:30:23.895454 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 09:30:23.895794 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 09:30:26.949809 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 09:30:26.950009 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 09:30:29.899520 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 09:30:29.899775 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 09:30:32.211163 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 09:30:32.211421 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 09:30:48.045626 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 09:30:48.045773 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 09:31:06.110025 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 09:31:06.110209 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 09:31:17.509752 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0829 09:31:17.509956 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 09:31:18.802793 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0829 09:31:20.221110 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0829 09:31:21.601881 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0829 09:31:22.894233 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0829 09:31:24.213189 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0829 09:31:25.656389 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0829 09:31:27.032396 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0829 09:31:28.487756 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0829 09:31:29.949174 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0829 09:31:31.537402 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0829 09:31:32.956100 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0829 09:31:34.257815 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0829 09:31:35.559957 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0829 09:31:36.992105 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0829 09:31:38.374357 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0829 09:31:39.649833 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0829 09:31:41.076075 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0829 09:31:42.624826 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0829 09:31:44.062897 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0829 09:31:45.393010 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0829 09:31:46.815921 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0829 09:31:48.300943 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0829 09:31:49.677836 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0829 09:31:51.058369 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0829 09:31:52.431316 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0829 09:31:52.431780 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 09:31:53.917919 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0829 09:31:53.918147 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 09:31:55.348540 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0829 09:31:55.348854 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 09:31:56.740321 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 09:31:56.741654 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 09:31:56.741731 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 09:31:56.741780 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 09:31:56.741819 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 09:31:56.741856 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 09:31:56.741896 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 09:31:56.741937 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 09:31:56.741977 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 09:31:56.742018 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 09:31:56.742066 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 09:31:56.742134 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 09:31:56.742206 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 09:31:56.742406 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 09:31:56.742465 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 09:31:56.742643 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 09:31:56.742713 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 09:31:56.742843 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 09:31:56.742949 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 09:31:56.743079 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 09:31:56.743124 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 09:31:56.743219 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 09:31:56.758824 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 09:31:56.759028 1 metrics.cc:757] Collecting CPU metrics
I0829 09:31:56.759153 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 09:31:56.760225 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 09:31:56.760398 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 09:31:56.801827 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 09:32:42.298609 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f1666000000' with size 268435456
I0829 09:32:42.299014 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 09:32:42.303990 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 09:32:42.304051 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 09:32:42.304097 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 09:32:42.304152 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 09:32:42.304206 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 09:32:42.304272 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 09:32:42.304319 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 09:32:42.304366 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 09:32:42.304416 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 09:32:42.304459 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 09:32:42.304502 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 09:32:42.304537 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 09:32:42.304815 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 09:32:42.304845 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 09:32:42.304925 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 09:32:42.304977 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 09:32:42.305030 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 09:32:42.305077 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 09:32:42.305116 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 09:32:42.305173 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 09:32:42.305227 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 09:32:42.305260 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 09:32:42.682930 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 09:32:42.682987 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 09:32:42.682995 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 09:32:42.685213 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 09:32:42.685756 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 09:32:42.686126 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 09:32:42.686144 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 09:32:42.686150 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 09:32:42.686155 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 09:32:42.686187 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 09:32:42.686542 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 09:32:42.686995 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 09:32:42.687013 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 09:32:42.687018 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 09:32:42.687023 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 09:32:42.687061 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 09:32:42.687430 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 09:32:42.687795 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 09:32:42.687826 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 09:32:42.687832 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 09:32:42.687836 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 09:32:42.687873 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 09:32:42.688240 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 09:32:42.688618 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 09:32:42.688635 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 09:32:42.688641 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 09:32:42.688645 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 09:32:42.688670 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 09:32:42.688961 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 09:32:42.689296 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 09:32:42.689314 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 09:32:42.689319 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 09:32:42.689323 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 09:32:42.690723 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 09:32:42.690749 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 09:32:42.690760 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 09:32:42.690765 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 09:32:42.699485 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 09:32:45.328258 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 09:32:45.329648 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 09:32:47.263233 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 09:32:47.263806 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 09:32:50.014463 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 09:32:50.017990 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 09:32:50.018263 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 09:32:53.818684 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 09:32:56.278653 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 09:33:03.094251 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 09:33:05.145252 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 09:33:05.146768 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 09:33:07.024021 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 09:33:07.024472 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 09:33:07.025835 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 09:34:07.511713 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0829 09:34:08.902829 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0829 09:34:10.429472 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 09:34:10.754356 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0829 09:34:10.754533 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 09:34:12.110619 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0829 09:34:13.581048 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 09:34:13.944168 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 09:34:13.944315 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 09:34:14.416607 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 09:34:14.416817 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 09:34:14.729180 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 09:34:14.729284 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 09:34:15.937738 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 09:34:15.938110 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 09:34:19.423862 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 09:34:19.424021 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 09:34:23.364284 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 09:34:23.364448 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 09:34:25.767649 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 09:34:25.767813 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 09:34:42.448181 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 09:34:42.449297 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 09:34:54.353592 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 09:34:54.353771 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 09:35:13.554485 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0829 09:35:13.554668 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 09:35:15.031871 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0829 09:35:16.553974 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0829 09:35:17.942177 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0829 09:35:19.459636 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0829 09:35:20.886003 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0829 09:35:22.471369 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0829 09:35:23.857662 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0829 09:35:25.410355 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0829 09:35:26.923494 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0829 09:35:28.569211 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0829 09:35:29.946967 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0829 09:35:31.429627 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0829 09:35:32.836436 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0829 09:35:34.388658 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0829 09:35:35.791894 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0829 09:35:37.289180 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0829 09:35:38.797552 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0829 09:35:40.427697 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0829 09:35:41.828323 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0829 09:35:43.287795 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0829 09:35:44.801304 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0829 09:35:46.392664 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0829 09:35:47.797905 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0829 09:35:49.358794 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0829 09:35:50.795876 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0829 09:35:50.796113 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 09:35:52.444971 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0829 09:35:52.445248 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 09:35:53.894922 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0829 09:35:53.895146 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 09:35:55.460259 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 09:35:55.461648 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 09:35:55.461741 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 09:35:55.461784 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 09:35:55.461835 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 09:35:55.461883 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 09:35:55.461950 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 09:35:55.462001 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 09:35:55.462045 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 09:35:55.462093 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 09:35:55.462157 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 09:35:55.462224 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 09:35:55.462304 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 09:35:55.462764 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 09:35:55.462851 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 09:35:55.462909 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 09:35:55.462960 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 09:35:55.463013 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 09:35:55.463065 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 09:35:55.463208 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 09:35:55.463263 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 09:35:55.463372 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 09:35:55.479826 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 09:35:55.480056 1 metrics.cc:757] Collecting CPU metrics
I0829 09:35:55.480219 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 09:35:55.481526 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 09:35:55.481706 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 09:35:55.523285 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 10:02:26.970015 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f905c000000' with size 268435456
I0829 10:02:26.970819 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 10:02:26.978412 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 10:02:26.978489 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 10:02:26.978551 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 10:02:26.978642 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 10:02:26.978696 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 10:02:26.978734 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 10:02:26.978776 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 10:02:26.978837 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 10:02:26.978980 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 10:02:26.979040 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 10:02:26.979080 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 10:02:26.979115 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 10:02:26.979292 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 10:02:26.979318 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 10:02:26.979370 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 10:02:26.979407 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 10:02:26.979447 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 10:02:26.979498 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 10:02:26.979527 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 10:02:26.979634 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 10:02:26.979677 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 10:02:26.979699 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 10:02:27.396301 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 10:02:27.396346 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 10:02:27.396354 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 10:02:27.398832 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 10:02:27.399323 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 10:02:27.399680 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 10:02:27.399696 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 10:02:27.399701 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 10:02:27.399705 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 10:02:27.399727 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 10:02:27.399992 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 10:02:27.400334 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 10:02:27.400350 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 10:02:27.400355 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 10:02:27.400359 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 10:02:27.400396 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 10:02:27.400845 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 10:02:27.401294 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 10:02:27.401315 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 10:02:27.401321 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 10:02:27.401327 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 10:02:27.401370 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 10:02:27.401881 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 10:02:27.402461 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 10:02:27.402487 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 10:02:27.402510 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 10:02:27.402517 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 10:02:27.402552 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 10:02:27.402836 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 10:02:27.403182 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 10:02:27.403198 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 10:02:27.403203 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 10:02:27.403207 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 10:02:27.404564 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 10:02:27.404618 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 10:02:27.404628 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 10:02:27.404632 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 10:02:27.416760 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 10:02:30.457265 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 10:02:30.458243 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 10:02:33.208407 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 10:02:35.404734 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 10:02:35.405572 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 10:02:38.161610 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 10:02:40.945674 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 10:02:48.767902 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 10:02:48.771496 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 10:02:48.771755 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 10:02:51.165632 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 10:02:51.166907 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 10:02:53.390355 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 10:02:58.854982 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 10:02:58.855545 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 10:03:55.356775 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0829 10:03:56.894777 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0829 10:03:58.265883 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0829 10:03:59.717325 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0829 10:04:01.058400 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 10:04:01.379482 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 10:04:01.379675 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 10:04:01.768851 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 10:04:01.769021 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 10:04:02.226784 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 10:04:02.226943 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 10:04:02.546662 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 10:04:02.546821 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 10:04:04.858345 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 10:04:04.858507 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 10:04:08.335669 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 10:04:08.335841 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 10:04:09.702369 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 10:04:09.702662 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 10:04:13.200348 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 10:04:13.200494 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 10:04:30.057226 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 10:04:30.057410 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 10:04:50.547240 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 10:04:50.547399 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 10:05:03.121450 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0829 10:05:03.121646 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 10:05:04.588383 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0829 10:05:05.911032 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0829 10:05:07.304314 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0829 10:05:08.616721 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0829 10:05:10.081591 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0829 10:05:11.416129 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0829 10:05:12.828868 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0829 10:05:14.194541 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0829 10:05:15.795578 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0829 10:05:17.288526 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0829 10:05:18.775436 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0829 10:05:20.124325 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0829 10:05:21.583013 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0829 10:05:22.937811 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0829 10:05:24.380698 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0829 10:05:25.756753 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0829 10:05:27.219013 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0829 10:05:28.715457 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0829 10:05:30.242563 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0829 10:05:31.607850 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0829 10:05:33.141932 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0829 10:05:34.681226 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0829 10:05:36.128180 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0829 10:05:37.500418 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0829 10:05:39.068137 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0829 10:05:39.068382 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 10:05:40.445568 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0829 10:05:40.445953 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 10:05:41.988099 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0829 10:05:41.988371 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 10:05:43.324337 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 10:05:43.325520 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 10:05:43.325587 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 10:05:43.325623 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 10:05:43.325656 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 10:05:43.325690 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 10:05:43.325728 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 10:05:43.325765 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 10:05:43.325819 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 10:05:43.325862 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 10:05:43.325891 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 10:05:43.325958 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 10:05:43.326006 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 10:05:43.326259 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 10:05:43.326303 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 10:05:43.326363 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 10:05:43.326460 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 10:05:43.326528 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 10:05:43.326551 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 10:05:43.326646 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 10:05:43.326691 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 10:05:43.326792 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 10:05:43.342372 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 10:05:43.342602 1 metrics.cc:757] Collecting CPU metrics
I0829 10:05:43.342724 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 10:05:43.343837 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 10:05:43.344023 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 10:05:43.385569 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 12:04:50.225476 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 12:04:50.225773 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0829 12:04:50.226549 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 12:04:50.226548 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 12:04:50.227672 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:04:50.228068 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0829 12:04:50.228128 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:04:50.228165 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:04:50.228197 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:04:50.228195 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 12:04:50.228489 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 12:04:50.228843 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:04:50.229558 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0829 12:04:50.229823 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:04:50.229871 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0829 12:04:50.230139 1 server.cc:295] All models are stopped, unloading models
I0829 12:04:50.230175 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0829 12:04:50.230287 1 server.cc:302] Timeout 30: Found 22 live models and 0 in-flight non-inference requests
I0829 12:04:50.231324 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0829 12:04:50.242732 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:04:50.242982 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0829 12:04:50.254939 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:04:50.254959 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:04:50.255119 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0829 12:04:50.255171 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0829 12:04:50.263531 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:04:50.263735 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0829 12:04:50.280528 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:04:50.280550 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:04:50.280649 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0829 12:04:50.280748 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0829 12:04:51.230916 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0829 12:04:51.323130 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0829 12:04:51.333676 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0829 12:04:51.339547 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0829 12:04:51.341714 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0829 12:04:51.414025 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0829 12:04:51.431509 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0829 12:04:51.434537 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0829 12:04:51.482249 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0829 12:04:51.543902 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0829 12:04:51.763645 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0829 12:04:52.231052 1 server.cc:302] Timeout 28: Found 4 live models and 0 in-flight non-inference requests
I0829 12:04:53.231200 1 server.cc:302] Timeout 27: Found 4 live models and 0 in-flight non-inference requests
I0829 12:04:54.231362 1 server.cc:302] Timeout 26: Found 4 live models and 0 in-flight non-inference requests
I0829 12:04:55.231511 1 server.cc:302] Timeout 25: Found 4 live models and 0 in-flight non-inference requests
I0829 12:04:56.239306 1 server.cc:302] Timeout 24: Found 4 live models and 0 in-flight non-inference requests
I0829 12:04:57.239459 1 server.cc:302] Timeout 23: Found 4 live models and 0 in-flight non-inference requests
I0829 12:04:58.239619 1 server.cc:302] Timeout 22: Found 4 live models and 0 in-flight non-inference requests
I0829 12:04:59.239786 1 server.cc:302] Timeout 21: Found 4 live models and 0 in-flight non-inference requests
I0829 12:05:09.077577 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fbc16000000' with size 268435456
I0829 12:05:09.077893 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 12:05:09.082941 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 12:05:09.082998 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 12:05:09.083031 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 12:05:09.083057 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 12:05:09.083084 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 12:05:09.083110 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 12:05:09.083134 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 12:05:09.083158 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 12:05:09.083183 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 12:05:09.083210 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 12:05:09.083235 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 12:05:09.083255 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 12:05:09.083418 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 12:05:09.083458 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 12:05:09.083494 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 12:05:09.083524 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 12:05:09.083566 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 12:05:09.083596 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 12:05:09.083623 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 12:05:09.083647 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 12:05:09.083676 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 12:05:09.083690 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 12:05:09.523221 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 12:05:09.523277 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 12:05:09.523286 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 12:05:09.523518 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 12:05:09.524132 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 12:05:09.524621 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 12:05:09.524638 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 12:05:09.524644 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 12:05:09.524650 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 12:05:09.524690 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 12:05:12.501296 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 12:05:12.501686 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 12:05:12.502049 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 12:05:12.502065 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 12:05:12.502071 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 12:05:12.502076 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 12:05:12.502115 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 12:05:12.503389 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 12:05:14.420103 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:05:14.474460 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 12:05:17.142492 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 12:05:17.142919 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 12:05:17.143313 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 12:05:17.143331 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 12:05:17.143348 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 12:05:17.143352 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 12:05:17.143807 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:05:19.559419 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 12:05:19.560025 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 12:05:19.560385 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 12:05:19.560402 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 12:05:19.560407 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 12:05:19.560411 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 12:05:19.560874 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:05:27.317738 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 12:05:27.317796 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 12:05:27.317810 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 12:05:27.317817 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 12:05:27.326632 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 12:05:27.329941 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0829 12:05:27.330333 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 12:05:28.670550 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 12:05:30.654830 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0829 12:05:30.656071 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 12:05:32.055193 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 12:05:32.331990 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 12:05:32.332114 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 12:05:32.664076 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 12:05:32.665387 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 12:05:33.080502 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 12:05:33.081169 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 12:05:33.358362 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0829 12:05:33.358552 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 12:05:34.601771 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 12:05:34.602224 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 12:05:34.602666 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 12:05:36.038800 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 12:05:36.038900 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:05:38.484693 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 12:05:38.485284 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 12:05:38.485845 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 12:05:38.485888 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 12:05:38.485897 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 12:05:38.485904 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 12:06:31.863900 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0829 12:06:33.206285 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0829 12:06:34.637767 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0829 12:06:37.627989 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0829 12:06:38.969645 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 12:06:40.848877 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 12:06:40.851217 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 12:06:46.043475 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 12:06:46.043599 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 12:06:48.261268 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 12:06:48.261398 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 12:07:03.898202 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 12:07:03.898384 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 12:07:22.905854 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 12:07:22.906011 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 12:07:34.177699 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0829 12:07:34.177964 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 12:07:35.644258 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0829 12:07:37.172392 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0829 12:07:38.534648 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 12:07:42.518471 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0829 12:07:42.518607 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 12:07:43.792811 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0829 12:07:45.210695 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0829 12:07:46.713063 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0829 12:07:48.011078 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0829 12:07:49.307976 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0829 12:07:50.685868 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0829 12:07:52.133499 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0829 12:07:53.432819 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0829 12:07:54.720101 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0829 12:07:56.095507 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0829 12:07:57.575816 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0829 12:07:58.947019 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0829 12:08:00.310624 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0829 12:08:01.733496 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0829 12:08:03.238100 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0829 12:08:04.563647 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0829 12:08:05.911176 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0829 12:08:07.322753 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0829 12:08:07.323005 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 12:08:08.831638 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0829 12:08:08.831852 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 12:08:10.176439 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0829 12:08:10.185662 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 12:08:11.520420 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0829 12:08:12.800129 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 12:08:12.801301 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 12:08:12.801376 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 12:08:12.801413 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 12:08:12.801448 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 12:08:12.801479 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 12:08:12.801513 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 12:08:12.801545 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 12:08:12.801577 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 12:08:12.801609 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 12:08:12.801648 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 12:08:12.801758 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 12:08:12.802223 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 12:08:12.802373 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 12:08:12.802421 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 12:08:12.802448 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 12:08:12.802475 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 12:08:12.802495 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 12:08:12.802515 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 12:08:12.802603 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 12:08:12.802650 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 12:08:12.802756 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 12:08:12.818096 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 12:08:12.818300 1 metrics.cc:757] Collecting CPU metrics
I0829 12:08:12.818420 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 12:08:12.819435 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 12:08:12.819606 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 12:08:12.860954 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 12:27:03.499970 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 12:27:03.500223 1 server.cc:280] Timeout 30: Found 2 model versions that have in-flight inferences
I0829 12:27:03.500234 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:03.500253 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:04.500365 1 server.cc:280] Timeout 29: Found 2 model versions that have in-flight inferences
I0829 12:27:04.500400 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:04.500406 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:05.500541 1 server.cc:280] Timeout 28: Found 2 model versions that have in-flight inferences
I0829 12:27:05.500592 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:05.500599 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:06.500743 1 server.cc:280] Timeout 27: Found 2 model versions that have in-flight inferences
I0829 12:27:06.500795 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:06.500801 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:07.500940 1 server.cc:280] Timeout 26: Found 2 model versions that have in-flight inferences
I0829 12:27:07.501001 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:07.501008 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:08.501130 1 server.cc:280] Timeout 25: Found 2 model versions that have in-flight inferences
I0829 12:27:08.501181 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:08.501191 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:09.501310 1 server.cc:280] Timeout 24: Found 2 model versions that have in-flight inferences
I0829 12:27:09.501353 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:09.501360 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:10.501471 1 server.cc:280] Timeout 23: Found 2 model versions that have in-flight inferences
I0829 12:27:10.501509 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:10.501513 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:11.501612 1 server.cc:280] Timeout 22: Found 2 model versions that have in-flight inferences
I0829 12:27:11.501641 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:11.501646 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:12.501753 1 server.cc:280] Timeout 21: Found 2 model versions that have in-flight inferences
I0829 12:27:12.501789 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:12.501795 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:27:13.501896 1 server.cc:280] Timeout 20: Found 2 model versions that have in-flight inferences
I0829 12:27:13.501928 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 12:27:13.501935 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 10 in-flight inferences
I0829 12:34:41.795869 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7efcec000000' with size 268435456
I0829 12:34:41.796622 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 12:34:41.801551 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 12:34:41.801610 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 12:34:41.801663 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 12:34:41.801709 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 12:34:41.801746 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 12:34:41.801777 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 12:34:41.801804 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 12:34:41.801834 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 12:34:41.801880 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 12:34:41.801959 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 12:34:41.802109 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 12:34:41.802207 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 12:34:41.802403 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 12:34:41.802501 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 12:34:41.802611 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 12:34:41.802714 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 12:34:41.802824 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 12:34:41.802942 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 12:34:41.803032 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 12:34:41.806496 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 12:34:41.806609 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 12:34:41.806691 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 12:34:42.197664 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 12:34:42.197715 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 12:34:42.197721 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 12:34:42.200642 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 12:34:42.201195 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 12:34:42.201567 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 12:34:42.201590 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 12:34:42.201597 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 12:34:42.201601 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 12:34:42.201637 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 12:34:42.202074 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 12:34:42.202656 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 12:34:42.202682 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 12:34:42.202690 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 12:34:42.202697 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 12:34:42.202743 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 12:34:42.203216 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 12:34:42.203622 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 12:34:42.203640 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 12:34:42.203645 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 12:34:42.203649 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 12:34:42.203675 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 12:34:42.204074 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 12:34:42.204598 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 12:34:42.204618 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 12:34:42.204630 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 12:34:42.204637 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 12:34:42.204666 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 12:34:42.204996 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 12:34:42.205344 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 12:34:42.205361 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 12:34:42.205365 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 12:34:42.205370 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 12:34:42.206868 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 12:34:42.206930 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 12:34:42.206950 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 12:34:42.206955 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 12:34:42.216131 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 12:34:57.168321 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:34:57.169666 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 12:34:59.866937 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 12:35:12.534069 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:35:12.534900 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 12:35:14.932293 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:35:17.319590 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:35:19.722084 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 12:35:21.014584 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 12:35:24.962499 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 12:35:24.965829 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 12:35:24.966083 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 12:35:27.213682 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 12:35:27.215343 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 12:35:29.262666 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 12:35:29.263136 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 12:35:29.264079 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 12:36:27.799225 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 12:36:29.178259 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 12:36:29.178527 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 12:36:30.644907 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 12:36:30.645088 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 12:36:31.975164 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 12:36:33.318724 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 12:36:33.610173 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 12:36:33.610346 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 12:36:34.038826 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 12:36:34.038982 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 12:36:34.344194 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 12:36:34.344351 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 12:36:35.650090 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 12:36:35.650440 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 12:36:38.219261 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 12:36:38.219436 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 12:36:42.015806 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 12:36:42.015980 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 12:36:44.246385 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 12:36:44.246625 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 12:37:00.209876 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 12:37:00.210051 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 12:37:18.953476 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 12:37:18.953656 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 12:37:30.517379 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 12:37:30.517556 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 12:37:30.875391 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 12:37:30.876478 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 12:37:30.876530 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 12:37:30.876566 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 12:37:30.876599 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 12:37:30.876629 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 12:37:30.876668 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 12:37:30.876705 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 12:37:30.876744 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 12:37:30.876782 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 12:37:30.876820 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 12:37:30.876887 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 12:37:30.876936 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 12:37:30.877235 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 12:37:30.877307 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 12:37:30.877376 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 12:37:30.877410 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 12:37:30.877442 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 12:37:30.877491 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 12:37:30.877584 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 12:37:30.877629 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 12:37:30.877901 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 12:37:30.894133 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 12:37:30.894413 1 metrics.cc:757] Collecting CPU metrics
I0829 12:37:30.894625 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 12:37:30.895856 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 12:37:30.896099 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 12:37:30.937253 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 12:49:54.179227 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f0a26000000' with size 268435456
I0829 12:49:54.179802 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 12:49:54.184561 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 12:49:54.184607 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 12:49:54.184641 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 12:49:54.184672 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 12:49:54.184705 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 12:49:54.184736 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 12:49:54.184761 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 12:49:54.184788 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 12:49:54.184840 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 12:49:54.184877 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 12:49:54.184908 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 12:49:54.184933 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 12:49:54.230473 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 12:49:54.230540 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 12:49:54.230597 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 12:49:54.230635 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 12:49:54.230677 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 12:49:54.230708 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 12:49:54.230734 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 12:49:54.230762 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 12:49:54.230799 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 12:49:54.230812 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 12:49:54.741413 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 12:49:54.741464 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 12:49:54.741473 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 12:49:54.745031 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 12:49:54.745191 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 12:49:54.745291 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 12:49:54.745382 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 12:49:54.755086 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 12:49:54.755668 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 12:49:54.756100 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 12:49:54.756123 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 12:49:54.756130 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 12:49:54.756135 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 12:49:54.756160 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 12:49:54.756483 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 12:49:54.756823 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 12:49:54.756838 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 12:49:54.756844 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 12:49:54.756849 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 12:49:54.756878 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 12:49:54.757254 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 12:49:54.757673 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 12:49:54.757689 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 12:49:54.757694 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 12:49:54.757698 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 12:49:54.757734 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 12:49:54.758146 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 12:49:54.758587 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 12:49:54.758604 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 12:49:54.758610 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 12:49:54.758614 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 12:49:57.410488 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:50:01.379859 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:50:04.083113 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:50:06.460820 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 12:50:06.461472 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 12:50:06.462002 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 12:50:06.462023 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 12:50:06.462029 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 12:50:06.462035 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 12:50:06.462517 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:50:10.435135 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 12:50:13.248257 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 12:50:13.249837 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 12:50:15.179733 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 12:50:15.180996 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 12:50:17.049006 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 12:50:17.050153 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 12:50:18.760001 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 12:50:18.760556 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 12:50:18.761921 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 12:51:17.282506 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 12:51:17.752271 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 12:51:17.752388 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 12:51:18.098502 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 12:51:18.098667 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 12:51:19.506222 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 12:51:19.506647 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 12:51:19.817112 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 12:51:19.817463 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 12:51:21.270375 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 12:51:21.270583 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 12:51:22.853047 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 12:51:22.853264 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 12:51:22.856984 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 12:51:22.857268 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 12:51:24.250861 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 12:51:24.251116 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 12:51:24.559699 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 12:51:24.559871 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 12:51:25.837390 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 12:51:25.838096 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 12:51:42.317030 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 12:51:42.317187 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 12:51:45.819037 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 12:51:45.819039 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 12:51:48.102138 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 12:51:48.102490 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 12:51:51.131630 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 12:51:51.132330 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 12:52:10.054786 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 12:52:10.054924 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 12:52:21.712873 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 12:52:21.714059 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 12:52:21.714141 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 12:52:21.714184 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 12:52:21.714220 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 12:52:21.714256 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 12:52:21.714293 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 12:52:21.714326 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 12:52:21.714360 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 12:52:21.714435 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 12:52:21.714480 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 12:52:21.714694 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 12:52:21.714739 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 12:52:21.714842 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 12:52:21.714903 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 12:52:21.714929 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 12:52:21.714991 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 12:52:21.715021 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 12:52:21.715044 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 12:52:21.715157 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 12:52:21.715202 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 12:52:21.715301 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 12:52:21.731874 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 12:52:21.732079 1 metrics.cc:757] Collecting CPU metrics
I0829 12:52:21.732202 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 12:52:21.733314 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 12:52:21.733492 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 12:52:21.774780 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 12:57:32.122899 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 12:57:32.122994 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0829 12:57:32.123236 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 12:57:32.123393 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 12:57:32.123401 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 12:57:32.123732 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0829 12:57:32.124262 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:57:32.124310 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:57:32.124619 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 12:57:32.124627 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:57:32.125275 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:57:32.125347 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:57:32.125667 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0829 12:57:32.125737 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0829 12:57:32.125896 1 server.cc:295] All models are stopped, unloading models
I0829 12:57:32.125913 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0829 12:57:32.125949 1 server.cc:302] Timeout 30: Found 22 live models and 0 in-flight non-inference requests
I0829 12:57:32.125930 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0829 12:57:32.125965 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 12:57:32.128761 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:57:32.128985 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0829 12:57:32.142416 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:57:32.142434 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:57:32.142455 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:57:32.142640 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0829 12:57:32.142683 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0829 12:57:32.151350 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0829 12:57:32.170916 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:57:32.170933 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 12:57:32.171084 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0829 12:57:32.171119 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0829 12:57:33.126267 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0829 12:57:33.158581 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0829 12:57:33.193927 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0829 12:57:33.212804 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0829 12:57:33.268762 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0829 12:57:33.296702 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0829 12:57:33.398947 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0829 12:57:33.451758 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0829 12:57:33.494963 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0829 12:57:33.508598 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0829 12:57:33.520719 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0829 12:57:33.527680 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0829 12:57:33.529567 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0829 12:57:33.598031 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0829 12:57:33.598621 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0829 12:57:34.126398 1 server.cc:302] Timeout 28: Found 0 live models and 0 in-flight non-inference requests
I0829 12:57:43.944725 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f7fb6000000' with size 268435456
I0829 12:57:43.945059 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 12:57:43.949584 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 12:57:43.949633 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 12:57:43.949669 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 12:57:43.949701 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 12:57:43.949748 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 12:57:43.949793 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 12:57:43.949822 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 12:57:43.949927 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 12:57:43.949980 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 12:57:43.950062 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 12:57:43.950097 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 12:57:43.950132 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 12:57:43.950361 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 12:57:43.950390 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 12:57:43.950439 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 12:57:43.950473 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 12:57:43.950504 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 12:57:43.950530 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 12:57:43.950555 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 12:57:43.950647 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 12:57:43.950685 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 12:57:43.950723 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 12:57:44.313120 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 12:57:44.313169 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 12:57:44.313176 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 12:57:44.315102 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 12:57:44.315632 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 12:57:44.316013 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 12:57:44.316030 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 12:57:44.316034 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 12:57:44.316040 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 12:57:44.316066 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 12:57:44.316347 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 12:57:44.316695 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 12:57:44.316712 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 12:57:44.316717 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 12:57:44.316722 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 12:57:44.316749 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 12:57:44.317220 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 12:57:44.317733 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 12:57:44.317759 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 12:57:44.317768 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 12:57:44.317776 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 12:57:44.319405 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 12:57:44.319428 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 12:57:44.319440 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 12:57:44.319444 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 12:57:44.328776 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 12:57:46.892866 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 12:57:46.894020 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 12:57:48.906855 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:57:48.908044 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 12:57:51.337890 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 12:57:51.338416 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 12:57:51.338899 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 12:57:51.338920 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 12:57:51.338925 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 12:57:51.338930 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 12:57:51.339342 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:57:53.741454 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:57:56.145649 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 12:57:58.568991 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 12:57:58.569904 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 12:57:58.570271 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 12:57:58.570288 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 12:57:58.570293 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 12:57:58.570297 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 12:58:03.877294 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 12:58:05.778885 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 12:58:05.779319 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 12:58:05.780094 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 12:59:02.418179 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 12:59:03.668157 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 12:59:03.668319 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 12:59:03.671404 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 12:59:03.671635 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 12:59:04.939054 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 12:59:04.939251 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 12:59:06.248205 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 12:59:06.248375 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 12:59:07.630736 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 12:59:07.630888 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 12:59:09.487336 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 12:59:09.488609 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 12:59:09.769305 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 12:59:09.769489 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 12:59:10.200097 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 12:59:10.200237 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 12:59:10.529976 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 12:59:10.530141 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 12:59:10.808859 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 12:59:10.808998 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 12:59:12.004511 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 12:59:12.004771 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 12:59:27.425272 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 12:59:27.425532 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 12:59:30.814494 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 12:59:30.814661 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 12:59:33.040928 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 12:59:33.041100 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 12:59:50.920694 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 12:59:50.920866 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 13:00:01.907546 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 13:00:01.907689 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 13:00:05.660010 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 13:00:05.661129 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 13:00:05.661186 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 13:00:05.661226 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 13:00:05.661261 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 13:00:05.661295 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 13:00:05.661333 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 13:00:05.661371 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 13:00:05.661410 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 13:00:05.661451 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 13:00:05.661497 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 13:00:05.661562 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 13:00:05.661639 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 13:00:05.661902 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 13:00:05.661974 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 13:00:05.662014 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 13:00:05.662052 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 13:00:05.662098 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 13:00:05.662150 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 13:00:05.662244 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 13:00:05.662290 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 13:00:05.662391 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 13:00:05.678136 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 13:00:05.678332 1 metrics.cc:757] Collecting CPU metrics
I0829 13:00:05.678457 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 13:00:05.679520 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 13:00:05.679701 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 13:00:05.720889 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 13:03:49.684928 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 13:03:49.685023 1 server.cc:280] Timeout 30: Found 2 model versions that have in-flight inferences
I0829 13:03:49.685032 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:49.685038 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:50.685182 1 server.cc:280] Timeout 29: Found 2 model versions that have in-flight inferences
I0829 13:03:50.685231 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:50.685242 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:51.685369 1 server.cc:280] Timeout 28: Found 2 model versions that have in-flight inferences
I0829 13:03:51.685413 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:51.685420 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:52.685555 1 server.cc:280] Timeout 27: Found 2 model versions that have in-flight inferences
I0829 13:03:52.685598 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:52.685603 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:53.685708 1 server.cc:280] Timeout 26: Found 2 model versions that have in-flight inferences
I0829 13:03:53.685740 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:53.685745 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:54.685861 1 server.cc:280] Timeout 25: Found 2 model versions that have in-flight inferences
I0829 13:03:54.685905 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:54.685916 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:55.686042 1 server.cc:280] Timeout 24: Found 2 model versions that have in-flight inferences
I0829 13:03:55.686094 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:55.686102 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:56.686244 1 server.cc:280] Timeout 23: Found 2 model versions that have in-flight inferences
I0829 13:03:56.686299 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:56.686308 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:57.686410 1 server.cc:280] Timeout 22: Found 2 model versions that have in-flight inferences
I0829 13:03:57.686458 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:57.686464 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:58.686593 1 server.cc:280] Timeout 21: Found 2 model versions that have in-flight inferences
I0829 13:03:58.686641 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:58.686647 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:03:59.686782 1 server.cc:280] Timeout 20: Found 2 model versions that have in-flight inferences
I0829 13:03:59.686832 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 1 in-flight inferences
I0829 13:03:59.686841 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 2 in-flight inferences
I0829 13:04:04.058341 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f0df6000000' with size 268435456
I0829 13:04:04.058704 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 13:04:04.063421 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 13:04:04.063468 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 13:04:04.063516 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 13:04:04.063562 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 13:04:04.063698 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 13:04:04.063735 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 13:04:04.063765 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 13:04:04.063793 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 13:04:04.063823 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 13:04:04.063850 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 13:04:04.063875 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 13:04:04.063897 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 13:04:04.064209 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 13:04:04.064236 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 13:04:04.064297 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 13:04:04.064335 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 13:04:04.064381 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 13:04:04.064423 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 13:04:04.064455 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 13:04:04.066509 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 13:04:04.066556 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 13:04:04.066574 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 13:04:04.441681 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 13:04:04.441729 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 13:04:04.441735 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 13:04:04.443821 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 13:04:04.444333 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 13:04:04.444699 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 13:04:04.444715 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 13:04:04.444720 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 13:04:04.444724 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 13:04:04.444770 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 13:04:04.445282 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 13:04:04.445805 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 13:04:04.445826 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 13:04:04.445831 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 13:04:04.445836 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 13:04:04.445859 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 13:04:04.446131 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 13:04:04.446482 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 13:04:04.446499 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 13:04:04.446504 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 13:04:04.446509 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 13:04:04.446546 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 13:04:04.446931 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 13:04:04.447306 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 13:04:04.447323 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 13:04:04.447328 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 13:04:04.447333 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 13:04:04.447367 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 13:04:04.447754 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 13:04:04.448138 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 13:04:04.448154 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 13:04:04.448159 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 13:04:04.448163 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 13:04:04.449512 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 13:04:04.449544 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 13:04:04.449550 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 13:04:04.449565 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 13:04:04.458376 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 13:04:06.956940 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 13:04:06.958386 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 13:04:08.629595 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 13:04:08.630352 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 13:04:11.051385 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 13:04:14.808458 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 13:04:19.884577 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 13:04:23.626296 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 13:04:25.261137 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 13:04:25.262569 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 13:04:25.264597 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 13:04:25.264884 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 13:04:26.996996 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 13:04:26.997483 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 13:04:26.998180 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 13:05:23.085075 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 13:05:24.384642 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 13:05:24.384793 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 13:05:25.818356 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 13:05:25.818562 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 13:05:26.259772 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 13:05:26.259902 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 13:05:27.500576 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 13:05:27.500797 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 13:05:27.823179 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 13:05:27.823320 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 13:05:28.105766 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 13:05:28.105879 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 13:05:29.427031 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 13:05:29.427270 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 13:05:29.721833 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 13:05:29.721979 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 13:05:30.830322 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 13:05:30.830731 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 13:05:33.770216 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 13:05:33.770395 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 13:05:37.570070 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 13:05:37.570387 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 13:05:39.766931 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 13:05:39.767127 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 13:05:55.360849 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 13:05:55.360997 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 13:06:13.971568 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 13:06:13.971788 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 13:06:25.143323 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 13:06:25.144552 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 13:06:25.144624 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 13:06:25.144663 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 13:06:25.144697 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 13:06:25.144727 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 13:06:25.144765 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 13:06:25.144800 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 13:06:25.144841 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 13:06:25.144880 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 13:06:25.144926 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 13:06:25.145093 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 13:06:25.145143 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 13:06:25.145222 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 13:06:25.145264 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 13:06:25.145293 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 13:06:25.145332 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 13:06:25.145385 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 13:06:25.145446 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 13:06:25.145551 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 13:06:25.145603 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 13:06:25.145707 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 13:06:25.161279 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 13:06:25.161476 1 metrics.cc:757] Collecting CPU metrics
I0829 13:06:25.161598 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 13:06:25.162631 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 13:06:25.162805 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 13:06:25.203992 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 13:08:06.548937 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 13:08:06.549270 1 server.cc:280] Timeout 30: Found 1 model versions that have in-flight inferences
I0829 13:08:06.549283 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:07.549406 1 server.cc:280] Timeout 29: Found 1 model versions that have in-flight inferences
I0829 13:08:07.549451 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:08.549589 1 server.cc:280] Timeout 28: Found 1 model versions that have in-flight inferences
I0829 13:08:08.549642 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:09.549762 1 server.cc:280] Timeout 27: Found 1 model versions that have in-flight inferences
I0829 13:08:09.549797 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:10.549940 1 server.cc:280] Timeout 26: Found 1 model versions that have in-flight inferences
I0829 13:08:10.549975 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:11.550085 1 server.cc:280] Timeout 25: Found 1 model versions that have in-flight inferences
I0829 13:08:11.554439 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:12.554576 1 server.cc:280] Timeout 24: Found 1 model versions that have in-flight inferences
I0829 13:08:12.554617 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:13.554737 1 server.cc:280] Timeout 23: Found 1 model versions that have in-flight inferences
I0829 13:08:13.554769 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:14.554905 1 server.cc:280] Timeout 22: Found 1 model versions that have in-flight inferences
I0829 13:08:14.554953 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:15.555090 1 server.cc:280] Timeout 21: Found 1 model versions that have in-flight inferences
I0829 13:08:15.555138 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:16.555304 1 server.cc:280] Timeout 20: Found 1 model versions that have in-flight inferences
I0829 13:08:16.567402 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 13:08:20.944273 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f797c000000' with size 268435456
I0829 13:08:20.944749 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 13:08:20.949603 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 13:08:20.949655 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 13:08:20.949690 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 13:08:20.949722 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 13:08:20.949769 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 13:08:20.949821 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 13:08:20.949853 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 13:08:20.949917 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 13:08:20.949956 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 13:08:20.950080 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 13:08:20.950131 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 13:08:20.950162 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 13:08:20.950516 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 13:08:20.950546 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 13:08:20.950594 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 13:08:20.950630 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 13:08:20.950725 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 13:08:20.950779 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 13:08:20.952341 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 13:08:20.952386 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 13:08:20.952422 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 13:08:20.952437 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 13:08:21.317204 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 13:08:21.317406 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 13:08:21.317413 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 13:08:21.319330 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 13:08:21.319851 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 13:08:21.320221 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 13:08:21.320237 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 13:08:21.320242 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 13:08:21.320246 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 13:08:21.320280 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 13:08:21.320713 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 13:08:21.321134 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 13:08:21.321149 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 13:08:21.321165 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 13:08:21.321171 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 13:08:21.321201 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 13:08:21.321465 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 13:08:21.321799 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 13:08:21.321814 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 13:08:21.321820 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 13:08:21.321825 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 13:08:21.321854 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 13:08:21.322131 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 13:08:21.322522 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 13:08:21.322541 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 13:08:21.322549 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 13:08:21.322556 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 13:08:21.322578 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 13:08:21.322843 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 13:08:21.323194 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 13:08:21.323208 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 13:08:21.323213 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 13:08:21.323217 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 13:08:21.324435 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 13:08:21.324464 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 13:08:21.324474 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 13:08:21.324478 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 13:08:21.333423 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 13:08:23.879436 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 13:08:23.881223 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 13:08:25.676524 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 13:08:25.677954 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 13:08:27.386476 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 13:08:27.387225 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 13:08:29.800756 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 13:08:29.804282 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 13:08:29.804359 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 13:08:32.537820 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 13:08:34.968407 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 13:08:42.759282 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 13:08:44.513770 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 13:08:44.514260 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 13:08:44.514945 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 13:09:43.595472 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 13:09:44.868890 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 13:09:44.870374 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 13:09:46.149121 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 13:09:46.149280 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 13:09:47.562752 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 13:09:47.562908 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 13:09:48.863604 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 13:09:48.863796 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 13:09:49.168783 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 13:09:49.168895 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 13:09:49.504946 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 13:09:49.505145 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 13:09:49.928516 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 13:09:49.928634 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 13:09:50.211417 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 13:09:50.211600 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 13:09:51.446192 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 13:09:51.446534 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 13:09:55.281313 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 13:09:55.281474 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 13:09:58.232324 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 13:09:58.232495 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 13:10:00.430300 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 13:10:00.430486 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 13:10:15.527414 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 13:10:15.527754 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 13:10:32.959391 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 13:10:32.959594 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 13:10:44.288598 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 13:10:44.289780 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 13:10:44.289836 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 13:10:44.289875 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 13:10:44.289913 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 13:10:44.289946 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 13:10:44.289983 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 13:10:44.290018 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 13:10:44.290053 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 13:10:44.290091 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 13:10:44.290147 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 13:10:44.291107 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 13:10:44.291184 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 13:10:44.291398 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 13:10:44.291457 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 13:10:44.291571 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 13:10:44.291637 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 13:10:44.291719 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 13:10:44.291783 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 13:10:44.291874 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 13:10:44.291918 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 13:10:44.292005 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 13:10:44.307847 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 13:10:44.308045 1 metrics.cc:757] Collecting CPU metrics
I0829 13:10:44.308160 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 13:10:44.309121 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 13:10:44.309295 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 13:10:44.350365 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 14:00:06.059785 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 14:00:06.059987 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0829 14:00:06.060235 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 14:00:06.060281 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 14:00:06.060395 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0829 14:00:06.060348 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 14:00:06.061034 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 14:00:06.061277 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 14:00:06.061288 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 14:00:06.061732 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 14:00:06.061774 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 14:00:06.062092 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 14:00:06.062561 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0829 14:00:06.062787 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0829 14:00:06.062787 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 14:00:06.063018 1 server.cc:295] All models are stopped, unloading models
I0829 14:00:06.063059 1 server.cc:302] Timeout 30: Found 22 live models and 0 in-flight non-inference requests
I0829 14:00:06.063069 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0829 14:00:06.064055 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0829 14:00:06.068075 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 14:00:06.068236 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0829 14:00:06.077937 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0829 14:00:06.078841 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0829 14:00:06.081927 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 14:00:06.082135 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0829 14:00:06.093382 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 14:00:06.093526 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0829 14:00:06.103299 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 14:00:06.103451 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 14:00:06.103549 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0829 14:00:06.103629 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0829 14:00:07.064410 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0829 14:00:07.161363 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0829 14:00:07.218682 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0829 14:00:07.219250 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0829 14:00:07.270231 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0829 14:00:07.291253 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0829 14:00:07.306635 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0829 14:00:07.322692 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0829 14:00:07.323164 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0829 14:00:07.325838 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0829 14:00:07.333794 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0829 14:00:07.370505 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0829 14:00:07.423919 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0829 14:00:07.559082 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0829 14:00:07.605153 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0829 14:00:08.064564 1 server.cc:302] Timeout 28: Found 0 live models and 0 in-flight non-inference requests
I0829 14:00:13.951560 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f90be000000' with size 268435456
I0829 14:00:13.951903 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 14:00:13.956661 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 14:00:13.956717 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 14:00:13.956746 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 14:00:13.956779 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 14:00:13.956822 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 14:00:13.956866 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 14:00:13.956899 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 14:00:13.956927 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 14:00:13.956984 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 14:00:13.957019 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 14:00:13.957045 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 14:00:13.957068 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 14:00:13.957312 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 14:00:13.957339 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 14:00:13.957377 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 14:00:13.957496 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 14:00:13.957533 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 14:00:13.957612 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 14:00:13.957657 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 14:00:13.957693 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 14:00:13.957732 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 14:00:13.957777 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 14:00:14.405132 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 14:00:14.405187 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 14:00:14.405195 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 14:00:14.408116 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 14:00:14.408653 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 14:00:14.409056 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 14:00:14.409075 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 14:00:14.409080 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 14:00:14.409084 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 14:00:14.409135 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 14:00:14.409565 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 14:00:14.410097 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 14:00:14.410119 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 14:00:14.410127 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 14:00:14.410134 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 14:00:14.410173 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 14:00:14.410593 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 14:00:14.410961 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 14:00:14.410978 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 14:00:14.410983 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 14:00:14.410988 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 14:00:14.411030 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 14:00:14.411711 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 14:00:14.412074 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 14:00:14.412091 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 14:00:14.412096 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 14:00:14.412101 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 14:00:14.412133 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 14:00:14.412411 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 14:00:14.412754 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 14:00:14.412771 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 14:00:14.412776 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 14:00:14.412780 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 14:00:14.414140 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 14:00:14.414222 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 14:00:14.414230 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 14:00:14.414234 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 14:00:14.423238 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 14:00:17.109356 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 14:00:17.110128 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 14:00:19.831357 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 14:00:21.842330 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 14:00:21.843978 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 14:00:25.593207 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 14:00:29.341434 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 14:00:33.086849 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 14:00:33.090394 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 14:00:33.090643 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 14:00:35.023738 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 14:00:35.025119 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 14:00:37.086036 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 14:00:37.086527 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 14:00:37.087323 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 14:01:35.768730 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 14:01:37.156847 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 14:01:37.157011 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 14:01:38.435295 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 14:01:38.435446 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 14:01:38.772656 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 14:01:38.772771 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 14:01:40.090071 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 14:01:40.090239 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 14:01:40.510667 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 14:01:40.510814 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 14:01:41.917250 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 14:01:41.917421 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 14:01:42.206986 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 14:01:42.207276 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 14:01:43.473539 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 14:01:43.473807 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 14:01:43.792735 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 14:01:43.792875 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 14:01:47.818845 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 14:01:47.819004 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 14:01:51.232362 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 14:01:51.232512 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 14:01:53.484207 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 14:01:53.484354 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 14:02:08.796682 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 14:02:08.796829 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 14:02:26.302897 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 14:02:26.303070 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 14:02:36.785857 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 14:02:36.786988 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 14:02:36.787049 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 14:02:36.787085 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 14:02:36.787130 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 14:02:36.787164 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 14:02:36.787203 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 14:02:36.787259 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 14:02:36.787309 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 14:02:36.787352 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 14:02:36.787399 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 14:02:36.787478 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 14:02:36.787555 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 14:02:36.788457 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 14:02:36.788516 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 14:02:36.788784 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 14:02:36.788900 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 14:02:36.788959 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 14:02:36.789002 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 14:02:36.789108 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 14:02:36.789147 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 14:02:36.789237 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 14:02:36.807726 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 14:02:36.807926 1 metrics.cc:757] Collecting CPU metrics
I0829 14:02:36.808045 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 14:02:36.809245 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 14:02:36.809478 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 14:02:36.850818 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 14:04:39.861647 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 14:04:39.861744 1 server.cc:280] Timeout 30: Found 2 model versions that have in-flight inferences
I0829 14:04:39.861751 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:39.861754 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:40.861874 1 server.cc:280] Timeout 29: Found 2 model versions that have in-flight inferences
I0829 14:04:40.861907 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:40.861912 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:41.862033 1 server.cc:280] Timeout 28: Found 2 model versions that have in-flight inferences
I0829 14:04:41.862062 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:41.862067 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:42.862196 1 server.cc:280] Timeout 27: Found 2 model versions that have in-flight inferences
I0829 14:04:42.862322 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:42.862406 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:43.866492 1 server.cc:280] Timeout 26: Found 2 model versions that have in-flight inferences
I0829 14:04:43.866524 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:43.866530 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:44.866652 1 server.cc:280] Timeout 25: Found 2 model versions that have in-flight inferences
I0829 14:04:44.866705 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:44.874587 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:45.874725 1 server.cc:280] Timeout 24: Found 2 model versions that have in-flight inferences
I0829 14:04:45.874763 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:45.874769 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:46.874907 1 server.cc:280] Timeout 23: Found 2 model versions that have in-flight inferences
I0829 14:04:46.874943 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:46.874949 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:47.875065 1 server.cc:280] Timeout 22: Found 2 model versions that have in-flight inferences
I0829 14:04:47.875114 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:47.875120 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:48.875240 1 server.cc:280] Timeout 21: Found 2 model versions that have in-flight inferences
I0829 14:04:48.875278 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:48.875284 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:49.875399 1 server.cc:280] Timeout 20: Found 2 model versions that have in-flight inferences
I0829 14:04:49.875426 1 server.cc:284] Model 'asr_pyctc_decoder_OR' (version 1) has 7 in-flight inferences
I0829 14:04:49.875440 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 8 in-flight inferences
I0829 14:04:54.232164 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fa366000000' with size 268435456
I0829 14:04:54.232502 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 14:04:54.237177 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 14:04:54.237355 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 14:04:54.237453 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 14:04:54.237586 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 14:04:54.237700 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 14:04:54.237818 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 14:04:54.237948 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 14:04:54.238047 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 14:04:54.238146 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 14:04:54.238247 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 14:04:54.238342 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 14:04:54.238445 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 14:04:54.238644 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 14:04:54.238734 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 14:04:54.238838 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 14:04:54.238944 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 14:04:54.239044 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 14:04:54.239151 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 14:04:54.239254 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 14:04:54.239350 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 14:04:54.239451 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 14:04:54.239581 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 14:04:54.581847 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 14:04:54.581900 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 14:04:54.581906 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 14:04:54.583823 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 14:04:54.584395 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 14:04:54.584903 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 14:04:54.584925 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 14:04:54.584932 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 14:04:54.584938 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 14:04:54.584973 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 14:04:54.585324 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 14:04:54.585688 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 14:04:54.585705 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 14:04:54.585722 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 14:04:54.585727 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 14:04:54.585761 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 14:04:54.586112 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 14:04:54.586484 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 14:04:54.586507 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 14:04:54.586512 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 14:04:54.586516 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 14:04:54.586538 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 14:04:54.586806 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 14:04:54.587143 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 14:04:54.587160 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 14:04:54.587166 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 14:04:54.587171 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 14:04:54.587204 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 14:04:54.587672 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 14:04:54.588208 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 14:04:54.588232 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 14:04:54.588239 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 14:04:54.588246 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 14:04:54.589545 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 14:04:54.589565 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 14:04:54.589575 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 14:04:54.589580 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 14:04:54.598104 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 14:04:57.118987 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 14:04:57.120446 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 14:04:58.801864 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 14:04:58.803093 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 14:05:00.498346 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 14:05:00.499112 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 14:05:02.901075 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 14:05:05.291876 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 14:05:07.686540 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 14:05:15.394067 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 14:05:17.054400 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 14:05:17.055583 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 14:05:17.057617 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 14:05:17.057803 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 14:05:17.058323 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 14:06:12.788945 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 14:06:14.050782 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 14:06:14.051227 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 14:06:15.429165 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 14:06:15.429383 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 14:06:16.734015 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 14:06:16.734209 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 14:06:17.981122 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 14:06:17.981281 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 14:06:18.277509 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 14:06:18.277653 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 14:06:18.607798 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 14:06:18.607967 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 14:06:19.042261 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 14:06:19.042491 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 14:06:19.321641 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 14:06:19.321774 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 14:06:20.418424 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 14:06:20.418757 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 14:06:24.650503 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 14:06:24.650678 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 14:06:27.128416 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 14:06:27.128549 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 14:06:45.278959 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 14:06:45.279160 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 14:07:00.239279 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 14:07:00.239403 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 14:07:02.382237 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 14:07:02.382376 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 14:07:13.373030 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 14:07:13.374170 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 14:07:13.374255 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 14:07:13.374299 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 14:07:13.374336 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 14:07:13.374371 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 14:07:13.374420 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 14:07:13.374474 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 14:07:13.374520 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 14:07:13.374562 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 14:07:13.374612 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 14:07:13.374659 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 14:07:13.374731 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 14:07:13.374934 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 14:07:13.375024 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 14:07:13.375069 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 14:07:13.375117 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 14:07:13.375156 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 14:07:13.375197 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 14:07:13.375296 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 14:07:13.375344 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 14:07:13.375444 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 14:07:13.391438 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 14:07:13.391645 1 metrics.cc:757] Collecting CPU metrics
I0829 14:07:13.391769 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 14:07:13.392885 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 14:07:13.393061 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 14:07:13.434315 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 16:11:01.421545 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f3736000000' with size 268435456
I0829 16:11:01.421884 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 16:11:01.427157 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 16:11:01.427198 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 16:11:01.427229 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 16:11:01.427292 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 16:11:01.427327 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 16:11:01.427441 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 16:11:01.427472 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 16:11:01.427642 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 16:11:01.427676 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 16:11:01.427733 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 16:11:01.427761 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 16:11:01.427787 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 16:11:01.428069 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 16:11:01.428087 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 16:11:01.428132 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 16:11:01.428166 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 16:11:01.428235 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 16:11:01.428283 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 16:11:01.428356 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 16:11:01.428388 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 16:11:01.428418 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 16:11:01.428520 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 16:11:01.855649 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 16:11:01.855684 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 16:11:01.855690 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 16:11:01.858299 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 16:11:01.858825 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 16:11:01.859179 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 16:11:01.859188 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 16:11:01.859192 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 16:11:01.859195 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 16:11:01.859221 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 16:11:01.859527 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 16:11:01.859909 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 16:11:01.859921 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 16:11:01.859925 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 16:11:01.859940 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 16:11:01.859980 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 16:11:01.860356 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 16:11:01.860702 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 16:11:01.860711 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 16:11:01.860714 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 16:11:01.860718 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 16:11:01.860744 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 16:11:01.861004 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 16:11:01.861327 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 16:11:01.861345 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 16:11:01.861349 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 16:11:01.861353 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 16:11:01.861379 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 16:11:05.871024 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 16:11:05.871067 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 16:11:05.871075 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 16:11:05.871079 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 16:11:05.871097 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 16:11:05.880146 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 16:11:05.884336 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 16:11:05.884554 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 16:11:08.234812 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 16:11:08.235280 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 16:11:08.235630 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 16:11:08.235639 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 16:11:08.235643 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 16:11:08.235646 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 16:11:08.236065 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 16:11:08.236116 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:11:10.985508 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:11:17.424145 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:11:19.852054 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:11:26.929022 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 16:11:29.206536 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 16:11:29.206993 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 16:11:29.207740 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 16:12:23.525689 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 16:12:25.566617 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 16:12:25.568036 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 16:12:26.894755 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 16:12:26.894956 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 16:12:28.301076 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 16:12:28.301251 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 16:12:28.625835 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 16:12:28.625969 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 16:12:28.972054 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 16:12:28.972238 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 16:12:29.446344 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 16:12:29.446459 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 16:12:30.755601 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 16:12:30.755819 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 16:12:32.301935 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 16:12:32.302128 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 16:12:32.635647 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 16:12:32.635759 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 16:12:37.135258 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 16:12:37.135427 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 16:12:41.081056 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 16:12:41.081195 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 16:12:42.500621 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 16:12:42.500984 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 16:12:44.723162 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 16:12:44.723339 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 16:13:03.557484 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 16:13:03.557575 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 16:13:14.794325 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 16:13:14.794500 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 16:13:30.203713 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 16:13:30.205011 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 16:13:30.205072 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 16:13:30.205108 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 16:13:30.205140 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 16:13:30.205170 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 16:13:30.205204 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 16:13:30.205244 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 16:13:30.205278 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 16:13:30.205314 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 16:13:30.205366 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 16:13:30.205438 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 16:13:30.205473 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 16:13:30.205908 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 16:13:30.205970 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 16:13:30.206038 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 16:13:30.206073 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 16:13:30.206127 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 16:13:30.206173 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 16:13:30.206302 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 16:13:30.206339 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 16:13:30.206423 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 16:13:30.223433 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 16:13:30.223629 1 metrics.cc:757] Collecting CPU metrics
I0829 16:13:30.223737 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 16:13:30.224853 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 16:13:30.225019 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 16:13:30.266241 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 16:41:40.814409 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 16:41:40.814512 1 server.cc:280] Timeout 30: Found 0 model versions that have in-flight inferences
I0829 16:41:40.815017 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 16:41:40.815036 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 16:41:40.815090 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0829 16:41:40.815133 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 16:41:40.815645 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:41:40.815729 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:41:40.816080 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:41:40.816113 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:41:40.816441 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 16:41:40.816619 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:41:40.817837 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:41:40.818032 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0829 16:41:40.818055 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0829 16:41:40.818079 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0829 16:41:40.818093 1 server.cc:295] All models are stopped, unloading models
I0829 16:41:40.818215 1 server.cc:302] Timeout 30: Found 21 live models and 0 in-flight non-inference requests
I0829 16:41:40.818748 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:41:40.818821 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0829 16:41:40.818903 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0829 16:41:40.826633 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:41:40.827321 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0829 16:41:40.847295 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:41:40.847394 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:41:40.847449 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0829 16:41:40.847491 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:41:40.847517 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:41:40.857040 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0829 16:41:40.857078 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0829 16:41:40.857132 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0829 16:41:41.822044 1 server.cc:302] Timeout 29: Found 14 live models and 0 in-flight non-inference requests
I0829 16:41:41.893220 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0829 16:41:41.932349 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0829 16:41:41.965111 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0829 16:41:42.081191 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0829 16:41:42.122651 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0829 16:41:42.132717 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0829 16:41:42.142744 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0829 16:41:42.161311 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0829 16:41:42.173464 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0829 16:41:42.176040 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0829 16:41:42.196442 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0829 16:41:42.204491 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0829 16:41:42.306882 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0829 16:41:42.317360 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0829 16:41:42.822252 1 server.cc:302] Timeout 28: Found 0 live models and 0 in-flight non-inference requests
I0829 16:42:06.173715 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7faf4c000000' with size 268435456
I0829 16:42:06.174210 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 16:42:06.178754 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 16:42:06.178919 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 16:42:06.179035 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 16:42:06.179159 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 16:42:06.179268 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 16:42:06.179368 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 16:42:06.179476 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 16:42:06.179572 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 16:42:06.179687 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 16:42:06.179799 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 16:42:06.179895 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 16:42:06.179986 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 16:42:06.180188 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 16:42:06.180273 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 16:42:06.180372 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 16:42:06.180487 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 16:42:06.180586 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 16:42:06.180686 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 16:42:06.180779 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 16:42:06.180872 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 16:42:06.180969 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 16:42:06.181056 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 16:42:06.668598 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 16:42:06.668644 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 16:42:06.668652 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 16:42:06.671777 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 16:42:06.672346 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 16:42:06.672737 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 16:42:06.672766 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 16:42:06.672775 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 16:42:06.672782 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 16:42:06.672833 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 16:42:09.879403 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 16:42:09.879823 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 16:42:09.880188 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 16:42:09.880206 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 16:42:09.880211 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 16:42:09.880215 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 16:42:09.880256 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 16:42:09.880709 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 16:42:09.881090 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 16:42:09.881108 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 16:42:09.881113 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 16:42:09.881117 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 16:42:09.881195 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
W0829 16:42:09.881761 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 16:42:09.881769 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 16:42:09.882127 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 16:42:09.882145 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 16:42:09.882150 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 16:42:09.882155 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 16:42:09.882478 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:42:12.596649 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 16:42:12.597043 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 16:42:12.597397 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 16:42:12.597413 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 16:42:12.597419 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 16:42:12.597423 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 16:42:12.597460 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 16:42:14.521383 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:42:14.522977 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 16:42:16.944537 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 16:42:16.944596 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 16:42:16.944602 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 16:42:16.944606 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 16:42:16.953480 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 16:42:16.959545 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 16:42:16.959783 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
I0829 16:42:18.980855 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0 (CPU device 0)
I0829 16:42:18.981975 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 16:42:20.291074 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 16:42:20.291265 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:42:22.743854 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0 (CPU device 0)
I0829 16:42:24.195806 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 16:42:24.196005 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 16:42:26.086232 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 16:42:26.086778 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 16:42:26.087268 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 16:42:31.537883 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:43:31.987967 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0 (CPU device 0)
I0829 16:43:33.355238 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 16:43:33.355430 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 16:43:34.667965 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 16:43:34.668306 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 16:43:35.152735 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 16:43:35.152970 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 16:43:35.488914 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 16:43:35.489062 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 16:43:35.826639 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 16:43:35.826785 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 16:43:36.199338 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0 (CPU device 0)
I0829 16:43:36.199485 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 16:43:37.513060 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 16:43:37.513289 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 16:43:40.607736 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 16:43:40.607836 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 16:43:44.464938 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 16:43:44.465084 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 16:43:46.703366 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 16:43:46.703550 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 16:44:02.358438 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 16:44:02.358552 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 16:44:13.366763 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 16:44:13.366922 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 16:44:31.613421 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 16:44:31.614601 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 16:44:31.614678 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 16:44:31.614719 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 16:44:31.614756 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 16:44:31.614801 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 16:44:31.614840 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 16:44:31.614879 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 16:44:31.614913 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 16:44:31.614953 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 16:44:31.614983 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 16:44:31.615078 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 16:44:31.615466 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 16:44:31.615531 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 16:44:31.615577 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 16:44:31.615606 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 16:44:31.615624 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 16:44:31.615672 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 16:44:31.615708 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 16:44:31.615809 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 16:44:31.615857 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 16:44:31.615949 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 16:44:31.632313 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 16:44:31.632516 1 metrics.cc:757] Collecting CPU metrics
I0829 16:44:31.632627 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 16:44:31.633688 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 16:44:31.633861 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 16:44:31.674952 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
I0829 16:48:38.329550 1 server.cc:264] Waiting for in-flight requests to complete.
I0829 16:48:38.329906 1 server.cc:280] Timeout 30: Found 1 model versions that have in-flight inferences
I0829 16:48:38.329996 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 4 in-flight inferences
I0829 16:48:39.330214 1 server.cc:280] Timeout 29: Found 1 model versions that have in-flight inferences
I0829 16:48:39.330269 1 server.cc:284] Model 'pipeline_pyctc_ensemble_OR' (version 1) has 1 in-flight inferences
I0829 16:48:40.330405 1 server.cc:280] Timeout 28: Found 0 model versions that have in-flight inferences
I0829 16:48:40.330723 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 16:48:40.330817 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 16:48:40.330879 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 16:48:40.330898 1 model_lifecycle.cc:579] successfully unloaded 'intent_ensemble' version 1
I0829 16:48:40.331759 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:48:40.331807 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:48:40.331859 1 onnxruntime.cc:2640] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:48:40.332044 1 model_lifecycle.cc:579] successfully unloaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 16:48:40.332316 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:48:40.332545 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:48:40.333154 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_HI' version 1
I0829 16:48:40.333291 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_OR' version 1
I0829 16:48:40.333293 1 libtorch.cc:2112] TRITONBACKEND_ModelInstanceFinalize: delete instance state
I0829 16:48:40.333423 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_EN' version 1
I0829 16:48:40.333567 1 server.cc:295] All models are stopped, unloading models
I0829 16:48:40.333606 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_ensemble_TA' version 1
I0829 16:48:40.333854 1 server.cc:302] Timeout 28: Found 20 live models and 0 in-flight non-inference requests
I0829 16:48:40.336342 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:48:40.336543 1 model_lifecycle.cc:579] successfully unloaded 'asr_preprocessor' version 1
I0829 16:48:40.348635 1 onnxruntime.cc:2586] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:48:40.348780 1 model_lifecycle.cc:579] successfully unloaded 'intent_model_onnx' version 1
I0829 16:48:40.349585 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:48:40.359318 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_EN' version 1
I0829 16:48:40.365618 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:48:40.365772 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_TA' version 1
I0829 16:48:40.366030 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:48:40.368202 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_HI' version 1
I0829 16:48:40.375316 1 libtorch.cc:2057] TRITONBACKEND_ModelFinalize: delete model state
I0829 16:48:40.375437 1 model_lifecycle.cc:579] successfully unloaded 'asr_am_OR' version 1
I0829 16:48:41.343314 1 server.cc:302] Timeout 27: Found 14 live models and 0 in-flight non-inference requests
I0829 16:48:41.425619 1 model_lifecycle.cc:579] successfully unloaded 'entity_TA' version 1
I0829 16:48:41.458650 1 model_lifecycle.cc:579] successfully unloaded 'itn_EN' version 1
I0829 16:48:41.458913 1 model_lifecycle.cc:579] successfully unloaded 'entity_EN' version 1
I0829 16:48:41.497809 1 model_lifecycle.cc:579] successfully unloaded 'entity_HI' version 1
I0829 16:48:41.542962 1 model_lifecycle.cc:579] successfully unloaded 'entity_OR' version 1
I0829 16:48:41.630160 1 model_lifecycle.cc:579] successfully unloaded 'intent_postprocessor' version 1
I0829 16:48:41.646050 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_EN' version 1
I0829 16:48:41.656817 1 model_lifecycle.cc:579] successfully unloaded 'itn_OR' version 1
I0829 16:48:41.682205 1 model_lifecycle.cc:579] successfully unloaded 'intent_preprocessor' version 1
I0829 16:48:41.682598 1 model_lifecycle.cc:579] successfully unloaded 'itn_HI' version 1
I0829 16:48:41.738693 1 model_lifecycle.cc:579] successfully unloaded 'itn_TA' version 1
I0829 16:48:41.807481 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_OR' version 1
I0829 16:48:41.818667 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_HI' version 1
I0829 16:48:41.828671 1 model_lifecycle.cc:579] successfully unloaded 'asr_pyctc_decoder_TA' version 1
I0829 16:48:42.343593 1 server.cc:302] Timeout 26: Found 0 live models and 0 in-flight non-inference requests
I0829 16:49:28.646549 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fdb9e000000' with size 268435456
I0829 16:49:28.646891 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864
I0829 16:49:28.651436 1 model_lifecycle.cc:459] loading: asr_am_EN:1
I0829 16:49:28.651485 1 model_lifecycle.cc:459] loading: asr_am_HI:1
I0829 16:49:28.651512 1 model_lifecycle.cc:459] loading: asr_am_OR:1
I0829 16:49:28.651539 1 model_lifecycle.cc:459] loading: asr_am_TA:1
I0829 16:49:28.651567 1 model_lifecycle.cc:459] loading: asr_preprocessor:1
I0829 16:49:28.651608 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_EN:1
I0829 16:49:28.651635 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_HI:1
I0829 16:49:28.651659 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_OR:1
I0829 16:49:28.651690 1 model_lifecycle.cc:459] loading: asr_pyctc_decoder_TA:1
I0829 16:49:28.651739 1 model_lifecycle.cc:459] loading: entity_EN:1
I0829 16:49:28.651773 1 model_lifecycle.cc:459] loading: entity_HI:1
I0829 16:49:28.651798 1 model_lifecycle.cc:459] loading: entity_OR:1
W0829 16:49:28.651901 1 model_lifecycle.cc:107] ignore version directory 'entity_EN' which fails to convert to integral number
I0829 16:49:28.651922 1 model_lifecycle.cc:459] loading: entity_TA:1
I0829 16:49:28.651955 1 model_lifecycle.cc:459] loading: intent_model_onnx:1
I0829 16:49:28.651985 1 model_lifecycle.cc:459] loading: intent_postprocessor:1
I0829 16:49:28.652013 1 model_lifecycle.cc:459] loading: intent_preprocessor:1
I0829 16:49:28.652038 1 model_lifecycle.cc:459] loading: itn_EN:1
I0829 16:49:28.652064 1 model_lifecycle.cc:459] loading: itn_HI:1
I0829 16:49:28.652087 1 model_lifecycle.cc:459] loading: itn_OR:1
W0829 16:49:28.652116 1 model_lifecycle.cc:107] ignore version directory 'itn_EN' which fails to convert to integral number
I0829 16:49:28.652128 1 model_lifecycle.cc:459] loading: itn_TA:1
I0829 16:49:29.032751 1 libtorch.cc:1985] TRITONBACKEND_Initialize: pytorch
I0829 16:49:29.032805 1 libtorch.cc:1995] Triton TRITONBACKEND API version: 1.10
I0829 16:49:29.032811 1 libtorch.cc:2001] 'pytorch' TRITONBACKEND API version: 1.10
I0829 16:49:29.032996 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_HI (version 1)
W0829 16:49:29.033484 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_HI': not supported for pytorch backend
I0829 16:49:29.033866 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_HI'
I0829 16:49:29.033883 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_HI'
I0829 16:49:29.033889 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_HI'
I0829 16:49:29.033893 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_HI'
I0829 16:49:29.033931 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_HI_0 (GPU device 0)
I0829 16:49:31.692422 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_OR (version 1)
W0829 16:49:31.692852 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_OR': not supported for pytorch backend
I0829 16:49:31.694210 1 model_lifecycle.cc:694] successfully loaded 'asr_am_HI' version 1
I0829 16:49:31.703392 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_OR'
I0829 16:49:31.703415 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_OR'
I0829 16:49:31.703420 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_OR'
I0829 16:49:31.703424 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_OR'
I0829 16:49:31.703464 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_OR_0 (GPU device 0)
I0829 16:49:33.644534 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_preprocessor (version 1)
W0829 16:49:33.644961 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_preprocessor': not supported for pytorch backend
I0829 16:49:33.645342 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_preprocessor'
I0829 16:49:33.645361 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_preprocessor'
I0829 16:49:33.645366 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_preprocessor'
I0829 16:49:33.645370 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_preprocessor'
I0829 16:49:33.645411 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_preprocessor_0 (GPU device 0)
I0829 16:49:33.648467 1 model_lifecycle.cc:694] successfully loaded 'asr_am_OR' version 1
I0829 16:49:33.648549 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_EN (version 1)
I0829 16:49:33.648744 1 model_lifecycle.cc:694] successfully loaded 'asr_preprocessor' version 1
W0829 16:49:33.649005 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_EN': not supported for pytorch backend
I0829 16:49:33.649463 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_EN'
I0829 16:49:33.649480 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_EN'
I0829 16:49:33.649485 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_EN'
I0829 16:49:33.649489 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_EN'
I0829 16:49:33.649526 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_EN_0 (GPU device 0)
I0829 16:49:35.592905 1 model_lifecycle.cc:694] successfully loaded 'asr_am_EN' version 1
I0829 16:49:35.594138 1 libtorch.cc:2034] TRITONBACKEND_ModelInitialize: asr_am_TA (version 1)
W0829 16:49:35.594661 1 libtorch.cc:284] skipping model configuration auto-complete for 'asr_am_TA': not supported for pytorch backend
I0829 16:49:35.595121 1 libtorch.cc:313] Optimized execution is enabled for model instance 'asr_am_TA'
I0829 16:49:35.595203 1 libtorch.cc:332] Cache Cleaning is disabled for model instance 'asr_am_TA'
I0829 16:49:35.595264 1 libtorch.cc:349] Inference Mode is disabled for model instance 'asr_am_TA'
I0829 16:49:35.595334 1 libtorch.cc:444] NvFuser is not specified for model instance 'asr_am_TA'
I0829 16:49:35.596636 1 onnxruntime.cc:2459] TRITONBACKEND_Initialize: onnxruntime
I0829 16:49:35.596735 1 onnxruntime.cc:2469] Triton TRITONBACKEND API version: 1.10
I0829 16:49:35.596755 1 onnxruntime.cc:2475] 'onnxruntime' TRITONBACKEND API version: 1.10
I0829 16:49:35.596760 1 onnxruntime.cc:2505] backend configuration:
{"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}}
I0829 16:49:35.605640 1 libtorch.cc:2078] TRITONBACKEND_ModelInstanceInitialize: asr_am_TA_0 (GPU device 0)
I0829 16:49:37.517367 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:49:37.518257 1 model_lifecycle.cc:694] successfully loaded 'asr_am_TA' version 1
I0829 16:49:39.985957 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:49:42.436857 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:49:44.907718 1 python_be.cc:1537] Input tensors can be both in CPU and GPU. FORCE_CPU_ONLY_INPUT_TENSORS is off.
I0829 16:50:52.611528 1 onnxruntime.cc:2563] TRITONBACKEND_ModelInitialize: intent_model_onnx (version 1)
I0829 16:50:52.611979 1 onnxruntime.cc:666] skipping model configuration auto-complete for 'intent_model_onnx': inputs and outputs already specified
I0829 16:50:52.612416 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_0 (CPU device 0)
I0829 16:50:53.922602 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_0 (CPU device 0)
I0829 16:50:55.287254 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_0 (CPU device 0)
I0829 16:50:56.721038 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_0 (CPU device 0)
I0829 16:50:58.007801 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_EN_0 (CPU device 0)
I0829 16:50:58.314516 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_HI_0 (CPU device 0)
I0829 16:50:58.314682 1 model_lifecycle.cc:694] successfully loaded 'entity_EN' version 1
I0829 16:50:58.653210 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_OR_0 (CPU device 0)
I0829 16:50:58.653334 1 model_lifecycle.cc:694] successfully loaded 'entity_HI' version 1
I0829 16:50:59.115256 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: entity_TA_0 (CPU device 0)
I0829 16:50:59.115428 1 model_lifecycle.cc:694] successfully loaded 'entity_OR' version 1
I0829 16:50:59.431582 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_postprocessor_0 (CPU device 0)
I0829 16:50:59.431749 1 model_lifecycle.cc:694] successfully loaded 'entity_TA' version 1
I0829 16:51:02.419046 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: intent_preprocessor_0 (CPU device 0)
I0829 16:51:02.419205 1 model_lifecycle.cc:694] successfully loaded 'intent_postprocessor' version 1
I0829 16:51:05.815960 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_EN_0 (CPU device 0)
I0829 16:51:05.816137 1 model_lifecycle.cc:694] successfully loaded 'intent_preprocessor' version 1
I0829 16:51:08.089621 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_HI_0 (CPU device 0)
I0829 16:51:08.089749 1 model_lifecycle.cc:694] successfully loaded 'itn_EN' version 1
I0829 16:51:23.940534 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_OR_0 (CPU device 0)
I0829 16:51:23.940721 1 model_lifecycle.cc:694] successfully loaded 'itn_HI' version 1
I0829 16:51:42.705653 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: itn_TA_0 (CPU device 0)
I0829 16:51:42.705811 1 model_lifecycle.cc:694] successfully loaded 'itn_OR' version 1
I0829 16:51:54.152558 1 onnxruntime.cc:2606] TRITONBACKEND_ModelInstanceInitialize: intent_model_onnx_0 (GPU device 0)
I0829 16:51:54.152699 1 model_lifecycle.cc:694] successfully loaded 'itn_TA' version 1
I0829 16:51:55.286970 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_1 (CPU device 0)
I0829 16:51:55.287260 1 model_lifecycle.cc:694] successfully loaded 'intent_model_onnx' version 1
I0829 16:51:56.622375 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_1 (CPU device 0)
I0829 16:51:58.000547 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_1 (CPU device 0)
I0829 16:51:59.444660 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_1 (CPU device 0)
I0829 16:52:00.762948 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_2 (CPU device 0)
I0829 16:52:02.098559 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_2 (CPU device 0)
I0829 16:52:03.482692 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_2 (CPU device 0)
I0829 16:52:04.934596 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_2 (CPU device 0)
I0829 16:52:06.257037 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_3 (CPU device 0)
I0829 16:52:07.580895 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_3 (CPU device 0)
I0829 16:52:08.992789 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_3 (CPU device 0)
I0829 16:52:10.460549 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_3 (CPU device 0)
I0829 16:52:11.779038 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_4 (CPU device 0)
I0829 16:52:13.088873 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_4 (CPU device 0)
I0829 16:52:14.437357 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_4 (CPU device 0)
I0829 16:52:15.894220 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_4 (CPU device 0)
I0829 16:52:17.200239 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_5 (CPU device 0)
I0829 16:52:18.556785 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_5 (CPU device 0)
I0829 16:52:19.944646 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_5 (CPU device 0)
I0829 16:52:21.441170 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_5 (CPU device 0)
I0829 16:52:22.769928 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_6 (CPU device 0)
I0829 16:52:24.100977 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_6 (CPU device 0)
I0829 16:52:25.504497 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_6 (CPU device 0)
I0829 16:52:27.010147 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_6 (CPU device 0)
I0829 16:52:28.377022 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_EN_0_7 (CPU device 0)
I0829 16:52:29.746120 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_HI_0_7 (CPU device 0)
I0829 16:52:29.746493 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_EN' version 1
I0829 16:52:31.111952 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_OR_0_7 (CPU device 0)
I0829 16:52:31.112189 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_HI' version 1
I0829 16:52:32.583752 1 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: asr_pyctc_decoder_TA_0_7 (CPU device 0)
I0829 16:52:32.584010 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_OR' version 1
I0829 16:52:33.914523 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_decoder_TA' version 1
I0829 16:52:33.915652 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_EN:1
I0829 16:52:33.915710 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_HI:1
I0829 16:52:33.915758 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_OR:1
I0829 16:52:33.915789 1 model_lifecycle.cc:459] loading: asr_pyctc_ensemble_TA:1
I0829 16:52:33.915822 1 model_lifecycle.cc:459] loading: intent_ensemble:1
I0829 16:52:33.915859 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_EN:1
I0829 16:52:33.915893 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_HI:1
I0829 16:52:33.915924 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_OR:1
I0829 16:52:33.915957 1 model_lifecycle.cc:459] loading: pipeline_pyctc_ensemble_TA:1
I0829 16:52:33.916023 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_HI' version 1
I0829 16:52:33.916113 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_OR' version 1
I0829 16:52:33.916542 1 model_lifecycle.cc:694] successfully loaded 'intent_ensemble' version 1
I0829 16:52:33.916574 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_EN' version 1
I0829 16:52:33.916626 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_HI' version 1
I0829 16:52:33.916682 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_TA' version 1
I0829 16:52:33.916697 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_EN' version 1
I0829 16:52:33.916804 1 model_lifecycle.cc:694] successfully loaded 'pipeline_pyctc_ensemble_OR' version 1
I0829 16:52:33.916926 1 model_lifecycle.cc:694] successfully loaded 'asr_pyctc_ensemble_TA' version 1
I0829 16:52:33.917080 1 server.cc:563] 
+------------------+------+
| Repository Agent | Path |
+------------------+------+
+------------------+------+

I0829 16:52:33.917124 1 server.cc:590] 
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Backend     | Path                                                            | Config                                                                                                                                                        |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| python      | /opt/tritonserver/backends/python/libtriton_python.so           | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {"cmdline":{"auto-complete-config":"true","min-compute-capability":"6.000000","backend-directory":"/opt/tritonserver/backends","default-max-batch-size":"4"}} |
+-------------+-----------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 16:52:33.917223 1 server.cc:633] 
+----------------------------+---------+--------+
| Model                      | Version | Status |
+----------------------------+---------+--------+
| asr_am_EN                  | 1       | READY  |
| asr_am_HI                  | 1       | READY  |
| asr_am_OR                  | 1       | READY  |
| asr_am_TA                  | 1       | READY  |
| asr_preprocessor           | 1       | READY  |
| asr_pyctc_decoder_EN       | 1       | READY  |
| asr_pyctc_decoder_HI       | 1       | READY  |
| asr_pyctc_decoder_OR       | 1       | READY  |
| asr_pyctc_decoder_TA       | 1       | READY  |
| asr_pyctc_ensemble_EN      | 1       | READY  |
| asr_pyctc_ensemble_HI      | 1       | READY  |
| asr_pyctc_ensemble_OR      | 1       | READY  |
| asr_pyctc_ensemble_TA      | 1       | READY  |
| entity_EN                  | 1       | READY  |
| entity_HI                  | 1       | READY  |
| entity_OR                  | 1       | READY  |
| entity_TA                  | 1       | READY  |
| intent_ensemble            | 1       | READY  |
| intent_model_onnx          | 1       | READY  |
| intent_postprocessor       | 1       | READY  |
| intent_preprocessor        | 1       | READY  |
| itn_EN                     | 1       | READY  |
| itn_HI                     | 1       | READY  |
| itn_OR                     | 1       | READY  |
| itn_TA                     | 1       | READY  |
| pipeline_pyctc_ensemble_EN | 1       | READY  |
| pipeline_pyctc_ensemble_HI | 1       | READY  |
| pipeline_pyctc_ensemble_OR | 1       | READY  |
| pipeline_pyctc_ensemble_TA | 1       | READY  |
+----------------------------+---------+--------+

I0829 16:52:33.932731 1 metrics.cc:864] Collecting metrics for GPU 0: NVIDIA A100 80GB PCIe
I0829 16:52:33.932958 1 metrics.cc:757] Collecting CPU metrics
I0829 16:52:33.933077 1 tritonserver.cc:2264] 
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Option                           | Value                                                                                                                                                                                                |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| server_id                        | triton                                                                                                                                                                                               |
| server_version                   | 2.29.0                                                                                                                                                                                               |
| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |
| model_repository_path[0]         | /models/model_repository                                                                                                                                                                             |
| model_control_mode               | MODE_NONE                                                                                                                                                                                            |
| strict_model_config              | 0                                                                                                                                                                                                    |
| rate_limit                       | OFF                                                                                                                                                                                                  |
| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |
| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |
| response_cache_byte_size         | 0                                                                                                                                                                                                    |
| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |
| strict_readiness                 | 1                                                                                                                                                                                                    |
| exit_timeout                     | 30                                                                                                                                                                                                   |
+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

I0829 16:52:33.934139 1 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001
I0829 16:52:33.934333 1 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000
I0829 16:52:33.975773 1 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002
